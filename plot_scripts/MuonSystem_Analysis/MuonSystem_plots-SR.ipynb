{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 (default, Aug  7 2019, 17:28:10) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n"
     ]
    }
   ],
   "source": [
    "# use OOT data to estimate bkg in signal region\n",
    "\n",
    "import ROOT as rt\n",
    "# import root_numpy as rtnp\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import awkward\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('/storage/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/lib/')\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 0\n",
    "\n",
    "wH = 1\n",
    "Z_MASS = 91.2\n",
    "\n",
    "\n",
    "# donotdelete = []\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyToyear(key):\n",
    "    for year in years:\n",
    "        if year in key:\n",
    "            return year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15/Data2018/v1/v1/normalized/Run2_displacedJetMuonNtupler_V1p15_Data2016_Data2017_Data2018-HighMET_goodLumi.root\n",
      "MC_Summer16_ggH_15_100 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-100_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Summer16_VBFH_15_100 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-100_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Summer16_ggH_15_1000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-1000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Summer16_VBFH_15_1000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-1000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Summer16_ggH_15_10000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-10000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Summer16_VBFH_15_10000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-10000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Summer16_ggH_15_100000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-100000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Summer16_VBFH_15_100000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Summer16/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-100000_TuneCUETP8M1_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_ggH_15_100 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-100_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_VBFH_15_100 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-100_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_ggH_15_1000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-1000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_VBFH_15_1000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-1000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_ggH_15_10000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-10000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_VBFH_15_10000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-10000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_ggH_15_100000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-100000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall17_VBFH_15_100000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall17/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-100000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_ggH_15_100 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-100_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_VBFH_15_100 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-100_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_ggH_15_1000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-1000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_VBFH_15_1000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-1000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_ggH_15_10000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-10000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_VBFH_15_10000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-10000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_ggH_15_100000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/ggH_HToSSTobbbb_MH-125_MS-15_ctau-100000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n",
      "MC_Fall18_VBFH_15_100000 /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15//MC_Fall18/v3/v4//normalized/VBFH_HToSSTobbbb_MH-125_MS-15_ctau-100000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root\n"
     ]
    }
   ],
   "source": [
    "fpath =OrderedDict()\n",
    "tree = OrderedDict()\n",
    "mass = [15, 40, 55]\n",
    "mass = [15]\n",
    "# ctau = [1, 10, 100, 1000, 10000, 100000]\n",
    "# ctau = [10, 100, 1000, 10000, 100000]\n",
    "OLD_CTAU = np.array([100, 1000, 10000, 100000])#in mm\n",
    "\n",
    "\n",
    "years = ['Summer16', 'Fall17', 'Fall18']\n",
    "lumi = {\n",
    "    'Summer16': 35.92 * 1000,\n",
    "    'Fall17': 41.53 * 1000,\n",
    "    'Fall18': 59.74 * 1000,\n",
    "}\n",
    "category = 0\n",
    "ntupler_version = 'V1p15/'\n",
    "analyzer_version = 'v3/v4/'\n",
    "\n",
    "data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p15/Data2018/v1/v1/normalized/'\n",
    "\n",
    "fpath['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p15_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "for y in years:\n",
    "        mc_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_'+y+'/'+analyzer_version+'/normalized/'\n",
    "        tune = 'TuneCP5'\n",
    "        if y == 'Summer16': tune = 'TuneCUETP8M1'\n",
    "        for m in mass:\n",
    "                for ct in OLD_CTAU:\n",
    "                        key = 'MC_'+y+'_ggH_'+str(m)+'_'+str(ct)                       \n",
    "                        fpath[key] = mc_path+'ggH_HToSSTobbbb_MH-125_MS-'+str(m)+'_ctau-'+str(ct)+'_' + tune + '_13TeV-powheg-pythia8_1pb_weighted.root'\n",
    "                        key = 'MC_'+y+'_VBFH_'+str(m)+'_'+str(ct)                       \n",
    "                        fpath[key] = mc_path+'VBFH_HToSSTobbbb_MH-125_MS-'+str(m)+'_ctau-'+str(ct)+'_' + tune + '_13TeV-powheg-pythia8_1pb_weighted.root'\n",
    "#                         key = 'MC_'+y+'_VBFH_'+str(m)+'_'+str(ct)                       \n",
    "#                         fpath[key] = mc_path+'VBFH_HToSSTobbbb_MH-125_MS-'+str(m)+'_ctau-'+str(ct)+'_'+tune+'_13TeV-powheg-pythia8_1pb_weighted.root'\n",
    "\n",
    "NEvents = {}\n",
    "NEvents_genweight = {}\n",
    "for k,v in fpath.items():\n",
    "    print (k, v)\n",
    "    root_dir = uproot.open(v) \n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "    NEvents[k] = root_dir['NEvents'][1]\n",
    "    a = tree[k][\"weight\"].array()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_names_file = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/trigger_names_llp_v1.dat'\n",
    "trigger_names = []\n",
    "with open(trigger_names_file) as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    for line in reader:\n",
    "        trigger_names.append(line[2])\n",
    "\n",
    "trigger_paths = [177,362,87,135,136] #PFMET120\n",
    "trigger_paths += [84,91]\n",
    "if category == 0:\n",
    "    trigger_paths = [310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load bdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24800783]\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "\n",
    "import pickle\n",
    "# model = pickle.load(open( 'bdt_flatten_noEvtSelection.pickle.dat', \"rb\" ))\n",
    "bdt_name = 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi_v2'\n",
    "model = pickle.load(open( bdt_name+'.pickle', \"rb\" ))\n",
    "y_pred = model.predict_proba([1,2,3,4,4,5,6])[:, 1]\n",
    "print (y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def deltaPhi( phi1,  phi2):\n",
    "    dphi = phi1-phi2\n",
    "    while (dphi > math.pi):\n",
    "        dphi -= 2*math.pi\n",
    "    while (dphi <= -math.pi):\n",
    "        dphi += 2*math.pi\n",
    "    return dphi\n",
    "def deltaR(eta1, phi1, eta2, phi2):\n",
    "    dphi = deltaPhi(phi1,phi2)\n",
    "    deta = eta1 - eta2\n",
    "    return (dphi*dphi + deta*deta)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc with different hit vetoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27570\n",
      "trigger 310 0.7416220091839738\n",
      "data 20993309 1258\n",
      "True\n",
      "effiency 0.9435612082670907\n",
      "290\n",
      "trigger 310 0.9696969696969697\n",
      "MC_Summer16_ggH_15_100 3069 271\n",
      "True\n",
      "effiency 0.9446494464944649\n",
      "287\n",
      "trigger 310 0.9528158295281582\n",
      "MC_Summer16_VBFH_15_100 2628 248\n",
      "True\n",
      "effiency 0.9556451612903226\n",
      "964\n",
      "trigger 310 0.9801675041876047\n",
      "MC_Summer16_ggH_15_1000 14925 867\n",
      "True\n",
      "effiency 0.9354094579008074\n",
      "956\n",
      "trigger 310 0.9455452501405284\n",
      "MC_Summer16_VBFH_15_1000 14232 763\n",
      "True\n",
      "effiency 0.9357798165137615\n",
      "298\n",
      "trigger 310 0.9849974374504962\n",
      "MC_Summer16_ggH_15_10000 21463 280\n",
      "True\n",
      "effiency 0.9035714285714286\n",
      "44\n",
      "trigger 310 0.9485930735930735\n",
      "MC_Summer16_VBFH_15_10000 3696 34\n",
      "True\n",
      "effiency 0.9411764705882353\n",
      "44\n",
      "trigger 310 0.9849843017700323\n",
      "MC_Summer16_ggH_15_100000 21977 41\n",
      "True\n",
      "effiency 0.9024390243902439\n",
      "11\n",
      "trigger 310 0.9458425609019528\n",
      "MC_Summer16_VBFH_15_100000 4967 9\n",
      "True\n",
      "effiency 0.7777777777777778\n",
      "174\n",
      "trigger 310 0.9507785032646912\n",
      "MC_Fall17_ggH_15_100 1991 160\n",
      "True\n",
      "effiency 0.9625\n",
      "0\n",
      "trigger 310 1.0\n",
      "MC_Fall17_VBFH_15_100 14 0\n",
      "588\n",
      "trigger 310 0.9740721380031364\n",
      "MC_Fall17_ggH_15_1000 9565 521\n",
      "True\n",
      "effiency 0.944337811900192\n",
      "1\n",
      "trigger 310 0.9722222222222222\n",
      "MC_Fall17_VBFH_15_1000 36 1\n",
      "True\n",
      "effiency 1.0\n",
      "170\n",
      "trigger 310 0.9868302903322359\n",
      "MC_Fall17_ggH_15_10000 13364 161\n",
      "True\n",
      "effiency 0.8757763975155279\n",
      "0\n",
      "trigger 310 1.0\n",
      "MC_Fall17_VBFH_15_10000 124 0\n",
      "29\n",
      "trigger 310 0.9902744270205066\n",
      "MC_Fall17_ggH_15_100000 13264 26\n",
      "True\n",
      "effiency 0.8076923076923077\n",
      "0\n",
      "trigger 310 1.0\n",
      "MC_Fall17_VBFH_15_100000 162 0\n",
      "331\n",
      "trigger 310 0.9595050618672666\n",
      "MC_Fall18_ggH_15_100 3556 311\n",
      "True\n",
      "effiency 0.9646302250803859\n",
      "66\n",
      "trigger 310 0.9719188767550702\n",
      "MC_Fall18_VBFH_15_100 641 57\n",
      "True\n",
      "effiency 0.9298245614035088\n",
      "1056\n",
      "trigger 310 0.96872329516322\n",
      "MC_Fall18_ggH_15_1000 17553 950\n",
      "True\n",
      "effiency 0.9494736842105264\n",
      "208\n",
      "trigger 310 0.9797979797979798\n",
      "MC_Fall18_VBFH_15_1000 3267 175\n",
      "True\n",
      "effiency 0.9485714285714286\n",
      "364\n",
      "trigger 310 0.9817525566472829\n",
      "MC_Fall18_ggH_15_10000 24935 339\n",
      "True\n",
      "effiency 0.9174041297935103\n",
      "26\n",
      "trigger 310 0.9870775347912525\n",
      "MC_Fall18_VBFH_15_10000 2012 23\n",
      "True\n",
      "effiency 0.8260869565217391\n",
      "49\n",
      "trigger 310 0.9848432123110235\n",
      "MC_Fall18_ggH_15_100000 25863 48\n",
      "True\n",
      "effiency 0.8541666666666666\n",
      "3\n",
      "trigger 310 0.9862475442043221\n",
      "MC_Fall18_VBFH_15_100000 2036 3\n",
      "True\n",
      "effiency 0.6666666666666666\n",
      "CPU times: user 2min 2s, sys: 31.8 s, total: 2min 33s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_t = time.time()\n",
    "JET_PT_CUT = 10.0\n",
    "MUON_PT_CUT = 20.0\n",
    "N_RECHIT_CUT = 90\n",
    "jetPt_cut = 50\n",
    "tightid = False\n",
    "\n",
    "\n",
    "# BDT_CUT = 0.467 #90% wp vBDT/v1, bdt_flatten_noEvtSelection\n",
    "# bdtBkgEff =  0.0661076084960519\n",
    "\n",
    "# BDT_CUT = 0.9227871 #90% wp vBDT/v2, bdt_flatten_metfilter_me1112nohits_eta2p1\n",
    "# bdtBkgEff =  0.10278372591006424\n",
    "if bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs':\n",
    "    BDT_CUT = 0.92245656 #bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs\n",
    "    bdtBkgEff = 0.09957173447537473\n",
    "elif bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi':\n",
    "    BDT_CUT = 0.9608465 #bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi\n",
    "    bdtBkgEff = 0.06745182012847965\n",
    "elif bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi_v2':\n",
    "    BDT_CUT = 0.7802247 #bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi\n",
    "    bdtBkgEff = 0.061027837259100645\n",
    "else:\n",
    "    print('BDT NAME NOT FOUND')\n",
    "\n",
    "intime = True\n",
    "DPHI_CUT = 1\n",
    "weight = {}\n",
    "weight_event = {}\n",
    "weight_ctau = {}\n",
    "lumiSec = {}\n",
    "evtNum = {}\n",
    "nCsc = {}\n",
    "npv = {}\n",
    "npu = {}\n",
    "runNum = {}\n",
    "nCsc_JetMuonVetoCluster0p4_Me1112Veto = {}\n",
    "gLLP_csc = {}\n",
    "cscClusterSize = {}\n",
    "cscClusterTime = {}\n",
    "nCscClusters = {}\n",
    "selections_cluster = {}\n",
    "sel_cluster = {}\n",
    "sel_jetveto = {}\n",
    "met_trigger = {}\n",
    "met = {}\n",
    "gLLP_beta = {}\n",
    "jetPt = {}\n",
    "jetPhi = {}\n",
    "metPhi = {}\n",
    "angle ={}\n",
    "nLeptons = {}\n",
    "genJetPt = {}\n",
    "genJetPhi = {}\n",
    "genMet = {}\n",
    "genMetPhi = {}\n",
    "pileupWeight = {}\n",
    "gLLP_ctau = {}\n",
    "npv = {}\n",
    "nRechitClusters = {}\n",
    "nJets = {}\n",
    "nJets_50gev = {}\n",
    "cscRechitClusterTimeDiff = {}\n",
    "cscRechitCluster_match_gLLP = {}\n",
    "\n",
    "cscRechitClusterXSpread = {}\n",
    "cscRechitClusterYSpread = {}\n",
    "cscRechitClusterNStation = {}\n",
    "cscRechitClusterEtaPhiSpread = {}\n",
    "cscRechitClusterPhiSpread = {}\n",
    "cscRechitClusterEtaSpread = {}\n",
    "cscRechitClusterX = {}\n",
    "cscRechitClusterY = {}\n",
    "cscRechitClusterZ = {}\n",
    "cscRechitClusterPhi = {}\n",
    "cscClusterJetVetoPt = {}\n",
    "cscRechitClusterEta = {}\n",
    "\n",
    "cscRechitClusterMaxStationRatio = {}\n",
    "cscRechitClusterNStation = {}\n",
    "cscRechitClusterNChamber = {}\n",
    "cscRechitClusterMet_dPhi = {}\n",
    "jetMet_dPhiMin30 = {}\n",
    "jetMet_dPhiMin = {}\n",
    "dphiMet_cluster = {}\n",
    "nRechits_sr = {}\n",
    "jetMet_dPhiMin30_sr = {}\n",
    "bdt_score = {}\n",
    "a = {}\n",
    "b = {}\n",
    "c = {}\n",
    "d = {}\n",
    "sel_ev = {}\n",
    "bdt_sel = {}\n",
    "\n",
    "legend = {}\n",
    "\n",
    "legend['data_oot'] = 'Data OOT region'\n",
    "legend['data_intime'] = 'Data in-time region'\n",
    "legend['mc_signal'] = 'signal MC in time'\n",
    "legend['mc_intime'] = 'MC in-time background'\n",
    "legend['mc_oot'] = 'MC OOT background'\n",
    "legend['mc_bkg'] = 'QCD 50toInf background'\n",
    "\n",
    "# keys = ['data','mc_intime_bkg','mc_oot_bkg','mc_signal']\n",
    "keys = ['data_intime','data_oot','mc_signal','mc_bkg']\n",
    "keys = ['data_intime','mc_signal',]\n",
    "keys = ['data_intime','mc_signal']\n",
    "keys = ['data_oot_vr','data_oot_sr', 'data_intime_vr', 'data_intime_sr', 'mc_vr','mc_sr']\n",
    "keys = ['data_oot_vr','data_oot_sr', 'data_intime_vr', 'data_intime_sr', 'mc100_vr','mc100_sr', 'mc1000_vr', 'mc1000_sr']\n",
    "\n",
    "# keys = ['mc100_vr','mc100_sr', 'mc1000_vr', 'mc1000_sr']\n",
    "\n",
    "# for k in keys:\n",
    "#     print(k)\n",
    "# #     if k == 'data_intime': continue\n",
    "#     if k == 'mc_bkg':\n",
    "#         T = tree_bkg['QCDHT50toInf']\n",
    "#     elif 'mc1000' in k:\n",
    "#         T = tree_bkg['mc1000']\n",
    "#     elif 'mc100' in k:\n",
    "#         T = tree_bkg['mc100']\n",
    "#     else:\n",
    "#         T = tree_bkg['data']\n",
    "for k, T in tree.items():\n",
    "#     if k == 'data':continue\n",
    "########### SELECTION: CLUSTERS ############\n",
    "\n",
    "    sel_rechitcluster =  np.abs(T.array('cscRechitClusterMaxChamber')) > 12\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, np.abs(T.array('cscRechitClusterEta')) < 2.1)\n",
    "\n",
    "    me1112_veto = 0\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberPlus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberPlus12') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberMinus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberMinus12') <= me1112_veto)\n",
    "    if 'oot' in k:\n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster,  T.array('cscRechitClusterTime') < -12.5)\n",
    "    else:\n",
    "        sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitClusterJetVetoPt') < JET_PT_CUT)\n",
    "        sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitClusterMuonVetoPt') < MUON_PT_CUT)\n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster, np.logical_and(T.array('cscRechitClusterTime') < 12.5, T.array('cscRechitClusterTime') > -5.0))\n",
    "    print(np.count_nonzero(sel_rechitcluster.flatten()))\n",
    "\n",
    "########### SELECTION: JETS ############\n",
    "    \n",
    "    sel_jet = np.logical_and(T.array('jetPt') > jetPt_cut, np.abs(T.array('jetEta')) < 2.4 )\n",
    "\n",
    "########### SELECTION: EVENTS ############\n",
    "    hlt = T['HLTDecision'].array()\n",
    "    # select only triggered events\n",
    "    sel_ev[k] = np.ones(hlt[:,0].shape, dtype=bool)\n",
    "    sel_ev[k] = np.zeros(hlt[:,0].shape)\n",
    "    for tr in trigger_paths:            \n",
    "        sel_ev[k]   = np.logical_or(sel_ev[k] ,hlt[:,tr])\n",
    "        print(\"trigger\",tr,1.0*np.count_nonzero(hlt[:,tr])/len(hlt[:,tr]))\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('met') > 200)\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k], T.array('category') == category)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('nLeptons') == 0)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] , sel_jet.sum()>=1)\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k],sel_rechitcluster.sum() == 1)\n",
    "    if k[:4] == 'data':\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_HBHENoiseFilter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_HBHEIsoNoiseFilter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_BadPFMuonFilter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_globalSuperTightHalo2016Filter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_EcalDeadCellTriggerPrimitiveFilter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_eeBadScFilter'))\n",
    "#             sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag_ecalBadCalibFilter'))\n",
    "\n",
    "        # missing Flag_EcalDeadCellTriggerPrimitiveFilter\n",
    "#             ecalBadCalibReducedMINIAODFilter\n",
    "    else:\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_HBHENoiseFilter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_HBHEIsoNoiseFilter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_BadPFMuonFilter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_globalSuperTightHalo2016Filter'))\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_EcalDeadCellTriggerPrimitiveFilter'))\n",
    "\n",
    "#             sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_ecalBadCalibFilter'))\n",
    "#             sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_eeBadScFilter'))\n",
    "\n",
    "            \n",
    "\n",
    "#             sel_ev = np.logical_and(sel_ev, T.array('runNum')<319077)\n",
    "#             print('selev',np.count_nonzero(sel_ev))\n",
    "#             sel_ev = np.logical_and(sel_ev, T.array('Flag_ecalBadCalibFilter'))\n",
    "#             print('selev',np.count_nonzero(T.array('Flag_ecalBadCalibFilter')))\n",
    "#     gLLP_csc[k] = T.array('gLLP_csc')\n",
    "#     if k[:2] == 'mc':\n",
    "#         sel_ev[k] = np.logical_and(sel_ev[k], np.sum(T.array('gLLP_csc'),axis = 1) > 0)\n",
    "    print(k, len(sel_ev[k]), np.count_nonzero(sel_ev[k]))\n",
    "########### BRANCHES ############\n",
    "\n",
    "   ##### event variables ##### \n",
    "    \n",
    "    gLLP_beta[k] = T.array('gLLP_beta')[sel_ev[k]]\n",
    "\n",
    "\n",
    "    ##### bdt variables ####\n",
    "    \n",
    "    cscRechitClusterPhi[k] = T.array('cscRechitClusterPhi')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterXSpread[k] = T.array('cscRechitClusterXSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterYSpread[k] = T.array('cscRechitClusterYSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEtaSpread[k] = T.array('cscRechitClusterEtaSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterPhiSpread[k] = T.array('cscRechitClusterPhiSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterNStation[k] = T.array('cscRechitClusterNStation')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEtaPhiSpread[k] = T.array('cscRechitClusterEtaPhiSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterX[k] = T.array('cscRechitClusterX')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterY[k] = T.array('cscRechitClusterY')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterZ[k] = T.array('cscRechitClusterZ')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEta[k] = T.array('cscRechitClusterEta')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterPhi[k] = T.array('cscRechitClusterPhi')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "\n",
    "    if bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs':\n",
    "        \n",
    "        bdt_var = {'cscRechitClusterXSpread': cscRechitClusterXSpread[k],\n",
    "         'cscRechitClusterYSpread': cscRechitClusterYSpread[k],\n",
    "         'cscRechitClusterNStation':cscRechitClusterNStation[k],\n",
    "         'cscRechitClusterEtaPhiSpread':cscRechitClusterEtaPhiSpread[k],\n",
    "         'cscRechitClusterX':cscRechitClusterX[k],\n",
    "         'cscRechitClusterY':cscRechitClusterY[k],\n",
    "         'cscRechitClusterZ':cscRechitClusterZ[k],\n",
    "        }\n",
    "    elif 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi' in bdt_name:\n",
    "        bdt_var = {'cscRechitClusterNStation': cscRechitClusterNStation[k],\n",
    "         'cscRechitClusterEtaSpread': cscRechitClusterEtaSpread[k],\n",
    "         'cscRechitClusterPhiSpread':cscRechitClusterPhiSpread[k],\n",
    "         'cscRechitClusterEtaPhiSpread':cscRechitClusterEtaPhiSpread[k],\n",
    "         'cscRechitClusterPhi':cscRechitClusterPhi[k],\n",
    "         'cscRechitClusterEta':np.abs(cscRechitClusterEta[k]),\n",
    "         'cscRechitClusterZ':np.abs(cscRechitClusterZ[k]),\n",
    "        }\n",
    "    else:\n",
    "        print('BDT NAME NOT FOUND')\n",
    "    \n",
    "    if len(cscRechitClusterX[k])>0:\n",
    "        dataset = pd.DataFrame(bdt_var)\n",
    "        bdt_score[k] = model.predict_proba(dataset.values)[:, 1]\n",
    "        print(len(bdt_score[k]) == np.count_nonzero(sel_ev[k]))\n",
    "        bdt_sel[k] = bdt_score[k] < BDT_CUT \n",
    "        if 'data' in k:\n",
    "            bdt_sel[k] = bdt_score[k] < BDT_CUT \n",
    "        else:\n",
    "            bdt_sel[k] = bdt_score[k] >= BDT_CUT \n",
    "        print(\"effiency\",np.count_nonzero(bdt_sel[k])/len(bdt_sel[k]))\n",
    "    \n",
    "\n",
    "\n",
    "        dphiMet_cluster[k] = np.abs(T.array('cscRechitClusterMet_dPhi'))[sel_rechitcluster][sel_ev[k]][:,0].flatten()[bdt_sel[k]]\n",
    "\n",
    "    #     jetMet_dPhiMin[k] = T.array('jetMet_dPhiMin')[sel_ev[k]][bdt_sel[k]]\n",
    "    #     metPhi[k] = T.array('metPhi')[sel_ev[k]]\n",
    "    #     jetPhi[k] = T.array('jetPhi')[sel_ev[k]]\n",
    "    #     jetPt[k] = T.array('jetPt')[sel_ev[k]]\n",
    "    #     jetMet_dPhiMin30[k] = []\n",
    "    #     for ev in range(len(jetPhi[k])):\n",
    "    #         dphi_min_temp = 999\n",
    "    #         for i in range(len(jetPhi[k][ev])):\n",
    "    #             if jetPt[k][ev][i] < 30: continue\n",
    "    #             dphi_temp = abs(deltaPhi(metPhi[k][ev],jetPhi[k][ev][i]))\n",
    "    #             if dphi_min_temp > dphi_temp: dphi_min_temp = dphi_temp\n",
    "    #         jetMet_dPhiMin30[k].append(dphi_min_temp)\n",
    "    #     jetMet_dPhiMin30[k] = np.array(jetMet_dPhiMin30[k])\n",
    "    #     jetMet_dPhiMin30_sr[k] = jetMet_dPhiMin30[k][np.logical_not(bdt_sel[k])]\n",
    "    #     jetMet_dPhiMin30[k] = jetMet_dPhiMin30[k][bdt_sel[k]]\n",
    "\n",
    "        weight[k] = T.array('weight')[sel_ev[k]][bdt_sel[k]]\n",
    "        npv[k] = T.array('npv')[sel_ev[k]][bdt_sel[k]]\n",
    "\n",
    "\n",
    "        if k[:2] == 'MC':\n",
    "            pileupWeight[k] = T.array('pileupWeight')[sel_ev[k]][bdt_sel[k]]\n",
    "        else:\n",
    "            pileupWeight[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "        if k[:2] == 'MC':\n",
    "            weight[k] = weight[k]*lumi[keyToyear(k)]\n",
    "        cscClusterSize[k] =  T.array('cscRechitClusterSize')[sel_rechitcluster][sel_ev[k]][bdt_sel[k]]\n",
    "        nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] = cscClusterSize[k][:,0]\n",
    "    else:\n",
    "        dphiMet_cluster[k] = np.abs(T.array('cscRechitClusterMet_dPhi'))[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "        weight[k] = T.array('weight')[sel_ev[k]]\n",
    "        npv[k] = T.array('npv')[sel_ev[k]]\n",
    "        if k[:2] == 'MC':\n",
    "            pileupWeight[k] = T.array('pileupWeight')[sel_ev[k]]\n",
    "        else:\n",
    "            pileupWeight[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "        if k[:2] == 'MC':\n",
    "            weight[k] = weight[k]*lumi[keyToyear(k)]\n",
    "        cscClusterSize[k] =  T.array('cscRechitClusterSize')[sel_rechitcluster][sel_ev[k]]\n",
    "        nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] = cscClusterSize[k][:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# life time reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_calc(llp_ct, new_ctau, old_ctau):\n",
    "    for i, ct in enumerate(old_ctau):\n",
    "        if i == 0: source = np.exp(-1.0*llp_ct/ct)/ct**2\n",
    "        else: source = source + np.exp(-1.0*llp_ct/ct)/ct**2\n",
    "    weight = len(old_ctau)*1.0/new_ctau**2 * np.exp(-1.0*llp_ct/new_ctau)/source\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in cm\n",
    "# new_ctau = ['5','10','30','40', '50','100','200','300','500','1000', '5000', '10000', '20000','50000', '100000', '200000'. '300000', '500000', '1000000'] #mm\n",
    "# ctaus = ['100']\n",
    "\n",
    "# y = 'Summer16'\n",
    "# m = 15\n",
    "# one weight, for each year, mass and ctau\n",
    "\n",
    "# for ctau in ctaus:\n",
    "#     for m in mass:\n",
    "#         for y in year:\n",
    "#             for ct0 in OLD_CTAU:\n",
    "#                 k = 'MC_'+y+'_ggH_'+str(m)+'_'+str(ct0)\n",
    "#                 T = tree[k]\n",
    "#                 new_ctau = float(ctau)\n",
    "#                 gLLP_ctau[ctau] = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "#                 weight_ctau[ctau] = np.exp(gLLP_ctau[ctau]*(1.0/ct0 - 1.0/new_ctau))*(ct0*1.0/new_ctau)**2\n",
    "# #         print(ctau, ct0, weight_ctau)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (14,) (135,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a9f81fc5d8ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mctau\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mctaus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m        \u001b[0mnew_ctau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m        \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpileupWeight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mc_vr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mc_vr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_ctau\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m        \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnCsc_JetMuonVetoCluster0p4_Me1112Veto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mc_vr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mN_RECHIT_CUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjetMet_dPhiMin30\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mc_vr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mDPHI_CUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m        \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnCsc_JetMuonVetoCluster0p4_Me1112Veto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mc_vr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mN_RECHIT_CUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjetMet_dPhiMin30\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mc_vr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mDPHI_CUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (14,) (135,) "
     ]
    }
   ],
   "source": [
    " #in cm\n",
    "ctaus = ['5','10','30','40', '50','100','200','300','500','1000', '5000', '10000', '100000']\n",
    "ctaus = ['100']\n",
    "k = 'mc_signal'\n",
    "T = tree_bkg['mc']\n",
    "br = 0.01 # use 1%\n",
    "DPHI_CUT = 0.6\n",
    "N_RECHIT_CUTS = np.arange(90,220, 10)\n",
    "\n",
    "for N_RECHIT_CUT in N_RECHIT_CUTS:\n",
    "    a_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] >= N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] >= DPHI_CUT))\n",
    "    b_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] < N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] >= DPHI_CUT))\n",
    "    c_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] < N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] < DPHI_CUT))\n",
    "    d_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] >= N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] < DPHI_CUT))\n",
    "    for ctau in ctaus:\n",
    "        new_ctau = float(ctau)\n",
    "        w = br * pileupWeight['mc_vr'] * weight['mc_vr'] * weight_ctau[ctau]\n",
    "        a = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']>=N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']>=DPHI_CUT)])\n",
    "        b = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']<N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']>=DPHI_CUT)])\n",
    "        c = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']<N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']<DPHI_CUT)])\n",
    "        d = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']>=N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']<DPHI_CUT)])\n",
    "\n",
    "#         print(N_RECHIT_CUT, a/a_data, a, a_data)\n",
    "#         print(a,b,c,d)\n",
    "        w = br * pileupWeight['mc_sr'] * weight['mc_sr'] \n",
    "        a = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_sr']>=N_RECHIT_CUT, jetMet_dPhiMin30['mc_sr']>=DPHI_CUT)])\n",
    "    print(a)\n",
    "        \n",
    "        \n",
    "#         print(N_RECHIT_CUT, a/a_data,b/b_data,c/c_data,d/d_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check bdt eff in low N_rechits bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 'data_intime'\n",
    "# print(\"n_rechit, VR, SR, unc\")\n",
    "# for n_rechits in [60,70,80,90]:\n",
    "#     for dphi in [ 0.4]:\n",
    "# #         print(\"dphi, n_rechits\", dphi, n_rechits)\n",
    "#         inverted = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<n_rechits, jetMet_dPhiMin30[k]<dphi))\n",
    "#         inverted_unc = inverted**0.5/(1-bdtBkgEff)*bdtBkgEff\n",
    "#         inverted = inverted/(1-bdtBkgEff)*bdtBkgEff\n",
    "#         print(n_rechits, np.count_nonzero(np.logical_and(nRechits_SR[k]<n_rechits, jetMet_dPhiMin30_sr[k]<dphi)), round(inverted,2), round(inverted_unc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120, 130, 140, 150, 160, 170, 180, 190, 200, 210])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(120,220, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.679829084176044, 10.663286384976526, 7.478655909767369, 5.609539746848185, 3.5192494338401814, 1.7881745120551087, 1.824635265912347, 1.5550510783200906, 0.929054054054054, 0.8716936439005131, 1.0069930069930069]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "N_RECHIT_CUTS = np.arange(60,170, 10)\n",
    "# N_RECHIT_CUTS = np.arange(160,170, 10)\n",
    "\n",
    "\n",
    "# ctaus = ['10','30','40', '50','100','200','300','500','1000', '2000', '3000','5000', '10000', '20000', '30000', '50000','100000']\n",
    "# ctaus = ['1000']\n",
    "ctaus = ['5','10','30','40', '50','100','200','300','500','1000', '5000', '10000', '20000','50000', '100000', '200000', '300000', '500000', '1000000'] #mm\n",
    "\n",
    "\n",
    "\n",
    "# N_RECHIT_CUT = 120\n",
    "UNBLIND = False\n",
    "methodA = 1\n",
    "jetmet = 0\n",
    "VBF = False\n",
    "if jetmet: \n",
    "    var = jetMet_dPhiMin30\n",
    "    DPHI_CUT = 0.6\n",
    "else: \n",
    "    var = dphiMet_cluster\n",
    "    DPHI_CUT = 0.75\n",
    "eff_path = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/data/bdt_eff/'\n",
    "eff_file = eff_path + bdt_name +'.txt'\n",
    "bdtBkgEff_nrechit = np.genfromtxt(eff_file, delimiter=',')\n",
    "# print(bdtBkgEff_nrechit.shape)\n",
    "bkg = []\n",
    "for N_RECHIT_CUT in N_RECHIT_CUTS:\n",
    "    if methodA:\n",
    "        ##### method A #####\n",
    "        row, _ = np.argwhere(bdtBkgEff_nrechit == N_RECHIT_CUT)[0]\n",
    "        lowN_eff = bdtBkgEff_nrechit[row,1]\n",
    "        highN_eff = bdtBkgEff_nrechit[row,2]\n",
    "        k = 'data'\n",
    "        a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "        b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "        c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT))\n",
    "        d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT))\n",
    "        if jetmet:\n",
    "            pred = b*d/c\n",
    "            stat_unc = (1./b + 1./c + 1./d)**0.5*(pred)\n",
    "            sys_unc = abs(a-pred)\n",
    "            unc = [(stat_unc**2 + sys_unc**2)**0.5/pred, b**0.5/b, c**0.5/c, d**0.5/d]\n",
    "            \n",
    "        else:\n",
    "            pred = a*c/b\n",
    "            stat_unc = (1./a + 1./c + 1./b)**0.5*(pred)\n",
    "            sys_unc = abs(d-pred)\n",
    "            unc = [a**0.5/a, b**0.5/b, c**0.5/c, (stat_unc**2 + sys_unc**2)**0.5/pred]\n",
    "#         print(N_RECHIT_CUT, stat_unc, sys_unc, unc)\n",
    "        a = a/(1-highN_eff)*highN_eff\n",
    "        b = b/(1-lowN_eff)*lowN_eff\n",
    "        c = c/(1-lowN_eff)*lowN_eff\n",
    "        d = d/(1-highN_eff)*highN_eff    \n",
    "        pred = pred/(1-highN_eff)*highN_eff\n",
    "#         print('eff',highN_eff, lowN_eff)\n",
    "    else:\n",
    "        ##### method B #####\n",
    "#         factor = (len(var['data_intime_vr'])+len(var['data_intime_sr']))/(len(var['data_oot_vr'])+len(var['data_oot_sr']))\n",
    "        factor = (len(var['data_intime_vr']))/(len(var['data_oot_vr']))\n",
    "#         print('factor', factor, factor2)\n",
    "        k = 'data_oot_sr'\n",
    "        a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "        b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT)) \n",
    "        c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "        d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "#         print(N_RECHIT_CUT, b_data*d_data/c_data, a_data,  b_data*d_data/c_data*factor)\n",
    "        if jetmet:\n",
    "            pred = b*d/c\n",
    "            stat_unc = (1./b + 1./c + 1./d)**0.5*(pred)\n",
    "            sys_unc = abs(a-pred)\n",
    "            unc = [(stat_unc**2 + sys_unc**2)**0.5/pred, b**0.5/b, c**0.5/c, d**0.5/d]\n",
    "        else:\n",
    "            pred = a*c/b\n",
    "            stat_unc = (1./a + 1./c + 1./b)**0.5*(pred)\n",
    "            sys_unc = abs(d-pred)\n",
    "            unc = [a**0.5/a, b**0.5/b, c**0.5/c, (stat_unc**2 + sys_unc**2)**0.5/pred]\n",
    "#         print(N_RECHIT_CUT, stat_unc, sys_unc, unc)\n",
    "#         print(factor)\n",
    "        a = a * factor\n",
    "        b = b * factor\n",
    "        c = c * factor\n",
    "        d = d * factor\n",
    "        pred = pred * factor\n",
    "    bkg.append(pred)\n",
    "    #####\n",
    "    # a = c*c1*c2\n",
    "    # b = c1* c\n",
    "    # c = c\n",
    "    # d = c2*c\n",
    "    #####\n",
    "    outDataCardsDir = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine/datacards/'+\\\n",
    "    ntupler_version+analyzer_version+'/'+bdt_name\n",
    "    if methodA: outDataCardsDir = outDataCardsDir + '/methodA/'\n",
    "    else: outDataCardsDir = outDataCardsDir + '/methodB/'\n",
    "    if not os.path.isdir(outDataCardsDir):os.mkdir(outDataCardsDir)\n",
    "    sig_norm = []\n",
    "    for m in mass:\n",
    "        for ct in ctaus:\n",
    "            dphi = str(DPHI_CUT).replace(\".\", \"p\")\n",
    "            if VBF: modelName = 'VBFH'\n",
    "            else: modelName = 'ggh'\n",
    "            if jetmet:\n",
    "                modelName = modelName + '_mh125_mx'+str(m)+'_ctau'+str(ct)+'mm_nRechit'+str(N_RECHIT_CUT)+'dPhiJet'+dphi\n",
    "            else:\n",
    "                modelName = modelName + '_mh125_mx'+str(m)+'_ctau'+str(ct)+'mm_nRechit'+str(N_RECHIT_CUT)+'dPhiCluster'+dphi\n",
    "            signal_rate = {}\n",
    "            signal_rate['ggH'] = np.zeros((4,))\n",
    "            signal_rate['VBFH'] = np.zeros((4,))\n",
    "            ctf = int(ct)\n",
    "            for i, y in enumerate(years):\n",
    "                if ctf < OLD_CTAU[0]:\n",
    "                    old_ctau_temp = np.array([OLD_CTAU[0]])\n",
    "                else:\n",
    "                    for j, ct0 in enumerate(OLD_CTAU):\n",
    "                        if ct0 == ctf: \n",
    "                            old_ctau_temp = np.array([ctf])\n",
    "                            break\n",
    "                        elif ct0 > ctf:\n",
    "                            old_ctau_temp = np.array([OLD_CTAU[j-1], OLD_CTAU[j]])\n",
    "                            old_ctau_temp = np.array([OLD_CTAU[j]])\n",
    "                            break\n",
    "                        if j == len(OLD_CTAU)-1: \n",
    "                            old_ctau_temp = np.array([OLD_CTAU[j]])\n",
    "                weight_sum = 0\n",
    "                weight_len = 0\n",
    "                for j,ct0 in enumerate(old_ctau_temp):\n",
    "                    if VBFH: prods = ['ggH', 'VBFH']\n",
    "                    else: prods = ['ggH']\n",
    "                    for prod in prods:\n",
    "                        k = 'MC_'+y+'_'+prod+'_'+str(m)+'_'+str(ct0)\n",
    "                        T = tree[k]\n",
    "                        if np.count_nonzero(sel_ev[k]) == 0: continue\n",
    "                        gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                        if len(gLLP_ctau) == 0: continue\n",
    "                        weight_ctau = weight_calc(gLLP_ctau, float(ct)/10, old_ctau_temp/10) # convert everything to cm\n",
    "                        w = pileupWeight[k] * weight[k] * weight_ctau\n",
    "                        weight_sum +=np.sum(weight_ctau)\n",
    "                        weight_len += len(weight_ctau)                    \n",
    "                        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]>=DPHI_CUT)\n",
    "                        signal_rate[prod][0]+=np.sum(w[cond])\n",
    "                        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]>=DPHI_CUT)\n",
    "                        signal_rate[prod][1]+=np.sum(w[cond])\n",
    "                        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]<DPHI_CUT)\n",
    "                        signal_rate[prod][2]+=np.sum(w[cond])\n",
    "                        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]<DPHI_CUT)\n",
    "                        signal_rate[prod][3]+=np.sum(w[cond])\n",
    "                    \n",
    "            norm = np.sum(signal_rate['VBFH']+signal_rate['ggH'])/2\n",
    "            if norm == 0: continue\n",
    "            sig_norm.append(norm)\n",
    "#             print(m, ct, norm, weight_sum/weight_len)\n",
    "            signal_rate = signal_rate/norm\n",
    "            if VBF:\n",
    "                make_datacard_2sig(outDataCardsDir,modelName, jetmet, signal_rate['ggH'], signal_rate['VBFH'], norm, a,b,c,d, unc)\n",
    "            else:\n",
    "                make_datacard(outDataCardsDir, modelName, jetmet, signal_rate['ggH'], norm, pred,b,c,d, unc)\n",
    "#     print(sig_norm)\n",
    "print(bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15 1000 1938.8570868046945\n",
    "40 1000 90.73068838176704\n",
    "55 1000 3.2566280769474663\n",
    "[1.0069930069930069]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datacard(outDataCardsDir,modelName, jetmet, signal_rate, norm, a,b,c,d, unc):\n",
    "    if jetmet:\n",
    "        c1 = b/c\n",
    "        c2 = d/c\n",
    "    else:\n",
    "        c1 = a/b\n",
    "        c2 = c/b\n",
    "    text_file = open(outDataCardsDir+modelName+\".txt\", \"w\")\n",
    "    text_file.write('# signal norm {0} \\n'.format(norm))\n",
    "\n",
    "    text_file.write('imax {0} \\n'.format(4))\n",
    "    text_file.write('jmax {0} \\n'.format(1))\n",
    "    text_file.write('kmax * \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('bin \\t chA \\t chB \\t chC \\t chD \\n')\n",
    "    text_file.write('observation \\t {0:6.2f} \\t {1:6.2f} \\t {2:6.2f} \\t {3:6.2f} \\n'.format(a, b, c, d))\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    text_file.write('bin \\t chA \\t chA \\t chB \\t chB \\t chC \\t chC \\t chD \\t chD \\n')\n",
    "    text_file.write('process sig \\t bkg \\t sig \\t bkg \\t sig \\t bkg \\t sig \\t bkg \\n')\n",
    "    text_file.write('process 0 \\t 1 \\t 0 \\t 1 \\t 0 \\t 1 \\t 0 \\t 1 \\n')\n",
    "    rate_string = 'rate'\n",
    "    for i, rate in enumerate(signal_rate):\n",
    "\n",
    "        rate_string =  rate_string+'\\t {0:e} \\t 1'.format(rate)\n",
    "    text_file.write(rate_string+'\\n')\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    for ch in ['A','B','C','D']:\n",
    "        text_file.write('NA\\t rateParam \\t ch{0} \\t bkg \\t {1:6.2f} \\n'.format(ch, c))\n",
    "    if jetmet:\n",
    "        text_file.write('c1\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "        text_file.write('c1\\t rateParam \\t chB \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "    else:\n",
    "        text_file.write('c1\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "        text_file.write('c1\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chC \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "#     #### uncertainties ####\n",
    "    text_file.write('lumi\\t lnN \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\n')\n",
    "    text_file.write('signal_yield \\t lnN \\t 1.2 \\t - \\t 1.2 \\t - \\t 1.2 \\t - \\t 1.2 \\t - \\n')\n",
    "    text_file.write('data_pred \\t lnN \\t - \\t {0} \\t - \\t {1} \\t - \\t {2} \\t - \\t {3} \\n'.format(1+unc[0], 1+unc[1], 1+unc[2], 1+unc[3]))\n",
    "\n",
    "\n",
    "\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datacard_2sig(outDataCardsDir,modelName, jetmet, signal_rate1, signal_rate2, norm, a,b,c,d, unc):\n",
    "    if jetmet:\n",
    "        c1 = b/c\n",
    "        c2 = d/c\n",
    "    else:\n",
    "        c1 = a/b\n",
    "        c2 = c/b\n",
    "    \n",
    "    text_file = open(outDataCardsDir+modelName+\".txt\", \"w\")\n",
    "    text_file.write('# signal norm {0} \\n'.format(norm))\n",
    "\n",
    "    text_file.write('imax {0} \\n'.format(4))\n",
    "    text_file.write('jmax {0} \\n'.format(1))\n",
    "    text_file.write('kmax * \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('bin \\t chA \\t chB \\t chC \\t chD \\n')\n",
    "    text_file.write('observation \\t {0:6.2f} \\t {1:6.2f} \\t {2:6.2f} \\t {3:6.2f} \\n'.format(a, b, c, d))\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    text_file.write('bin \\t chA \\t chA \\t chA \\t chB \\t chB \\t chB \\t chC \\t chC \\t chC \\t chD \\t chD \\t chD \\n')\n",
    "    text_file.write('process ggH \\t VBFH \\t bkg \\t ggH \\t VBFH \\t bkg \\t ggH \\t VBFH \\t bkg \\t ggH \\t VBFH \\t bkg \\n')\n",
    "    text_file.write('process 0 \\t 0 \\t 1 \\t 0 \\t 0 \\t 1 \\t 0 \\t 0 \\t 1 \\t 0 \\t 0 \\t 1 \\n')\n",
    "    rate_string = 'rate'\n",
    "    for i, rate in enumerate(signal_rate1):\n",
    "        rate_string =  rate_string+'\\t {0:e} \\t {1:e} \\t1'.format(rate, signal_rate2[i])\n",
    "    text_file.write(rate_string+'\\n')\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    for ch in ['A','B','C','D']:\n",
    "        text_file.write('NA\\t rateParam \\t ch{0} \\t bkg \\t {1:6.2f} \\n'.format(ch, c))\n",
    "\n",
    "    if jetmet:\n",
    "        text_file.write('c1\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "        text_file.write('c1\\t rateParam \\t chB \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "    else:\n",
    "        text_file.write('c1\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "        text_file.write('c1\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chC \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "\n",
    "#     #### uncertainties ####\n",
    "    text_file.write('lumi\\t lnN \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\n')\n",
    "    text_file.write('signal_yield \\t lnN \\t 1.2 \\t - \\t 1.2 \\t - \\t 1.2 \\t - \\t 1.2 \\t - \\n')\n",
    "    text_file.write('data_pred \\t lnN \\t - \\t {0} \\t - \\t {1} \\t - \\t {2} \\t - \\t {3} \\n'.format(1+unc[0], 1+unc[1], 1+unc[2], 1+unc[3]))\n",
    "\n",
    "\n",
    "\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# significance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# background prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution for event level variables in different binnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roc curve for event level variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['histo_utilities'])\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "leg = rt.TLegend(0.5,0.80,0.90,0.90)\n",
    "\n",
    "leg.SetTextSize(0.03)\n",
    "leg.SetBorderSize(0)\n",
    "\n",
    "leg.SetEntrySeparation(0.01)\n",
    "c = rt.TCanvas('c','c', 800, 800)\n",
    "# Plotting ncsc\n",
    "start_t = time.time()\n",
    "\n",
    "legend = {}\n",
    "legend['data_oot'] = 'Data OOT region'\n",
    "legend['data_intime'] = 'Data in-time region'\n",
    "legend['mc_signal'] = 'signal MC in time'\n",
    "legend['mc_intime'] = 'MC in-time background'\n",
    "legend['mc_oot'] = 'MC OOT background'\n",
    "legend['mc_bkg'] = 'QCD 50toInf background'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "keys = ['data_intime','data_oot','mc_signal',]\n",
    "keys = ['data_intime','mc_signal',]\n",
    "\n",
    "\n",
    "h = {}\n",
    "rt.gStyle.SetOptFit(1011)\n",
    "# for i,k in enumerate(tree_bkg.keys()):\n",
    "br = 1\n",
    "for i,k in enumerate(keys):\n",
    "\n",
    "#     if k == 'data_intime':\n",
    "#         cond = nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < 200\n",
    "        \n",
    "#     else:\n",
    "#         cond = np.ones(weight[k].shape, dtype=bool)\n",
    "#     cond = np.logical_and(cond, jetMet_dPhiMin4[k]>0.25)\n",
    "    if k == 'mc_signal':\n",
    "        br = 1\n",
    "    else: br = 1\n",
    "#     if k == 'mc_background':br = 1\n",
    "    bins = [50,0,1000]\n",
    "    metcut = 200\n",
    "    h[k] = create_TH1D( nCsc_JetMuonVetoCluster0p4_Me1112Veto[k][cond], axis_title=['N_{rechits}', 'Events'], name=k, binning=bins,weights = br*weight[k][cond])\n",
    "    h[k].SetLineColor(std_color_list[i])\n",
    "    print(\"weight\",weight[k][0])\n",
    "    leg.AddEntry(h[k], legend[k]+\" (scaled)\" if k == 'data_oot' else legend[k])\n",
    "#     if k == 'mc_signal':\n",
    "#         for i in range(h[k].GetNbinsX()):\n",
    "#             s = 0.015*h[k].GetBinContent(i+1)\n",
    "#             b = h['data_oot'].GetBinContent(i+1)\n",
    "#             if s+b == 0:continue\n",
    "#             sig = s/(s+b)**0.5\n",
    "#             print(i,h[k].GetBinCenter(i+1),sig,s,b)\n",
    "#             if sig < 1./100:\n",
    "#                 print(i,sig)\n",
    "#                 continue\n",
    "#     h[k].SetMinimum(1)\n",
    "\n",
    "#     r = h[k].Fit('expo', 'LRSQ+', '', 50,400)\n",
    "#     print(r.Get())\n",
    "#     print(r.Prob())\n",
    "#     h[k].GetFunction(\"expo\").SetLineColor(std_color_list[2])\n",
    "#     h[k].GetFunction(\"expo\").SetLineWidth(2)\n",
    "    h[k].GetXaxis().SetLabelSize(0.04)\n",
    "    h[k].SetMinimum(0.1)\n",
    "    h[k].SetMaximum(10E6/2)\n",
    "#     h[k+'met'].GetXaxis().SetLabelSize(0.02)\n",
    "    if k == 'data_oot':\n",
    "        scale = 1.0*h['data_intime'].GetBinContent(4)/h['data_oot'].GetBinContent(4)\n",
    "#         for i in range(10):\n",
    "#             print(1.0*h['data_intime'].GetBinContent(i+1)/h['data_oot'].GetBinContent(i+1))\n",
    "        h[k].Scale(scale)\n",
    "    if k[:4] == 'data':\n",
    "        h[k].Draw('same E1')\n",
    "    else:\n",
    "        h[k].Draw(\"same hist\")\n",
    "#     h[k+'met'].DrawNormalized('same')\n",
    "    \n",
    "\n",
    "# c = make_ratio_plot([h['mc'],h['data']], fit = False, logy=True, in_tags = [\"MC\",\"Data\"], ratio_bounds = [0,3])\n",
    "c.SetRightMargin(0)\n",
    "c.SetLogy()\n",
    "leg.Draw()\n",
    "\n",
    "c.Draw()\n",
    "# print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['histo_utilities'])\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "leg = rt.TLegend(0.5,0.80,0.90,0.90)\n",
    "\n",
    "leg.SetTextSize(0.03)\n",
    "leg.SetBorderSize(0)\n",
    "\n",
    "leg.SetEntrySeparation(0.01)\n",
    "c = rt.TCanvas('c','c', 800, 800)\n",
    "# Plotting ncsc\n",
    "start_t = time.time()\n",
    "\n",
    "\n",
    "k = 'data_intime'\n",
    "\n",
    "h = {}\n",
    "rt.gStyle.SetOptFit(1011)\n",
    "\n",
    "bins = [40,0,1000]\n",
    "metcut = 200\n",
    "\n",
    "# cscRechitClusterMaxChamber = {}\n",
    "# cscRechitClusterNChamber = {}\n",
    "# cscRechitClusterNStation = {}\n",
    "# cscRechitClusterMaxStationRatio = {}\n",
    "# cscRechitClusterMaxChamberRatio = {}\n",
    "\n",
    "# h[k] = create_TH1D( cscRechitClusterMaxChamber[k], axis_title=['max chamber', 'Events'], name=k, binning=[200,-50,50])\n",
    "h[k] = create_TH1D( cscRechitClusterMaxChamberRatio[k], axis_title=['max chamber ratio', 'Events'], name=k, binning=[20,0,1])\n",
    "# h[k] = create_TH1D( cscClusterMet_dPhi[k], axis_title=['#Delta#phi(MET, cluster)', 'Events'], name=k, binning=[20,0,3.14])\n",
    "# h[k] = create_TH1D( n_chamber[k], axis_title=['Number of Chambers', 'Events'], name=k, binning=[10,0,10])\n",
    "# h[k] = create_TH1D( cscRechitClusterNStation[k], axis_title=['max station', 'Events'], name=k, binning=[5,0,5])\n",
    "# print(cscRechitClusterMaxStationRatio[k])\n",
    "# h[k] = create_TH1D( cscRechitClusterNStation[k], axis_title=['Number of station', 'Events'], name=k, binning=[20,0,10])\n",
    "\n",
    "\n",
    "# h['1jet'].GetXaxis().SetLabelSize(0.04)\n",
    "# h['1jet'].SetMinimum(0.1)\n",
    "# h['1jet'].SetMaximum(10E6/2)\n",
    "\n",
    "h[k].Draw('hist')\n",
    "\n",
    "\n",
    "c.SetRightMargin(0)\n",
    "c.SetLogy()\n",
    "\n",
    "c.Draw()\n",
    "# print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "#ROC curve\n",
    "c = rt.TCanvas('c','c', 800, 800)\n",
    "leg = rt.TLegend(0.35,0.80,0.85,0.92)\n",
    "leg.SetTextSize(0.022)\n",
    "leg.SetBorderSize(0)\n",
    "\n",
    "leg.SetEntrySeparation(0.01)\n",
    "\n",
    "var = [nCsc_JetMuonVetoCluster0p4_Me1112Veto,]\n",
    "name = ['nCsc_JetMuonVetoCluster0p4_Me1112Veto',]\n",
    "legend = [ 'jet & muon veto + ME11/12 veto',]\n",
    "\n",
    "bkg_k = 'data_oot'\n",
    "sig_k = 'mc_signal'\n",
    "br = 0.01\n",
    "\n",
    "threshold = list(range(300))\n",
    "threshold = np.array(list(range(2000)))\n",
    "# print(threshold)\n",
    "for i in range(len(var)):\n",
    "    event_count = {}\n",
    "    \n",
    "    for k in ['data_oot','mc_signal']:\n",
    "        event_count[k] = []\n",
    "        for th in threshold:\n",
    "            event_count[k].append(np.sum(weight[k][var[i][k]>th]))\n",
    "        event_count[k] = np.array(event_count[k])\n",
    "        if k == sig_k:\n",
    "            event_count[k] = event_count[k]*br\n",
    "    sig = event_count[sig_k]/np.sqrt(event_count[sig_k]+event_count[bkg_k])\n",
    "    cond = event_count[sig_k]>0\n",
    "    sig = sig[cond]\n",
    "    ncsc = threshold[cond]\n",
    "#     gr['bbbb'] = create_TGraph(eff_bkg,eff_sig,axis_title = ['#epsilon_{bkg}','#epsilon_{signal}'])\n",
    "    h[sig_k+str(i)] = create_TGraph(ncsc, sig,  axis_title=['N_{rechits}', 'Significnace'])\n",
    "#     h[sig_k+str(i)] = create_TGraph(ncsc, event_count[sig_k],  axis_title=['N_{rechits}', 'Event Yield'])\n",
    "\n",
    "    h[sig_k+str(i)].SetLineWidth(2)\n",
    "    h[sig_k+str(i)].SetMarkerColor(std_color_list[i])\n",
    "    h[sig_k+str(i)].SetLineColor(std_color_list[i])\n",
    "    h[sig_k+str(i)].GetXaxis().SetRangeUser(0, 3000)\n",
    "    h[sig_k+str(i)].GetXaxis().SetLabelSize(0.04)\n",
    "\n",
    "#     h[sig_k+str(i)].GetYaxis().SetRangeUser(0, 3)\n",
    "\n",
    "\n",
    "    leg.AddEntry(h[sig_k+str(i)],sig_k+\" \"+legend[i])\n",
    "    h[sig_k+str(i)].Draw('ac' if i == 0 else 'c')\n",
    "\n",
    "#     h[sig_k+str(i)].Draw('ac' if i==0 else 'c')\n",
    "#     gr['bbbb'].Draw('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# c.SetLogy()\n",
    "c.Draw()\n",
    "# c.SaveAs('../plots/timing_studies/compare_timing_definition_ROC.png')\n",
    "\n",
    "print(time.time()-start_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ncsc\n",
    "start_t = time.time()\n",
    "c = rt.TCanvas('c','c', 1000, 800)\n",
    "h = {}\n",
    "# leg = rt.TLegend(0.50,0.75,0.97,0.93)\n",
    "leg = rt.TLegend(0.58,0.70,0.94,0.85)\n",
    "leg.SetTextSize(0.022)\n",
    "# leg.SetTextFont(42)\n",
    "leg.SetEntrySeparation(0.01)\n",
    "\n",
    "i = 0\n",
    "k = 'data_intime'\n",
    "\n",
    "# h[k] = create_TH2D(np.column_stack((angle[k][cond],jetPt[k][cond][:,0])), axis_title = ['\\Delta\\phi (jet,met)','jet p_{T}[GeV]','Events'], binning=[80,-3.14,3.14,100,0,2000])\n",
    "h[k] = create_TH2D(np.column_stack(( nCsc_JetMuonVetoCluster0p4_Me1112Veto[k], dphiMet_cluster[k])),\n",
    "                   axis_title = ['N_{rechits}','\\Delta\\phi (cluster,met)','Events'], binning=[50,0,600,50,0,3.14])\n",
    "h[k] = create_TH2D(np.column_stack(( nCsc_JetMuonVetoCluster0p4_Me1112Veto[k], jetMet_dPhiMin4[k])),\n",
    "                   axis_title = ['N_{rechits}','min_{4jet}\\Delta\\phi (jet,met)','Events'], binning=[50,0,600,50,0,3.14])\n",
    "\n",
    "\n",
    "h[k].GetXaxis().SetLabelSize(0.04)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h[k].SetLineColor(std_color_list[i])\n",
    "# leg.AddEntry(h[k], k)\n",
    "#     h[k].SetMaximum(10E5)\n",
    "#     h[k].SetMinimum(1)\n",
    "h[k].Draw('colz')\n",
    "c.SetRightMargin(0.2)\n",
    "\n",
    "\n",
    "\n",
    "# if setlog: \n",
    "c.SetLogz()\n",
    "c.Draw()\n",
    "print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# event yield vs. ncsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
