{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master File for CMS Run 3 Level 1 Muon RoI Trigger Offline Studies\n",
    "\n",
    "# Coders: Nathan Suri, Caltech; Cristian Pena, Caltech/Fermilab\n",
    "# Date: July 2019\n",
    "# LPC LLP Group\n",
    "\n",
    "# Description\n",
    "# Compiled progress on offline trigger study for CMS Run 3 Level 1 Muon RoI Trigger\n",
    "\n",
    "# Action Plan\n",
    "# Understand phi granularity implementation\n",
    "\n",
    "# Notes/Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: nasurijr\n"
     ]
    }
   ],
   "source": [
    "# Setups pwd location for data files and imports of special ROOT utilities\n",
    "\n",
    "work_location = input(\"Username: \")\n",
    "if work_location == 'nasurijr':\n",
    "    pwd = '/nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/'\n",
    "# elif work_location == '<Insert Tier2 username here>':\n",
    "#     pwd = '/home/cms/delayed_jet_analyzer/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports necessary utilities and modules\n",
    "\n",
    "import ROOT as rt\n",
    "import root_numpy as rtnp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter \n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "# Graph/histo utilities from ROOT\n",
    "# Contained within the delayed_jet_analyzer repository\n",
    "import sys\n",
    "sys.path.append(pwd+'lib')\n",
    "from histo_utilities import create_TH1D, create_TH2D, create_TGraph, std_color_list\n",
    "\n",
    "# Used for extracting the TTree structure from each datafile\n",
    "import os\n",
    "import uproot\n",
    "\n",
    "# Sets display width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "\n",
    "# Imports jet clustering algorithm (FastJet)\n",
    "from pyjet import cluster\n",
    "\n",
    "\n",
    "donotdelete = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Extract TTrees from Datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-30 13:57:58.958241-07:00\n",
      "qcd /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/jet_timing_studies_ntuple_RunIIFall17DRPremix_QCD_Pt_170to300_TuneCP5_13TeV_pythia8_1.root\n",
      "2019-08-30 13:57:59.619567-07:00\n",
      "zeroBias /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/jet_timing_studies_ZeroBias_Run2018B_112_dec.root\n",
      "2019-08-30 13:58:00.287680-07:00\n",
      "WJetsToLNu /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/jet_timing_studies_ntuple_RunIIFall17DRPremix_WJetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8.root\n",
      "2019-08-30 13:58:00.783152-07:00\n",
      "m50ct1000mm /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/jet_timing_studies_ntuple_metbb_ggh_ISR_mh125_mx50_pl1000_ev100000.root\n",
      "2019-08-30 13:58:01.321517-07:00\n",
      "m50ct10000mm /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/jet_timing_studies_ntuple_metbb_ggh_ISR_mh125_mx50_pl10000_ev100000.root\n",
      "2019-08-30 13:58:01.728785-07:00\n",
      "m975ct1000mm /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/jet_timing_studies_ntuple_metbb_ggh_ISR_mh2000_mx975_pl1000_ev100000.root\n",
      "2019-08-30 13:58:02.129862-07:00\n",
      "m975ct10000mm /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/jet_timing_studies_ntuple_metbb_ggh_ISR_mh2000_mx975_pl10000_ev100000.root\n",
      "2019-08-30 13:58:02.628062-07:00\n",
      "l1_nik_m50ct1000mm /nfshome/nasurijr/LLP_analysis/delayed_jet_analyzer/data/EMTF_ppTohToSS1SS2_SS1Tobb_SS2Tobb_ggh_withISR.root\n"
     ]
    }
   ],
   "source": [
    "# Setups dictionaries for storing data from MC/data ntuples\n",
    "fpath = {}\n",
    "tree = {}\n",
    "\n",
    "data_path = pwd+'data/'\n",
    "\n",
    "# Background Samples\n",
    "fpath['qcd'] = data_path +'jet_timing_studies_ntuple_RunIIFall17DRPremix_QCD_Pt_170to300_TuneCP5_13TeV_pythia8_1.root'\n",
    "\n",
    "# Small subset of B samples for quick runs/tests\n",
    "fpath['zeroBias'] = data_path + 'jet_timing_studies_ZeroBias_Run2018B_112_dec.root'\n",
    "# # Complete set of A and B ZeroBias samples (time-intensive to run)\n",
    "# fpath['zeroBias'] = data_path + 'jet_timing_studies_ZeroBias_Run2018AB_complete.root'\n",
    "\n",
    "# WH-comparable background: WJetsToLNu\n",
    "fpath['WJetsToLNu'] = data_path + 'jet_timing_studies_ntuple_RunIIFall17DRPremix_WJetsToLNu_TuneCP5_13TeV-madgraphMLM-pythia8.root'\n",
    "\n",
    "################################################################\n",
    "\n",
    "# Signal Samples\n",
    "# mH = 125 GeV, mX = 50 GeV, ctau = 1 m\n",
    "fpath['m50ct1000mm'] = data_path+'jet_timing_studies_ntuple_metbb_ggh_ISR_mh125_mx50_pl1000_ev100000.root'\n",
    "\n",
    "# mH = 125 GeV, mX = 50 GeV, ctau = 10 m\n",
    "fpath['m50ct10000mm'] = data_path+'jet_timing_studies_ntuple_metbb_ggh_ISR_mh125_mx50_pl10000_ev100000.root'\n",
    "\n",
    "# mH = 2000 GeV, mX = 975 GeV, ctau = 1 m\n",
    "fpath['m975ct1000mm'] = data_path+'jet_timing_studies_ntuple_metbb_ggh_ISR_mh2000_mx975_pl1000_ev100000.root'\n",
    "\n",
    "# mH = 2000 GeV, mX = 975 GeV, ctau = 10 m\n",
    "fpath['m975ct10000mm'] = data_path+'jet_timing_studies_ntuple_metbb_ggh_ISR_mh2000_mx975_pl10000_ev100000.root'\n",
    "\n",
    "fpath['l1_nik_m50ct1000mm'] = data_path+'EMTF_ppTohToSS1SS2_SS1Tobb_SS2Tobb_ggh_withISR.root'\n",
    "\n",
    "# Iterates through each file and extracts the ROOT TTree structure from each\n",
    "for k,v in fpath.items():\n",
    "    print(str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "    print(k, v)\n",
    "    root_dir = uproot.open(v)\n",
    "    if k == 'l1_nik_m50ct1000mm':\n",
    "        tree[k] = root_dir['FlatNtupleMC']['tree']\n",
    "    else:\n",
    "        tree[k] = root_dir['ntuples']['llp']\n",
    "#     print(root_dir['ntuples']['NEvents'][1])\n",
    "    # Accesses the array form of the jetPt branch\n",
    "#     a = tree[k][\"jetPt\"].array()\n",
    "#     print(a[:-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name TTree Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bookkeeping: Defines the TTrees from the read datafiles\n",
    "# Names displayed in README.md table\n",
    "\n",
    "T = tree['m50ct1000mm']\n",
    "T_bkg = tree['qcd']\n",
    "T_minBias = tree['zeroBias']\n",
    "T_low_ctau10 = tree['m50ct10000mm']\n",
    "T_high_ctau1 = tree['m975ct1000mm']\n",
    "T_high_ctau10 = tree['m975ct10000mm']\n",
    "T_l1 = tree['l1_nik_m50ct1000mm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables and Name Datafiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Definitions\n",
    "# Creates dictionaries for variables to be analyzed\n",
    "# The dictionaries will contain the variable arrays for each datafile with a relevant key\n",
    "\n",
    "# CSC\n",
    "nCsc = {}\n",
    "csc_z = {}\n",
    "csc_x = {}\n",
    "csc_y = {}\n",
    "csc_eta = {}\n",
    "csc_phi = {}\n",
    "# Gen Level\n",
    "gLLP_eta = {}\n",
    "gLLP_r = {}\n",
    "gLLP_decay = {}\n",
    "eventNum_endcap = {}\n",
    "lumiNum_endcap = {}\n",
    "eventNum_barrel = {}\n",
    "lumiNum_barrel = {}\n",
    "eventNum_bkg = {}\n",
    "lumiNum_bkg = {}\n",
    "ncsc_barrel = {}\n",
    "gLLPr = {}\n",
    "\n",
    "# Drift Tube (DT)\n",
    "nDt = {}\n",
    "dt_phi = {}\n",
    "dt_eta = {}\n",
    "dt_z = {}\n",
    "dt_x = {}\n",
    "dt_y = {}\n",
    "# RPC\n",
    "nRpc = {}\n",
    "rpc_phi = {}\n",
    "rpc_eta = {}\n",
    "rpc_z = {}\n",
    "rpc_x = {}\n",
    "rpc_y = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bookkeeping: Creates a dictionary for iterating over all of the datafiles and \n",
    "#              converting the relevant branches to numpy arrays\n",
    "# Names displayed in README.md table\n",
    "\n",
    "data_trees = {'m50ct1m': T, 'qcd': T_bkg, 'zeroBias':T_minBias, 'm50ct10m': T_low_ctau10, 'm975ct1m': T_high_ctau1, 'm975ct10m': T_high_ctau10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBranch -> np.array() Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2019-08-30 13:58:03.575140-07:00\n",
      "m50ct1m: 2019-08-30 13:58:04.629534-07:00\n",
      "qcd: 2019-08-30 13:58:05.896163-07:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-5b5ce03849fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_trees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mgLLP_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gLLP_decay_vertex_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gLLP_decay_vertex_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mgLLP_decay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gLLP_decay_vertex_x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gLLP_decay_vertex_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marbor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gLLP_decay_vertex_z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(self, interpretation, entrystart, entrystop, flatten, awkwardlib, cache, basketcache, keycache, executor, blocking)\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mkeycache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         \u001b[0mbasket_itemoffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_basket_itemoffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpretation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeycache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0mbasket_entryoffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_basket_entryoffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasketstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36m_basket_itemoffset\u001b[0;34m(self, interpretation, basketstart, basketstop, keycache)\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_basket_itemoffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeycache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0mbasket_itemoffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threadsafe_iterate_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeycache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasketstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasketstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mnumitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasket_numentries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36m_threadsafe_iterate_keys\u001b[0;34m(self, keycache, complete, basketstart, basketstop)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeycache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mkeycache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keycachekey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomplete\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"border\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_basketkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeysource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mkeycache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m                             \u001b[0mkeycache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keycachekey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36m_basketkey\u001b[0;34m(self, source, i, complete)\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_basketkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numgoodbaskets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BasketKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fBasketSeek\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numgoodbaskets\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumbaskets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/uproot/tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, cursor, compression, complete)\u001b[0m\n\u001b[1;32m   1596\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fNbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fVersion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fObjlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fDatime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fKeylen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fCycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fSeekKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fSeekPdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTBranchMethods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BasketKey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fVersion\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/uproot/source/cursor.py\u001b[0m in \u001b[0;36mfields\u001b[0;34m(self, source, format)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Event Selection\n",
    "\n",
    "print('Start: ' + str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "\n",
    "# MET+bb Final State\n",
    "if 'metbb' in fpath['m50ct1000mm']:\n",
    "    for species, arbor in data_trees.items():\n",
    "        \n",
    "        gLLP_r[species] = np.sqrt((arbor['gLLP_decay_vertex_x'].array()[:,0])**2+(arbor['gLLP_decay_vertex_y'].array()[:,0])**2)\n",
    "        gLLP_decay[species] = np.sqrt((arbor['gLLP_decay_vertex_x'].array()[:,0])**2+(arbor['gLLP_decay_vertex_y'].array()[:,0])**2 + (arbor['gLLP_decay_vertex_z'].array()[:,0])**2)\n",
    "        \n",
    "        # Endcap Signal Event Selection: Requires that the bb-decaying LLP decays within the endcap of the muon system        \n",
    "        sel_csc = np.logical_and(np.absolute(arbor['gLLP_decay_vertex_z'].array()[:,0]) > 568 , np.absolute(arbor['gLLP_decay_vertex_z'].array()[:,0]) < 1100)\n",
    "        sel_csc = np.logical_and(sel_csc, np.absolute(arbor['gLLP_eta'].array()[:,0])<2.4)\n",
    "        sel_csc = np.logical_and(sel_csc, np.absolute(arbor['gLLP_eta'].array()[:,0])>0.9)\n",
    "        sel_csc = np.logical_and(sel_csc, np.absolute(gLLP_r[species])<695.5)\n",
    "\n",
    "        # Barrel Signal Event Selection: Requires that the bb-decaying LLP decays within the barrel of the muon system        \n",
    "        sel_barrel = np.logical_and(np.absolute(arbor['gLLP_decay_vertex_z'].array()[:,0]) > -661 , np.absolute(arbor['gLLP_decay_vertex_z'].array()[:,0]) < 661)\n",
    "        sel_barrel = np.logical_and(sel_barrel, np.absolute(gLLP_r[species])<738)\n",
    "        sel_barrel = np.logical_and(sel_barrel, np.absolute(gLLP_r[species])>380)\n",
    "\n",
    "        # Overlap Signal Event Selection: Requires that the bb-decaying LLP decays within the overlap of the barrel\n",
    "        #                                 and endcap of the muon system\n",
    "        sel_rpc = np.logical_and(np.absolute(arbor['gLLP_decay_vertex_z'].array()[:,0]) > 0 , np.absolute(arbor['gLLP_decay_vertex_z'].array()[:,0]) < 1100)\n",
    "        sel_rpc = np.logical_and(sel_rpc, np.absolute(arbor['gLLP_eta'].array()[:,0])<1.6)\n",
    "        sel_rpc = np.logical_and(sel_rpc, np.absolute(gLLP_r[species])<738)\n",
    "        sel_rpc = np.logical_and(sel_rpc, np.absolute(gLLP_r[species])>275)\n",
    "\n",
    "        # Total Muon System Signal Event Selection: Logical or of barrel and endcap gen-level restrictions\n",
    "        sel_dis_signal = np.logical_or(sel_csc, sel_barrel)\n",
    "\n",
    "        if 'vh' in fpath['m50ct1000mm']:\n",
    "            # Basic implementation: Loop through files and compile Boolean array with 1 muon/electron\n",
    "            mu = np.logical_and(np.logical_and(np.absolute(gParticleId[ev]) == 13, np.absolute(gParticleMotherId[ev]) == 24), gParticleStatus[ev] == 1 )\n",
    "            ele = np.logical_and(np.logical_and(np.absolute(gParticleId[ev]) == 11, np.absolute(gParticleMotherId[ev]) == 24), gParticleStatus[ev] == 1 )\n",
    "            if not ((np.count_nonzero(mu) ==1 or np.count_nonzero(ele)==1)): continue\n",
    "        \n",
    "        # Converts variable branches to numpy arrays with event selection\n",
    "        # Signal conversions\n",
    "        if species in ('m50ct1m', 'm50ct10m', 'm975ct1m', 'm975ct10m'):\n",
    "            # Endcap: CSCs\n",
    "            nCsc[species] = arbor['nCsc'].array()[sel_csc]\n",
    "            csc_z[species] = arbor['cscZ'].array()[sel_csc]\n",
    "            csc_x[species] = arbor['cscX'].array()[sel_csc]\n",
    "            csc_y[species] = arbor['cscY'].array()[sel_csc]\n",
    "            csc_eta[species] = arbor['cscEta'].array()[sel_csc]\n",
    "            csc_phi[species] = arbor['cscPhi'].array()[sel_csc]\n",
    "            \n",
    "            # Gen-level\n",
    "            gLLP_eta[species] = arbor['gLLP_eta'].array()[:,0][sel_csc]\n",
    "            eventNum_endcap[species] = arbor['eventNum'].array()[sel_csc]\n",
    "            lumiNum_endcap[species] = arbor['lumiNum'].array()[sel_csc]\n",
    "            \n",
    "            eventNum_barrel[species] = arbor['eventNum'].array()[sel_barrel]\n",
    "            lumiNum_barrel[species] = arbor['lumiNum'].array()[sel_barrel]\n",
    "            gLLPr[species] = gLLP_r[species][sel_barrel]\n",
    "            ncsc_barrel = arbor['nCsc'].array()[sel_barrel]\n",
    "            \n",
    "            # Barrel: DTs\n",
    "            nDt[species] = arbor['nDt'].array()[sel_barrel]\n",
    "            dt_z[species] = arbor['dtZ'].array()[sel_barrel]\n",
    "            dt_x[species] = arbor['dtX'].array()[sel_barrel]\n",
    "            dt_y[species] = arbor['dtY'].array()[sel_barrel]\n",
    "            dt_eta[species] = arbor['dtEta'].array()[sel_barrel]\n",
    "            dt_phi[species] = arbor['dtPhi'].array()[sel_barrel]\n",
    "            \n",
    "            # Overlap: RPCs\n",
    "            nRpc[species] = arbor['nRpc'].array()[sel_rpc]\n",
    "            rpc_z[species] = arbor['rpcZ'].array()[sel_rpc]\n",
    "            rpc_x[species] = arbor['rpcX'].array()[sel_rpc]\n",
    "            rpc_y[species] = arbor['rpcY'].array()[sel_rpc]\n",
    "            rpc_eta[species] = arbor['rpcEta'].array()[sel_rpc]\n",
    "            rpc_phi[species] = arbor['rpcPhi'].array()[sel_rpc]\n",
    "        \n",
    "        # Background conversions\n",
    "        if species in ('qcd', 'zeroBias'):\n",
    "            sel_bkg = np.ones(len(arbor['nCsc'].array()), dtype=bool)\n",
    "            \n",
    "            # Endcap: CSCs\n",
    "            nCsc[species] = arbor['nCsc'].array()[sel_bkg]\n",
    "            csc_z[species] = arbor['cscZ'].array()[sel_bkg]\n",
    "            csc_x[species] = arbor['cscX'].array()[sel_bkg]\n",
    "            csc_y[species] = arbor['cscY'].array()[sel_bkg]\n",
    "            csc_eta[species] = arbor['cscEta'].array()[sel_bkg]\n",
    "            csc_phi[species] = arbor['cscPhi'].array()[sel_bkg]\n",
    "            gLLP_eta[species] = arbor['gLLP_eta'].array()[:,0][sel_bkg]\n",
    "            \n",
    "            # Gen-level\n",
    "            eventNum_bkg[species] = arbor['eventNum'].array()[sel_bkg]\n",
    "            lumiNum_bkg[species] = arbor['lumiNum'].array()[sel_bkg]\n",
    "            \n",
    "            # Barrel: DTs\n",
    "            nDt[species] = arbor['nDt'].array()[sel_bkg]\n",
    "            dt_z[species] = arbor['dtZ'].array()[sel_bkg]\n",
    "            dt_x[species] = arbor['dtX'].array()[sel_bkg]\n",
    "            dt_y[species] = arbor['dtY'].array()[sel_bkg]\n",
    "            dt_eta[species] = arbor['dtEta'].array()[sel_bkg]\n",
    "            dt_phi[species] = arbor['dtPhi'].array()[sel_bkg]\n",
    "            \n",
    "            # Overlap: RPCs\n",
    "            nRpc[species] = arbor['nRpc'].array()[sel_bkg]\n",
    "            rpc_z[species] = arbor['rpcZ'].array()[sel_bkg]\n",
    "            rpc_x[species] = arbor['rpcX'].array()[sel_bkg]\n",
    "            rpc_y[species] = arbor['rpcY'].array()[sel_bkg]\n",
    "            rpc_eta[species] = arbor['rpcEta'].array()[sel_bkg]\n",
    "            rpc_phi[species] = arbor['rpcPhi'].array()[sel_bkg]\n",
    "        \n",
    "        print(species + ': ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Trigger Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCsc['l1_m50ct1m'] = T_l1['nHits'].array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Moment Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pt_csc = {}\n",
    "fake_mass_csc = {}\n",
    "\n",
    "print('Start: ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "\n",
    "for species in data_trees.keys():\n",
    "    event_empty = np.copy(csc_z[species])*(-999)\n",
    "    fake_pt_csc[species] = event_empty\n",
    "    fake_mass_csc[species] = event_empty\n",
    "    \n",
    "    print(species + ': ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dataset = {}\n",
    "\n",
    "print('Start: ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "\n",
    "for species in data_trees.keys():\n",
    "    cluster_dataset[species] = np.dstack((fake_pt_csc[species], csc_eta[species], csc_phi[species], fake_mass_csc[species], csc_z[species]))\n",
    "\n",
    "    print(species + ': ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc_clusters = {}\n",
    "ncsc_cluster = {}\n",
    "eta_max_cluster = {}\n",
    "\n",
    "print('Start: ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "\n",
    "for species in data_trees.keys():\n",
    "    csc_clusters[species] = []\n",
    "    ncsc_cluster[species] = []\n",
    "    eta_max_cluster[species] = []\n",
    "    for hit_seq in range(len(csc_z[species])):\n",
    "#         event_clusters = []\n",
    "        test_data_0 = np.dstack(cluster_dataset[species][0][hit_seq])[0].astype(np.float64)\n",
    "        test_data_0 = np.core.records.fromarrays(test_data_0.transpose(), names='pT, eta, phi, mass, z_pos', formats = 'f8, f8, f8, f8, f8')\n",
    "        sequence_0 = cluster(test_data_0, R=0.4, p=0)\n",
    "        jets = sequence_0.inclusive_jets()\n",
    "#         event_clusters.append(jets)\n",
    "#         csc_clusters[species].append(event_clusters)\n",
    "        csc_clusters[species].append(jets)\n",
    "\n",
    "        total_hits = 0\n",
    "        for cluster_hits in range(len(jets)):\n",
    "            if len(jets[cluster_hits].constituents_array()) > 3:\n",
    "                total_hits += len(jets[cluster_hits].constituents_array())\n",
    "        ncsc_cluster[species].append(total_hits)\n",
    "        \n",
    "        if len(jets) == 0:\n",
    "            continue\n",
    "        max_pop_index = np.where(np.max(len(jets)))\n",
    "        \n",
    "        eta_max_cluster[species].append(jets[max_pop_index[0][0]].constituents_array()['eta'])\n",
    "    \n",
    "    print(species + ': '+  str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_phi(phi_array):\n",
    "    moment_2 = []\n",
    "    for event in phi_array:\n",
    "        avg_phi = np.mean(event)\n",
    "        moment_array = []\n",
    "        for segment in event:\n",
    "            moment = (segment-avg_phi)**2\n",
    "            moment_array.append(moment)\n",
    "        moment_2.append(np.sum(moment_array))\n",
    "    return moment_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_2_phi = {}\n",
    "for species in data_trees.keys():\n",
    "    moment_2_phi[species] = []\n",
    "    moment_2_phi[species].append(moment_phi(eta_max_cluster[species]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizes phi spread of most populated cluster\n",
    "\n",
    "c_phi = rt.TCanvas('c_phi','c_phi', 800, 600)\n",
    "\n",
    "h={}\n",
    "h['signal_phi'] = create_TH1D(moment_2_phi['m50ct1m'][0], axis_title=['signal_phi', 'Events'], name='signal_phi', binning=[100,0,6.3])\n",
    "h['signal_phi'].SetLineColor(4)\n",
    "\n",
    "\n",
    "h['bkg_phi'] = create_TH1D(moment_2_phi['zeroBias'][0], axis_title=['bkg_phi', 'Events'], name='bkg_phi', binning=[100,0,6.3])\n",
    "h['bkg_phi'].SetLineColor(2)\n",
    "\n",
    "c_phi.SetLogy()\n",
    "\n",
    "h['signal_phi'].SetLineWidth(2)\n",
    "h['bkg_phi'].SetLineWidth(2)\n",
    "\n",
    "# h['bkg_phi'].GetYaxis().SetRangeUser(1,10**10)\n",
    "h['bkg_phi'].GetXaxis().SetRangeUser(0,6.3)\n",
    "\n",
    "\n",
    "h['bkg_phi'].SetStats(0)\n",
    "h['bkg_phi'].SetTitle(\"CSC Inclusive (ggH #rightarrow MET + bb)\")\n",
    "h['bkg_phi'].SetXTitle(\"m_{#phi}\")\n",
    "\n",
    "\n",
    "h['bkg_phi'].Draw('histo')\n",
    "h['signal_phi'].Draw('histo+same')\n",
    "\n",
    "\n",
    "legend = rt.TLegend(0.48,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "legend.AddEntry( h['signal_phi'], \"ggH Second Moment\" , \"L\");\n",
    "legend.AddEntry( h['bkg_phi'], \"zeroBias Second Moment\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c_phi.Draw()\n",
    "\n",
    "# c.SaveAs(\"ncsc_inclusive_mc_zeroBias.pdf\")\n",
    "# c.SaveAs(\"ncsc_inclusive_mc_zeroBias.C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endcap Hit Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit Removal\n",
    "# For both the endcap and barrel regions (overlap to be determined), the closest stations to the beamspot are the noisiest.\n",
    "# Thus, we remove the hits that land in these stations for each event in each datafile.\n",
    "\n",
    "# Endcap\n",
    "nCsc_station = {}\n",
    "nCsc_removal = {}\n",
    "\n",
    "# Loops over every datafile\n",
    "for files in data_trees.keys():\n",
    "    # Endcap\n",
    "    nCsc_station[files] = {}\n",
    "    nCsc_station[files]['ME_11'] = []\n",
    "    nCsc_station[files]['ME_12'] = []\n",
    "    nCsc_station[files]['ME_13'] = []\n",
    "    \n",
    "    # Loops over every event in each datafile\n",
    "    for pos_bool in range(len(csc_z[files])):\n",
    "        csc_r = np.sqrt(csc_x[files][pos_bool]**2+csc_y[files][pos_bool]**2)\n",
    "        z_pos_bool = csc_z[files][pos_bool]\n",
    "        \n",
    "        counter_me11 = 0\n",
    "        counter_me12 = 0\n",
    "        counter_me13 = 0\n",
    "        \n",
    "        # Loops over every hit in each event\n",
    "        for z_ind in range(len(z_pos_bool)):\n",
    "            z_bool = np.absolute(z_pos_bool[z_ind])\n",
    "            # ME 1/1 Constraints\n",
    "            if z_bool > 568 and z_bool < 632:\n",
    "                counter_me11 += 1\n",
    "                \n",
    "            if z_bool > 663 and z_bool < 724:\n",
    "                # ME 1/2 Constraints\n",
    "                if csc_r[z_ind] < 465 and csc_r[z_ind] > 275:\n",
    "                    counter_me12 += 1\n",
    "                # ME 1/3 Constraints\n",
    "                if csc_r[z_ind] < 695.5 and csc_r[z_ind] > 505.5:\n",
    "                    counter_me13 += 1\n",
    "                    \n",
    "        nCsc_station[files]['ME_11'].append(counter_me11)\n",
    "        nCsc_station[files]['ME_12'].append(counter_me12)\n",
    "        nCsc_station[files]['ME_13'].append(counter_me13)\n",
    "    \n",
    "    # nCsc dictionaries containing hits removed labelled by removed stations\n",
    "    nCsc_removal[files] = {}\n",
    "    nCsc_removal[files]['ME_11'] = np.array(nCsc[files]) - np.array(nCsc_station[files]['ME_11'])\n",
    "    nCsc_removal[files]['ME_112'] = np.array(nCsc[files]) - (np.array(nCsc_station[files]['ME_11']) + np.array(nCsc_station[files]['ME_12']))\n",
    "    nCsc_removal[files]['ME_1123'] = np.array(nCsc[files]) - (np.array(nCsc_station[files]['ME_11']) + np.array(nCsc_station[files]['ME_12']) + np.array(nCsc_station[files]['ME_13']))\n",
    "    \n",
    "    print(files + ': ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nCsc['m50ct10m']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hit Selection based on Phi Granularity\n",
    "\n",
    "pg_ncsc = {}\n",
    "pg_ncsc_noME11 = {}\n",
    "pg_ncsc_noME112 = {}\n",
    "pg_ncsc_noME1123 = {}\n",
    "\n",
    "print('Start: ' + str(datetime.datetime.now(pytz.timezone('US/Pacific'))))\n",
    "\n",
    "for species in data_trees.keys():\n",
    "    pg_ncsc[species] = []\n",
    "    pg_ncsc_noME11[species] = []\n",
    "    pg_ncsc_noME112[species] = []\n",
    "    pg_ncsc_noME1123[species] = []\n",
    "    \n",
    "    for event in range(len(csc_z[species])):\n",
    "        cscR = np.sqrt(csc_x[species][event]**2+csc_y[species][event]**2)\n",
    "        cscZ = csc_z[species][event]\n",
    "        cscPhi = csc_phi[species][event] * (180/np.pi)\n",
    "        \n",
    "        pg_me11 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me12 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me13 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me21 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me22 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me31 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me32 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me41 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        pg_me42 = {'sectors':np.zeros(36), 'counter':0}\n",
    "        \n",
    "        \n",
    "        for zIndex in range(len(cscZ)):\n",
    "            hit_z = np.absolute(cscZ[zIndex])\n",
    "            hit_phi = cscPhi[zIndex]\n",
    "            hit_r = cscR[zIndex]\n",
    "            \n",
    "            # ME 1/1\n",
    "            if hit_z > 568 and hit_z < 632:\n",
    "                index = int((hit_phi+180)/10.0)\n",
    "                pg_me11['sectors'][index - 1] += 1\n",
    "\n",
    "#             # ME 1/2 and ME 1/3\n",
    "            if hit_z > 663 and hit_z < 724:\n",
    "                if hit_r < 465 and hit_r > 275:\n",
    "                    index = int((hit_phi+180)/10.0)\n",
    "                    pg_me12['sectors'][index - 1] += 1\n",
    "                if hit_r < 695.5 and hit_r > 505.5:\n",
    "                    index = int((hit_phi+180)/10.0)\n",
    "                    pg_me13['sectors'][index - 1] += 1\n",
    "    \n",
    "            # ME 2/1 and ME 2/2\n",
    "            if hit_z > 791 and hit_z < 849.5:\n",
    "                if hit_r < 345 and hit_r > 138.5:\n",
    "                    index = int((hit_phi+180)/20.0)\n",
    "                    pg_me21['sectors'][index - 1] += 1\n",
    "                if hit_r < 695.5 and hit_r > 357.5:\n",
    "                    index = int((hit_phi+180)/10.0)\n",
    "                    pg_me22['sectors'][index - 1] += 1\n",
    "\n",
    "            # ME 3/1 and ME 3/2\n",
    "            if hit_z > 911.5 and hit_z < 970:\n",
    "                if hit_r < 345 and hit_r > 160.5:\n",
    "                    index = int((hit_phi+180)/20.0)\n",
    "                    pg_me31['sectors'][index - 1] += 1\n",
    "                if hit_r < 695.5 and hit_r > 357.5:\n",
    "                    index = int((hit_phi+180)/10.0)\n",
    "                    pg_me32['sectors'][index - 1] += 1\n",
    "                \n",
    "            # ME 4/1 and ME 4/2\n",
    "            if hit_z > 1002 and hit_z < 1060.5:\n",
    "                if hit_r < 345 and hit_r > 177.5:\n",
    "                    index = int((hit_phi+180)/20.0)\n",
    "                    pg_me41['sectors'][index - 1] += 1\n",
    "                if hit_r < 695.5 and hit_r > 357.5:\n",
    "                    index = int((hit_phi+180)/10.0)\n",
    "                    pg_me42['sectors'][index - 1] += 1\n",
    "                    \n",
    "        pg_me11['counter'] += np.count_nonzero(pg_me11['sectors'])\n",
    "        pg_me12['counter'] += np.count_nonzero(pg_me12['sectors'])\n",
    "        pg_me13['counter'] += np.count_nonzero(pg_me13['sectors'])\n",
    "        pg_me21['counter'] += np.count_nonzero(pg_me21['sectors'])\n",
    "        pg_me22['counter'] += np.count_nonzero(pg_me22['sectors'])\n",
    "        pg_me31['counter'] += np.count_nonzero(pg_me31['sectors'])\n",
    "        pg_me32['counter'] += np.count_nonzero(pg_me32['sectors'])\n",
    "        pg_me41['counter'] += np.count_nonzero(pg_me41['sectors'])\n",
    "        pg_me42['counter'] += np.count_nonzero(pg_me42['sectors'])\n",
    "        \n",
    "#         print(pg_me11['sectors'])\n",
    "#         print(np.count_nonzero(pg_me11['sectors']))\n",
    "#         print(np.where(pg_me11['sectors'] >= 2)[0].size)\n",
    "        \n",
    "#         break\n",
    "\n",
    "        pg_me11['counter'] += np.where(pg_me11['sectors'] >= 2)[0].size\n",
    "        pg_me12['counter'] += np.where(pg_me12['sectors'] >= 2)[0].size\n",
    "        pg_me13['counter'] += np.where(pg_me13['sectors'] >= 2)[0].size\n",
    "        pg_me21['counter'] += np.where(pg_me21['sectors'] >= 2)[0].size\n",
    "        pg_me22['counter'] += np.where(pg_me22['sectors'] >= 2)[0].size\n",
    "        pg_me31['counter'] += np.where(pg_me31['sectors'] >= 2)[0].size\n",
    "        pg_me32['counter'] += np.where(pg_me32['sectors'] >= 2)[0].size\n",
    "        pg_me41['counter'] += np.where(pg_me41['sectors'] >= 2)[0].size\n",
    "        pg_me42['counter'] += np.where(pg_me42['sectors'] >= 2)[0].size\n",
    "        \n",
    "\n",
    "        cscSum_inclusive = pg_me11['counter'] + pg_me12['counter'] + pg_me13['counter'] + pg_me21['counter'] + pg_me22['counter'] + pg_me31['counter'] + pg_me32['counter'] + pg_me41['counter'] + pg_me42['counter']\n",
    "        cscSum_noME11 = pg_me12['counter'] + pg_me13['counter'] + pg_me21['counter'] + pg_me22['counter'] + pg_me31['counter'] + pg_me32['counter'] + pg_me41['counter'] + pg_me42['counter']\n",
    "        cscSum_noME112 = pg_me13['counter'] + pg_me21['counter'] + pg_me22['counter'] + pg_me31['counter'] + pg_me32['counter'] + pg_me41['counter'] + pg_me42['counter']\n",
    "        cscSum_noME1123 = pg_me21['counter'] + pg_me22['counter'] + pg_me31['counter'] + pg_me32['counter'] + pg_me41['counter'] + pg_me42['counter']\n",
    "        \n",
    "        pg_ncsc[species].append(cscSum_inclusive)\n",
    "        pg_ncsc_noME11[species].append(cscSum_noME11)\n",
    "        pg_ncsc_noME112[species].append(cscSum_noME112)\n",
    "        pg_ncsc_noME1123[species].append(cscSum_noME1123)\n",
    "        \n",
    "    print(species + ': ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares L1 trigger primitives to translated reco variable\n",
    "\n",
    "c_pg = rt.TCanvas('c_pg','c_pg', 800, 600)\n",
    "\n",
    "h['reco_inc'] = create_TH1D(pg_ncsc['m50ct1m'], axis_title=['reco_inc', 'Events'], name='reco_inc', binning=[100,0,200])\n",
    "h['reco_inc'].SetLineColor(4)\n",
    "h['reco_inc'].SetLineStyle(1)\n",
    "\n",
    "h['reco_bkg'] = create_TH1D(pg_ncsc['qcd'], axis_title=['reco_bkg', 'Events'], name='reco_bkg', binning=[100,0,200])\n",
    "h['reco_bkg'].SetLineColor(2)\n",
    "h['reco_bkg'].SetLineStyle(1)\n",
    "\n",
    "\n",
    "h['reco_no11'] = create_TH1D(pg_ncsc_noME11['m50ct1m'], axis_title=['reco_no11', 'Events'], name='reco_no11', binning=[100,0,200])\n",
    "h['reco_no11'].SetLineColor(1)\n",
    "h['reco_no11'].SetLineStyle(1)\n",
    "\n",
    "h['reco_no112'] = create_TH1D(pg_ncsc_noME112['m50ct1m'], axis_title=['reco_no112', 'Events'], name='reco_no112', binning=[100,0,200])\n",
    "h['reco_no112'].SetLineColor(6)\n",
    "h['reco_no112'].SetLineStyle(1)\n",
    "\n",
    "h['reco_no1123'] = create_TH1D(pg_ncsc_noME1123['m50ct1m'], axis_title=['reco_no1123', 'Events'], name='reco_no1123', binning=[100,0,200])\n",
    "h['reco_no1123'].SetLineColor(8)\n",
    "h['reco_no1123'].SetLineStyle(1)\n",
    "\n",
    "\n",
    "h['l1_inc'] = create_TH1D(nCsc['l1_m50ct1m'], axis_title=['l1_inc', 'Events'], name='l1_inc', binning=[100,0,200])\n",
    "h['l1_inc'].SetLineColor(4)\n",
    "h['l1_inc'].SetLineStyle(2)\n",
    "\n",
    "c_pg.SetLogy()\n",
    "\n",
    "h['reco_inc'].SetLineWidth(2)\n",
    "h['reco_no11'].SetLineWidth(2)\n",
    "h['reco_no112'].SetLineWidth(2)\n",
    "h['reco_no1123'].SetLineWidth(2)\n",
    "h['l1_inc'].SetLineWidth(2)\n",
    "h['reco_bkg'].SetLineWidth(2)\n",
    "\n",
    "h['reco_inc'].GetYaxis().SetRangeUser(1,10**5)\n",
    "h['reco_inc'].GetXaxis().SetRangeUser(0,55)\n",
    "\n",
    "\n",
    "h['reco_inc'].SetStats(0)\n",
    "h['reco_inc'].SetTitle(\"Phi Granularity (ggH #rightarrow MET + bb)\")\n",
    "h['reco_inc'].SetXTitle(\"N_{CSC/LCT}\")\n",
    "\n",
    "\n",
    "h['reco_inc'].Draw('histo')\n",
    "h['reco_no11'].Draw('histo+same')\n",
    "h['reco_no112'].Draw('histo+same')\n",
    "h['reco_no1123'].Draw('histo+same')\n",
    "h['l1_inc'].Draw('histo+same')\n",
    "h['reco_bkg'].Draw('histo+same')\n",
    "\n",
    "\n",
    "\n",
    "# legend = rt.TLegend(0.48,0.70,0.87,0.87);\n",
    "legend = rt.TLegend(0.6,0.60,0.6,0.6);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "legend.AddEntry( h['reco_inc'], \"ggH Inclusive\" , \"L\");\n",
    "legend.AddEntry( h['reco_no11'], \"ggH w/o ME 11\" , \"L\");\n",
    "legend.AddEntry( h['reco_no112'], \"ggH w/o ME 11+12\" , \"L\");\n",
    "legend.AddEntry( h['reco_no1123'], \"ggH w/o ME 11+12+13\" , \"L\");\n",
    "legend.AddEntry( h['reco_bkg'], \"QCD Inclusive\" , \"L\");\n",
    "legend.AddEntry( h['l1_inc'], \"ggH LCT Inclusive\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c_pg.Draw()\n",
    "\n",
    "# c.SaveAs(\"ncsc_inclusive_mc_zeroBias.pdf\")\n",
    "# c.SaveAs(\"ncsc_inclusive_mc_zeroBias.C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barrel Hit Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit removal done identically to that of the endcap\n",
    "\n",
    "# Barrel\n",
    "nDt_station = {}\n",
    "nDt_removal = {}\n",
    "\n",
    "# Loops over every datafile\n",
    "for files in data_trees.keys():\n",
    "    # Barrel\n",
    "    nDt_station[files] = {}\n",
    "    nDt_station[files]['MB_1'] = []\n",
    "    nDt_station[files]['MB_2'] = []\n",
    "    nDt_station[files]['MB_3'] = []\n",
    "    nDt_station[files]['MB_4'] = []\n",
    "    \n",
    "    # Loops over every event in each datafile\n",
    "    for pos_bool in range(len(dt_z[files])):\n",
    "        dt_r = np.sqrt(dt_x[files][pos_bool]**2+dt_y[files][pos_bool]**2)\n",
    "        z_pos_bool = dt_z[files][pos_bool]\n",
    "        \n",
    "        counter_mb1 = 0\n",
    "        counter_mb2 = 0\n",
    "        counter_mb3 = 0\n",
    "        counter_mb4 = 0\n",
    "        \n",
    "        # Loops over every hit in each event\n",
    "        for z_ind in range(len(z_pos_bool)):\n",
    "            z_bool = np.absolute(z_pos_bool[z_ind])\n",
    "            if z_bool > -661 and z_bool < 661:\n",
    "                \n",
    "                # MB 1 Constraints\n",
    "                if dt_r[z_ind] < 449 and dt_r[z_ind] > 402:\n",
    "                    counter_mb1 += 1\n",
    "                # MB 2 Constraints\n",
    "                if dt_r[z_ind] < 533.5 and dt_r[z_ind] > 490.5:\n",
    "                    counter_mb2 += 1\n",
    "                # MB 3 Constraints\n",
    "                if dt_r[z_ind] < 636 and dt_r[z_ind] > 597.5:\n",
    "                    counter_mb3 += 1\n",
    "                # MB 4 Constraints\n",
    "                if dt_r[z_ind] < 738 and dt_r[z_ind] > 700:\n",
    "                    counter_mb4 += 1\n",
    "                    \n",
    "        nDt_station[files]['MB_1'].append(counter_mb1)\n",
    "        nDt_station[files]['MB_2'].append(counter_mb2)\n",
    "        nDt_station[files]['MB_3'].append(counter_mb3)\n",
    "        nDt_station[files]['MB_4'].append(counter_mb4)    \n",
    "    \n",
    "    # nDt dictionaries containing hits removed labelled by removed stations\n",
    "    nDt_removal[files] = {}\n",
    "    nDt_removal[files]['MB_1'] = np.array(nDt[files]) - np.array(nDt_station[files]['MB_1'])\n",
    "    nDt_removal[files]['MB_12'] = np.array(nDt[files]) - (np.array(nDt_station[files]['MB_1']) + np.array(nDt_station[files]['MB_2']))\n",
    "    \n",
    "    print(files + ': ' +str(datetime.datetime.now(pytz.timezone('US/Pacific'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Average Fraction of Hits per DT station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determines the evenness of hits distributed across the barrel DT stations by taking the average ratio of nDt for adjacent stations per event\n",
    "\n",
    "# nDt_avg_ratio = {}\n",
    "# nDt_ratio_cut = {}\n",
    "    \n",
    "# for species in data_trees.keys():\n",
    "#     nDt_ratio_cut[species] = {}\n",
    "#     ratio_mb_12 = []\n",
    "#     ratio_mb_23 = []\n",
    "#     ratio_mb_34 = []\n",
    "#     for event in range(len(nDt_station[species]['MB_1'])):\n",
    "#         mb_12_comp = np.min((nDt_station[species]['MB_1'][event], nDt_station[species]['MB_2'][event]))/np.max((nDt_station[species]['MB_1'][event], nDt_station[species]['MB_2'][event]))\n",
    "#         ratio_mb_12.append(mb_12_comp)\n",
    "        \n",
    "#         mb_23_comp = np.min((nDt_station[species]['MB_2'][event], nDt_station[species]['MB_3'][event]))/np.max((nDt_station[species]['MB_2'][event], nDt_station[species]['MB_3'][event]))\n",
    "#         ratio_mb_23.append(mb_23_comp)\n",
    "        \n",
    "#         mb_34_comp = np.min((nDt_station[species]['MB_3'][event], nDt_station[species]['MB_4'][event]))/np.max((nDt_station[species]['MB_3'][event], nDt_station[species]['MB_4'][event]))\n",
    "#         ratio_mb_34.append(mb_34_comp)\n",
    "\n",
    "#     barrel_station_ratio = np.dstack((np.array(ratio_mb_12), np.array(ratio_mb_23), np.array(ratio_mb_34)))\n",
    "#     barrel_avg_ratio = np.mean(barrel_station_ratio, axis=2)\n",
    "#     nDt_avg_ratio[species] = barrel_avg_ratio\n",
    "#     sel_avg_ratio = nDt_avg_ratio[species][0]<7\n",
    "#     nDt_ratio_cut[species]['dt_inclusive'] = nDt[species][sel_avg_ratio]\n",
    "#     nDt_ratio_cut[species]['no_MB1'] = nDt_removal[species]['MB_1'][sel_avg_ratio]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations for N<sub>CSC, DT, RPC</sub> Threshold ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations for ROC Curves for ggH/QCD/ZeroBias Samples: nCsc/nDt/nRpc \n",
    "\n",
    "# Calculates efficiency by calculating the fraction of events that pass nCsc/nDt/nRpc thresholds\n",
    "\n",
    "eff_ncsc = {}\n",
    "eff_ndt = {}\n",
    "eff_nrpc = {}\n",
    "rejection_power = {}\n",
    "ncsc_var_x = np.array([])\n",
    "# ndt_var_x = np.array([])\n",
    "\n",
    "# Iterates over every datafile\n",
    "for data_type in data_trees.keys():\n",
    "    eff_ncsc[data_type] = {}\n",
    "    eff_ndt[data_type] = {}\n",
    "    eff_nrpc[data_type] = {}\n",
    "      \n",
    "    # No clustering: Endcap\n",
    "    eff_ncsc[data_type]['noCluster'] = {}\n",
    "    eff_ncsc[data_type]['noCluster']['csc_inclusive'] = np.array([])\n",
    "    eff_ncsc[data_type]['noCluster']['csc_noME11'] = np.array([])\n",
    "    eff_ncsc[data_type]['noCluster']['csc_noME112'] = np.array([])\n",
    "    eff_ncsc[data_type]['noCluster']['csc_noME1123'] = np.array([])\n",
    "    eff_ncsc[data_type]['noCluster']['pg_inclusive'] = np.array([])\n",
    "    eff_ncsc[data_type]['noCluster']['pg_noME11'] = np.array([])\n",
    "    eff_ncsc[data_type]['noCluster']['pg_noME112'] = np.array([])\n",
    "    eff_ncsc[data_type]['noCluster']['pg_noME1123'] = np.array([])\n",
    "    \n",
    "    # No clustering: Barrel\n",
    "    eff_ndt[data_type]['noCluster'] = {}\n",
    "    eff_ndt[data_type]['noCluster_ratioCut'] = {}\n",
    "    \n",
    "    eff_ndt[data_type]['noCluster']['dt_inclusive'] = np.array([])\n",
    "    eff_ndt[data_type]['noCluster']['dt_noMB1'] = np.array([])\n",
    "    eff_ndt[data_type]['noCluster']['dt_noMB12'] = np.array([])\n",
    "    eff_ndt[data_type]['noCluster_ratioCut']['dt_inclusive'] = np.array([])\n",
    "    eff_ndt[data_type]['noCluster_ratioCut']['dt_noMB1'] = np.array([])\n",
    "        \n",
    "    # No clustering: Overlap\n",
    "    eff_nrpc[data_type]['noCluster'] = {}\n",
    "    eff_nrpc[data_type]['noCluster']['rpc_inclusive'] = np.array([])\n",
    "    \n",
    "    for hit_thresh in range(0, 200):\n",
    "        ncsc_var_x = np.append(ncsc_var_x, hit_thresh)\n",
    "        \n",
    "        # No-Clustering ROCs\n",
    "        # Endcap\n",
    "        eff_ncsc[data_type]['noCluster']['csc_inclusive'] = np.append(eff_ncsc[data_type]['noCluster']['csc_inclusive'], np.count_nonzero(np.array(nCsc[data_type])>hit_thresh)/len(nCsc[data_type]))\n",
    "        eff_ncsc[data_type]['noCluster']['csc_noME11'] = np.append(eff_ncsc[data_type]['noCluster']['csc_noME11'], np.count_nonzero(np.array(nCsc_removal[data_type]['ME_11'])>hit_thresh)/len(nCsc_removal[data_type]['ME_11']))\n",
    "        eff_ncsc[data_type]['noCluster']['csc_noME112'] = np.append(eff_ncsc[data_type]['noCluster']['csc_noME112'], np.count_nonzero(np.array(nCsc_removal[data_type]['ME_112'])>hit_thresh)/len(nCsc_removal[data_type]['ME_112']))\n",
    "        eff_ncsc[data_type]['noCluster']['csc_noME1123'] = np.append(eff_ncsc[data_type]['noCluster']['csc_noME1123'], np.count_nonzero(np.array(nCsc_removal[data_type]['ME_1123'])>hit_thresh)/len(nCsc_removal[data_type]['ME_1123']))\n",
    "\n",
    "        eff_ncsc[data_type]['noCluster']['pg_inclusive'] = np.append(eff_ncsc[data_type]['noCluster']['pg_inclusive'], np.count_nonzero(np.array(pg_ncsc[data_type])>hit_thresh)/len(pg_ncsc[data_type]))\n",
    "        eff_ncsc[data_type]['noCluster']['pg_noME11'] = np.append(eff_ncsc[data_type]['noCluster']['pg_noME11'], np.count_nonzero(np.array(pg_ncsc_noME11[data_type])>hit_thresh)/len(pg_ncsc_noME11[data_type]))\n",
    "        eff_ncsc[data_type]['noCluster']['pg_noME112'] = np.append(eff_ncsc[data_type]['noCluster']['pg_noME112'], np.count_nonzero(np.array(pg_ncsc_noME112[data_type])>hit_thresh)/len(pg_ncsc_noME112[data_type]))\n",
    "        eff_ncsc[data_type]['noCluster']['pg_noME1123'] = np.append(eff_ncsc[data_type]['noCluster']['pg_noME1123'], np.count_nonzero(np.array(pg_ncsc_noME1123[data_type])>hit_thresh)/len(pg_ncsc_noME1123[data_type]))\n",
    "\n",
    "        \n",
    "#         Overlap\n",
    "        eff_nrpc[data_type]['noCluster']['rpc_inclusive'] = np.append(eff_nrpc[data_type]['noCluster']['rpc_inclusive'], np.count_nonzero(np.array(nRpc[data_type])>hit_thresh)/len(nRpc[data_type]))\n",
    "\n",
    "    # Rejection power calculation\n",
    "    rejection_power[data_type] = {}\n",
    "    rejection_power[data_type]['noCluster'] = {}\n",
    "#     rejection_power[data_type]['noCluster_ratioCut'] = {}\n",
    "    \n",
    "    # No clustering\n",
    "    rejection_power[data_type]['noCluster']['csc_inclusive'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['csc_inclusive']))\n",
    "    rejection_power[data_type]['noCluster']['csc_noME11'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['csc_noME11']))\n",
    "    rejection_power[data_type]['noCluster']['csc_noME112'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['csc_noME112']))\n",
    "    rejection_power[data_type]['noCluster']['csc_noME1123'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['csc_noME1123']))\n",
    "    \n",
    "    rejection_power[data_type]['noCluster']['pg_inclusive'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['pg_inclusive']))\n",
    "    rejection_power[data_type]['noCluster']['pg_noME11'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['pg_noME11']))    \n",
    "    rejection_power[data_type]['noCluster']['pg_noME112'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['pg_noME112']))\n",
    "    rejection_power[data_type]['noCluster']['pg_noME1123'] = np.reciprocal(np.trim_zeros(eff_ncsc[data_type]['noCluster']['pg_noME1123']))\n",
    "\n",
    "    rejection_power[data_type]['noCluster']['rpc_inclusive'] = np.reciprocal(np.trim_zeros(eff_nrpc[data_type]['noCluster']['rpc_inclusive']))\n",
    "\n",
    "    For the high LLP mass, low ctau sample (m975ct1m) , none of the events pass the barrel cut and thus I hard-coded a \n",
    "    way to avoid divide-by-zero errors later on when plotting ROC curves by simpling not recording any barrel datapoints\n",
    "    for this sample.\n",
    "    if data_type != 'm975ct1m':\n",
    "        \n",
    "        for hit_thresh in range(0, 200):\n",
    "            ndt_var_x = np.append(ndt_var_x, hit_thresh)\n",
    "            \n",
    "            # No-Clustering ROCs\n",
    "            # Barrel\n",
    "            eff_ndt[data_type]['noCluster']['dt_inclusive'] = np.append(eff_ndt[data_type]['noCluster']['dt_inclusive'], np.count_nonzero(np.array(nDt[data_type])>hit_thresh)/len(nDt[data_type]))\n",
    "            eff_ndt[data_type]['noCluster']['dt_noMB1'] = np.append(eff_ndt[data_type]['noCluster']['dt_noMB1'], np.count_nonzero(np.array(nDt_removal[data_type]['MB_1'])>hit_thresh)/len(nDt_removal[data_type]['MB_1']))\n",
    "            eff_ndt[data_type]['noCluster']['dt_noMB12'] = np.append(eff_ndt[data_type]['noCluster']['dt_noMB12'], np.count_nonzero(np.array(nDt_removal[data_type]['MB_12'])>hit_thresh)/len(nDt_removal[data_type]['MB_12']))\n",
    "            \n",
    "#             eff_ndt[data_type]['noCluster_ratioCut']['dt_inclusive'] = np.append(eff_ndt[data_type]['noCluster_ratioCut']['dt_inclusive'], np.count_nonzero(np.array(nDt_ratio_cut[data_type]['dt_inclusive'])>hit_thresh)/len(nDt_ratio_cut[data_type]['dt_inclusive']))\n",
    "#             eff_ndt[data_type]['noCluster_ratioCut']['dt_noMB1'] = np.append(eff_ndt[data_type]['noCluster_ratioCut']['dt_noMB1'], np.count_nonzero(np.array(nDt_ratio_cut[data_type]['no_MB1'])>hit_thresh)/len(nDt_ratio_cut[data_type]['no_MB1']))\n",
    "            \n",
    "            \n",
    "        # No clustering\n",
    "        rejection_power[data_type]['noCluster']['dt_inclusive'] = np.reciprocal(np.trim_zeros(eff_ndt[data_type]['noCluster']['dt_inclusive']))\n",
    "        rejection_power[data_type]['noCluster']['dt_noMB1'] = np.reciprocal(np.trim_zeros(eff_ndt[data_type]['noCluster']['dt_noMB1']))\n",
    "        rejection_power[data_type]['noCluster']['dt_noMB12'] = np.reciprocal(np.trim_zeros(eff_ndt[data_type]['noCluster']['dt_noMB12']))\n",
    "        \n",
    "#         rejection_power[data_type]['noCluster_ratioCut']['dt_inclusive'] = np.reciprocal(np.trim_zeros(eff_ndt[data_type]['noCluster_ratioCut']['dt_inclusive']))  \n",
    "#         rejection_power[data_type]['noCluster_ratioCut']['dt_noMB1'] = np.reciprocal(np.trim_zeros(eff_ndt[data_type]['noCluster_ratioCut']['dt_noMB1']))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Lookup Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Selection of Events for Event Display Purposes (Test area)\n",
    "# # print(len(eventNum_barrel['m50ct10m']))\n",
    "# # print(len(nDt_avg_ratio['m50ct10m'][0]))\n",
    "# index_ev = np.where(np.array(nDt['m50ct10m'])==0)\n",
    "# print('Lumi ' + 'Event ' + 'nCsc ' + 'gLLP_r')\n",
    "# print(np.dstack((lumiNum_barrel['m50ct10m'][index_ev].astype(int), eventNum_barrel['m50ct10m'][index_ev].astype(int), gLLPr['m50ct10m'][index_ev])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endcap Offline Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Endcap Inclusive N<sub>CSC</sub> Histogram*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the number of CSC hits for the m50ct1m signal MC, QCD MC, and ZeroBias data \n",
    "# with no hit removal\n",
    "\n",
    "c = rt.TCanvas('c','c', 800, 600)\n",
    "h = {}\n",
    "h['nCsc_m50ct1m'] = create_TH1D(nCsc['m50ct1m'], axis_title=['nCsc_m50ct1m', 'Events'], name='nCsc_m50ct1m', binning=[150,0,500])\n",
    "h['nCsc_m50ct1m'].SetLineColor(4)\n",
    "\n",
    "h['nCsc_qcd'] = create_TH1D(nCsc['qcd'], axis_title=['nCsc_qcd', 'Events'], name='nCsc_qcd', binning=[150,0,500])\n",
    "h['nCsc_qcd'].SetLineColor(2)\n",
    "h['nCsc_qcd'].SetLineStyle(2)\n",
    "\n",
    "\n",
    "h['nCsc_zeroBias'] = create_TH1D(nCsc['zeroBias'], axis_title=['nCsc_zeroBias', 'Events'], name='nCsc_zeroBias', binning=[150,0,500])\n",
    "h['nCsc_zeroBias'].SetLineColor(2)\n",
    "h['nCsc_zeroBias'].SetLineStyle(1)\n",
    "\n",
    "c.SetLogy()\n",
    "\n",
    "h['nCsc_m50ct1m'].Scale(1.0/h['nCsc_m50ct1m'].Integral())\n",
    "h['nCsc_qcd'].Scale(1.0/h['nCsc_qcd'].Integral())\n",
    "h['nCsc_zeroBias'].Scale(1.0/h['nCsc_zeroBias'].Integral())\n",
    "\n",
    "\n",
    "h['nCsc_m50ct1m'].SetLineWidth(2)\n",
    "h['nCsc_qcd'].SetLineWidth(2)\n",
    "h['nCsc_zeroBias'].SetLineWidth(2)\n",
    "\n",
    "h['nCsc_m50ct1m'].GetXaxis().SetRangeUser(0,200)\n",
    "h['nCsc_qcd'].GetXaxis().SetRangeUser(0,200)\n",
    "h['nCsc_zeroBias'].GetXaxis().SetRangeUser(0,200)\n",
    "\n",
    "\n",
    "h['nCsc_qcd'].SetStats(0)\n",
    "h['nCsc_qcd'].SetTitle(\"CSC Inclusive\")\n",
    "h['nCsc_qcd'].SetXTitle(\"N_{csc}\")\n",
    "\n",
    "\n",
    "h['nCsc_qcd'].Draw('histo')\n",
    "h['nCsc_m50ct1m'].Draw('histo+same')\n",
    "h['nCsc_zeroBias'].Draw('histo+same')\n",
    "\n",
    "legend = rt.TLegend(0.50,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "#legend-.SetFillStyle(0);\n",
    "legend.AddEntry( h['nCsc_m50ct1m'], \"mX=50 GeV, c#tau=1m (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nCsc_qcd'], \"QCD (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nCsc_zeroBias'], \"Zero Bias\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c.Draw()\n",
    "\n",
    "c.SaveAs(\"ncsc_inclusive_mc_zeroBias.pdf\")\n",
    "c.SaveAs(\"ncsc_inclusive_mc_zeroBias.C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *N<sub>CSC</sub> Histogram with ME 1/1 Hits Removed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the number of CSC hits for the m50ct1m signal MC, QCD MC, and ZeroBias data\n",
    "# after removing hits in ME 1/1\n",
    "\n",
    "c2 = rt.TCanvas('c2','c2', 800, 600)\n",
    "\n",
    "h['nCsc_m50ct1m_noME11'] = create_TH1D(nCsc_removal['m50ct1m']['ME_11'], axis_title=['nCsc_m50ct1m_noME11', 'Events'], name='nCsc_m50ct1m_noME11', binning=[150,0,500])\n",
    "h['nCsc_m50ct1m_noME11'].SetLineColor(4)\n",
    "\n",
    "h['nCsc_qcd_noME11'] = create_TH1D(nCsc_removal['qcd']['ME_11'], axis_title=['nCsc_qcd_noME11', 'Events'], name='nCsc_qcd_noME11', binning=[150,0,500])\n",
    "h['nCsc_qcd_noME11'].SetLineColor(2)\n",
    "h['nCsc_qcd_noME11'].SetLineStyle(2)\n",
    "\n",
    "\n",
    "h['nCsc_zeroBias_noME11'] = create_TH1D(nCsc_removal['zeroBias']['ME_11'], axis_title=['nCsc_zeroBias_noME11', 'Events'], name='nCsc_zeroBias_noME11', binning=[150,0,500])\n",
    "h['nCsc_zeroBias_noME11'].SetLineColor(2)\n",
    "h['nCsc_zeroBias_noME11'].SetLineStyle(1)\n",
    "\n",
    "c2.SetLogy()\n",
    "\n",
    "h['nCsc_m50ct1m_noME11'].Scale(1.0/h['nCsc_m50ct1m_noME11'].Integral())\n",
    "h['nCsc_qcd_noME11'].Scale(1.0/h['nCsc_qcd_noME11'].Integral())\n",
    "h['nCsc_zeroBias_noME11'].Scale(1.0/h['nCsc_zeroBias_noME11'].Integral())\n",
    "\n",
    "\n",
    "h['nCsc_m50ct1m_noME11'].SetLineWidth(2)\n",
    "h['nCsc_qcd_noME11'].SetLineWidth(2)\n",
    "h['nCsc_zeroBias_noME11'].SetLineWidth(2)\n",
    "\n",
    "h['nCsc_m50ct1m_noME11'].GetXaxis().SetRangeUser(0,200)\n",
    "h['nCsc_qcd_noME11'].GetXaxis().SetRangeUser(0,200)\n",
    "h['nCsc_zeroBias_noME11'].GetXaxis().SetRangeUser(0,200)\n",
    "\n",
    "\n",
    "h['nCsc_qcd_noME11'].SetStats(0)\n",
    "h['nCsc_qcd_noME11'].SetTitle(\"ME 1/1 Removed\")\n",
    "h['nCsc_qcd_noME11'].SetXTitle(\"N_{csc}\")\n",
    "\n",
    "\n",
    "h['nCsc_qcd_noME11'].Draw('histo')\n",
    "h['nCsc_m50ct1m_noME11'].Draw('histo+same')\n",
    "h['nCsc_zeroBias_noME11'].Draw('histo+same')\n",
    "\n",
    "legend = rt.TLegend(0.50,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "#legend-.SetFillStyle(0);\n",
    "legend.AddEntry( h['nCsc_m50ct1m_noME11'], \"mX=50 GeV, c#tau=1m (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nCsc_qcd_noME11'], \"QCD (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nCsc_zeroBias_noME11'], \"Zero Bias\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c2.Draw()\n",
    "\n",
    "c2.SaveAs(\"ncsc_noME11_mc_zeroBias.pdf\")\n",
    "c2.SaveAs(\"ncsc_noME11_mc_zeroBias.C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *N<sub>CSC</sub> Threshold ROC Curves*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates ROC curves for the signal efficiency of the m50ct1m signal sample against the ZeroBias samples\n",
    "# using nCsc thresholds\n",
    "\n",
    "c3 = rt.TCanvas('c3','c3', 800, 600)\n",
    "\n",
    "h['roc_curve_noCluster'] = create_TGraph(rejection_power['zeroBias']['noCluster']['csc_inclusive'], eff_ncsc['m50ct1m']['noCluster']['csc_inclusive'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_curve_clean_noCluster'] = create_TGraph(rejection_power['zeroBias']['noCluster']['csc_noME11'], eff_ncsc['m50ct1m']['noCluster']['csc_noME11'], axis_title=['#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_curve_res_noCluster'] = create_TGraph(rejection_power['zeroBias']['noCluster']['csc_noME1123'], eff_ncsc['m50ct1m']['noCluster']['csc_noME1123'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_curve_med_noCluster'] = create_TGraph(rejection_power['zeroBias']['noCluster']['csc_noME112'], eff_ncsc['m50ct1m']['noCluster']['csc_noME112'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "\n",
    "h['roc_curve_pg_inc'] = create_TGraph(rejection_power['zeroBias']['noCluster']['pg_inclusive'], eff_ncsc['m50ct1m']['noCluster']['pg_inclusive'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_curve_pg_no11'] = create_TGraph(rejection_power['zeroBias']['noCluster']['pg_noME11'], eff_ncsc['m50ct1m']['noCluster']['pg_noME11'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_curve_pg_no112'] = create_TGraph(rejection_power['zeroBias']['noCluster']['pg_noME112'], eff_ncsc['m50ct1m']['noCluster']['pg_noME112'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_curve_pg_no1123'] = create_TGraph(rejection_power['zeroBias']['noCluster']['pg_noME1123'], eff_ncsc['m50ct1m']['noCluster']['pg_noME1123'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "\n",
    "\n",
    "c3.SetLogx()\n",
    "\n",
    "h['roc_curve_noCluster'].SetTitle('ZeroBias')\n",
    "\n",
    "\n",
    "h['roc_curve_noCluster'].SetLineWidth(2)\n",
    "h['roc_curve_clean_noCluster'].SetLineWidth(2)\n",
    "h['roc_curve_res_noCluster'].SetLineWidth(2)\n",
    "h['roc_curve_med_noCluster'].SetLineWidth(2)\n",
    "\n",
    "h['roc_curve_pg_inc'].SetLineWidth(2)\n",
    "h['roc_curve_pg_no11'].SetLineWidth(2)\n",
    "h['roc_curve_pg_no112'].SetLineWidth(2)\n",
    "h['roc_curve_pg_no1123'].SetLineWidth(2)\n",
    "\n",
    "\n",
    "h['roc_curve_noCluster'].SetLineColor(1)\n",
    "h['roc_curve_noCluster'].SetLineStyle(2)\n",
    "\n",
    "h['roc_curve_clean_noCluster'].SetLineColor(2)\n",
    "h['roc_curve_clean_noCluster'].SetLineStyle(2)\n",
    "                                          \n",
    "h['roc_curve_res_noCluster'].SetLineColor(3)\n",
    "h['roc_curve_res_noCluster'].SetLineStyle(2)\n",
    "\n",
    "h['roc_curve_med_noCluster'].SetLineColor(4)\n",
    "h['roc_curve_med_noCluster'].SetLineStyle(2)\n",
    "\n",
    "h['roc_curve_pg_inc'].SetLineColor(1)\n",
    "h['roc_curve_pg_no11'].SetLineColor(2)\n",
    "h['roc_curve_pg_no112'].SetLineColor(3)\n",
    "h['roc_curve_pg_no1123'].SetLineColor(4)\n",
    "\n",
    "h['roc_curve_noCluster'].GetXaxis().SetLimits(10, 10000000)\n",
    "h['roc_curve_noCluster'].GetYaxis().SetRangeUser(0,1)\n",
    "\n",
    "h['roc_curve_noCluster'].Draw()\n",
    "h['roc_curve_clean_noCluster'].Draw('same')\n",
    "\n",
    "h['roc_curve_res_noCluster'].Draw('same')\n",
    "h['roc_curve_med_noCluster'].Draw('same')\n",
    "\n",
    "h['roc_curve_pg_inc'].Draw('same')\n",
    "h['roc_curve_pg_no11'].Draw('same')\n",
    "h['roc_curve_pg_no112'].Draw('same')\n",
    "h['roc_curve_pg_no1123'].Draw('same')\n",
    "\n",
    "legend = rt.TLegend(0.50,0.70,0.5,0.7);\n",
    "legend.SetTextSize(0.03);\n",
    "legend.SetBorderSize(0);\n",
    "legend.SetFillStyle(0);\n",
    "\n",
    "legend.AddEntry( h['roc_curve_noCluster'], \"Reco Inclusive\", 'l');\n",
    "legend.AddEntry( h['roc_curve_clean_noCluster'], \"Reco No 1/1\", 'l');\n",
    "legend.AddEntry( h['roc_curve_med_noCluster'], \"Reco No 1/1+1/2\", 'l');\n",
    "legend.AddEntry( h['roc_curve_res_noCluster'], \"Reco No 1/1+1/2+1/3\", 'l');\n",
    "\n",
    "legend.AddEntry( h['roc_curve_pg_inc'], \"L1 Inclusive\", 'l');\n",
    "legend.AddEntry( h['roc_curve_pg_no11'], \"L1 No 1/1\", 'l');\n",
    "legend.AddEntry( h['roc_curve_pg_no112'], \"L1 No 1/1+1/2\", 'l');\n",
    "legend.AddEntry( h['roc_curve_pg_no1123'], \"L1 No 1/1+1/2+1/3\", 'l');\n",
    "\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c3.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barrel Offline Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Barrel Inclusive N<sub>DT</sub> Histogram*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the number of DT hits for the m50ct1m signal MC, QCD MC, and ZeroBias data\n",
    "# with no hit removal\n",
    "\n",
    "c4 = rt.TCanvas('c4','c4', 800, 600)\n",
    "h['nDt_signal'] = create_TH1D(nDt['m50ct1m'], axis_title=['nDt_signal', 'Events'], name='nDt_signal', binning=[150,0,500])\n",
    "h['nDt_signal'].SetLineColor(4)\n",
    "\n",
    "h['nDt_qcd'] = create_TH1D(nDt['qcd'], axis_title=['nDt_qcd', 'Events'], name='nDt_qcd', binning=[150,0,500])\n",
    "h['nDt_qcd'].SetLineColor(2)\n",
    "h['nDt_qcd'].SetLineStyle(2)\n",
    "\n",
    "\n",
    "h['nDt_zeroBias'] = create_TH1D(nDt['zeroBias'], axis_title=['nDt_zeroBias', 'Events'], name='nDt_zeroBias', binning=[150,0,500])\n",
    "h['nDt_zeroBias'].SetLineColor(2)\n",
    "h['nDt_zeroBias'].SetLineStyle(1)\n",
    "\n",
    "c4.SetLogy()\n",
    "\n",
    "h['nDt_signal'].Scale(1.0/h['nDt_signal'].Integral())\n",
    "h['nDt_qcd'].Scale(1.0/h['nDt_qcd'].Integral())\n",
    "h['nDt_zeroBias'].Scale(1.0/h['nDt_zeroBias'].Integral())\n",
    "\n",
    "\n",
    "h['nDt_signal'].SetLineWidth(2)\n",
    "h['nDt_qcd'].SetLineWidth(2)\n",
    "h['nDt_zeroBias'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_signal'].GetXaxis().SetRangeUser(0,200)\n",
    "h['nDt_qcd'].GetXaxis().SetRangeUser(0,200)\n",
    "h['nDt_zeroBias'].GetXaxis().SetRangeUser(0,200)\n",
    "\n",
    "\n",
    "h['nDt_qcd'].SetStats(0)\n",
    "h['nDt_qcd'].SetTitle(\"DT Inclusive\")\n",
    "h['nDt_qcd'].SetXTitle(\"N_{DT}\")\n",
    "\n",
    "\n",
    "h['nDt_qcd'].Draw('histo')\n",
    "h['nDt_signal'].Draw('histo+same')\n",
    "h['nDt_zeroBias'].Draw('histo+same')\n",
    "\n",
    "legend = rt.TLegend(0.49,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "legend.AddEntry( h['nDt_signal'], \"mX=50 GeV, c#tau=1m (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nDt_qcd'], \"QCD (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nDt_zeroBias'], \"Zero Bias\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c4.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *N<sub>DT</sub> Histogram with MB 1 Hits Removed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the number of DT hits for the m50ct1m signal MC, QCD MC, and ZeroBias data\n",
    "# after removing hits in MB 1\n",
    "\n",
    "c5 = rt.TCanvas('c5','c5', 800, 600)\n",
    "\n",
    "h['nDt_signal_noMB1'] = create_TH1D(nDt_removal['m50ct1m']['MB_1'], axis_title=['nDt_signal_noMB1', 'Events'], name='nDt_signal_noMB1', binning=[150,0,500])\n",
    "h['nDt_signal_noMB1'].SetLineColor(4)\n",
    "\n",
    "h['nDt_qcd_noMB1'] = create_TH1D(nDt_removal['qcd']['MB_1'], axis_title=['nDt_qcd_noMB1', 'Events'], name='nDt_qcd_noMB1', binning=[150,0,500])\n",
    "h['nDt_qcd_noMB1'].SetLineColor(2)\n",
    "h['nDt_qcd_noMB1'].SetLineStyle(2)\n",
    "\n",
    "\n",
    "h['nDt_zeroBias_noMB1'] = create_TH1D(nDt_removal['zeroBias']['MB_1'], axis_title=['nDt_zeroBias_noMB1', 'Events'], name='nDt_zeroBias_noMB1', binning=[150,0,500])\n",
    "h['nDt_zeroBias_noMB1'].SetLineColor(2)\n",
    "h['nDt_zeroBias_noMB1'].SetLineStyle(1)\n",
    "\n",
    "c5.SetLogy()\n",
    "\n",
    "h['nDt_signal_noMB1'].Scale(1.0/h['nDt_signal_noMB1'].Integral())\n",
    "h['nDt_qcd_noMB1'].Scale(1.0/h['nDt_qcd_noMB1'].Integral())\n",
    "h['nDt_zeroBias_noMB1'].Scale(1.0/h['nDt_zeroBias_noMB1'].Integral())\n",
    "\n",
    "\n",
    "h['nDt_signal_noMB1'].SetLineWidth(2)\n",
    "h['nDt_qcd_noMB1'].SetLineWidth(2)\n",
    "h['nDt_zeroBias_noMB1'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_qcd_noMB1'].GetXaxis().SetRangeUser(0,200)\n",
    "h['nDt_qcd_noMB1'].SetStats(0)\n",
    "h['nDt_qcd_noMB1'].SetTitle(\"MB 1 Removed\")\n",
    "h['nDt_qcd_noMB1'].SetXTitle(\"N_{DT}\")\n",
    "\n",
    "\n",
    "h['nDt_qcd_noMB1'].Draw('histo')\n",
    "h['nDt_signal_noMB1'].Draw('histo+same')\n",
    "h['nDt_zeroBias_noMB1'].Draw('histo+same')\n",
    "\n",
    "legend = rt.TLegend(0.48,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "#legend-.SetFillStyle(0);\n",
    "legend.AddEntry( h['nDt_signal_noMB1'], \"mX=50 GeV, c#tau=1m (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nDt_qcd_noMB1'], \"QCD (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nDt_zeroBias_noMB1'], \"Zero Bias\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c5.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the number of DT hits for the m50ct1m signal MC, QCD MC, and ZeroBias data\n",
    "# after removing hits in MB 1\n",
    "\n",
    "c5_5 = rt.TCanvas('c5_5','c5_5', 800, 600)\n",
    "\n",
    "h['nDt_signal_MB1'] = create_TH1D(nDt_station['m50ct10m']['MB_1'], axis_title=['nDt_signal_MB1', 'Events'], name='nDt_signal_MB1', binning=[50,0,200])\n",
    "h['nDt_signal_MB1'].SetLineColor(1)\n",
    "h['nDt_signal_MB1'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_signal_MB2'] = create_TH1D(nDt_station['m50ct10m']['MB_2'], axis_title=['nDt_signal_MB2', 'Events'], name='nDt_signal_MB2', binning=[50,0,200])\n",
    "h['nDt_signal_MB2'].SetLineColor(2)\n",
    "h['nDt_signal_MB2'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_signal_MB3'] = create_TH1D(nDt_station['m50ct10m']['MB_3'], axis_title=['nDt_signal_MB3', 'Events'], name='nDt_signal_MB3', binning=[50,0,200])\n",
    "h['nDt_signal_MB3'].SetLineColor(3)\n",
    "h['nDt_signal_MB3'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_signal_MB4'] = create_TH1D(nDt_station['m50ct10m']['MB_4'], axis_title=['nDt_signal_MB4', 'Events'], name='nDt_signal_MB4', binning=[50,0,200])\n",
    "h['nDt_signal_MB4'].SetLineColor(4)\n",
    "h['nDt_signal_MB4'].SetLineWidth(2)\n",
    "\n",
    "c5_5.SetLogy()\n",
    "\n",
    "h['nDt_signal_MB1'].Scale(1.0/h['nDt_signal_MB1'].Integral())\n",
    "h['nDt_signal_MB2'].Scale(1.0/h['nDt_signal_MB2'].Integral())\n",
    "h['nDt_signal_MB3'].Scale(1.0/h['nDt_signal_MB3'].Integral())\n",
    "h['nDt_signal_MB4'].Scale(1.0/h['nDt_signal_MB4'].Integral())\n",
    "\n",
    "\n",
    "h['nDt_signal_MB1'].GetXaxis().SetRangeUser(0,120)\n",
    "h['nDt_signal_MB1'].SetStats(0)\n",
    "h['nDt_signal_MB1'].SetTitle(\"N_{DT} per station: mX=50 GeV, c#tau=10m (MC)\")\n",
    "h['nDt_signal_MB1'].SetXTitle(\"N_{DT}\")\n",
    "\n",
    "\n",
    "h['nDt_signal_MB1'].Draw('histo')\n",
    "h['nDt_signal_MB2'].Draw('histo+same')\n",
    "h['nDt_signal_MB3'].Draw('histo+same')\n",
    "h['nDt_signal_MB4'].Draw('histo+same')\n",
    "\n",
    "legend = rt.TLegend(0.48,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "#legend-.SetFillStyle(0);\n",
    "legend.AddEntry( h['nDt_signal_MB1'], \"MB 1\" , \"L\");\n",
    "legend.AddEntry( h['nDt_signal_MB2'], \"MB 2\" , \"L\");\n",
    "legend.AddEntry( h['nDt_signal_MB3'], \"MB 3\" , \"L\");\n",
    "legend.AddEntry( h['nDt_signal_MB4'], \"MB 4\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c5_5.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *N<sub>DT</sub> Histogram for MB 2 Hits Only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the number of DT hits for the m50ct1m signal MC, QCD MC, and ZeroBias data in MB 2\n",
    "\n",
    "c5_comp = rt.TCanvas('c5_comp','c5_comp', 800, 600)\n",
    "\n",
    "h['nDt_m50ct1m_MB1'] = create_TH1D(nDt_station['m50ct1m']['MB_2'], axis_title=['nDt_m50ct1m_MB1', 'Events'], name='nDt_m50ct1m_MB1', binning=[50,0,200])\n",
    "h['nDt_m50ct1m_MB1'].SetLineColor(1)\n",
    "h['nDt_m50ct1m_MB1'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_qcd_MB1'] = create_TH1D(nDt_station['qcd']['MB_2'], axis_title=['nDt_qcd_MB1', 'Events'], name='nDt_qcd_MB1', binning=[50,0,200])\n",
    "h['nDt_qcd_MB1'].SetLineColor(2)\n",
    "h['nDt_qcd_MB1'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_zeroBias_MB1'] = create_TH1D(nDt_station['zeroBias']['MB_2'], axis_title=['nDt_zeroBias_MB1', 'Events'], name='nDt_zeroBias_MB1', binning=[50,0,200])\n",
    "h['nDt_zeroBias_MB1'].SetLineColor(3)\n",
    "h['nDt_zeroBias_MB1'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_m50ct10m_MB1'] = create_TH1D(nDt_station['m50ct10m']['MB_2'], axis_title=['nDt_m50ct10m_MB1', 'Events'], name='nDt_m50ct10m_MB1', binning=[50,0,200])\n",
    "h['nDt_m50ct10m_MB1'].SetLineColor(4)\n",
    "h['nDt_m50ct10m_MB1'].SetLineWidth(2)\n",
    "\n",
    "c5_comp.SetLogy()\n",
    "\n",
    "h['nDt_m50ct1m_MB1'].Scale(1.0/h['nDt_m50ct1m_MB1'].Integral())\n",
    "h['nDt_qcd_MB1'].Scale(1.0/h['nDt_qcd_MB1'].Integral())\n",
    "h['nDt_zeroBias_MB1'].Scale(1.0/h['nDt_zeroBias_MB1'].Integral())\n",
    "h['nDt_m50ct10m_MB1'].Scale(1.0/h['nDt_m50ct10m_MB1'].Integral())\n",
    "\n",
    "\n",
    "h['nDt_m50ct1m_MB1'].GetXaxis().SetRangeUser(0,120)\n",
    "h['nDt_m50ct1m_MB1'].SetStats(0)\n",
    "h['nDt_m50ct1m_MB1'].SetTitle(\"MB 2 N_{DT} per station: mX=50 GeV, c#tau=10m (MC)\")\n",
    "h['nDt_m50ct1m_MB1'].SetXTitle(\"N_{DT}\")\n",
    "\n",
    "\n",
    "h['nDt_m50ct1m_MB1'].Draw('histo')\n",
    "h['nDt_qcd_MB1'].Draw('histo+same')\n",
    "h['nDt_zeroBias_MB1'].Draw('histo+same')\n",
    "h['nDt_m50ct10m_MB1'].Draw('histo+same')\n",
    "\n",
    "legend = rt.TLegend(0.48,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "#legend-.SetFillStyle(0);\n",
    "legend.AddEntry( h['nDt_m50ct1m_MB1'], \"mX=50 GeV, c#tau=1m (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nDt_qcd_MB1'], \"QCD\" , \"L\");\n",
    "legend.AddEntry( h['nDt_zeroBias_MB1'], \"ZeroBias\" , \"L\");\n",
    "legend.AddEntry( h['nDt_m50ct10m_MB1'], \"mX=50 GeV, c#tau=10m (MC)\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c5_comp.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Average Fraction of Hits per DT station*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the average fraction of DT hits contributed by each barrel station\n",
    "\n",
    "c5_6 = rt.TCanvas('c5_6','c5_6', 800, 600)\n",
    "\n",
    "h['nDt_signal_ratio'] = create_TH1D(nDt_avg_ratio['m50ct10m'][0], axis_title=['nDt_signal_ratio', 'Events'], name='nDt_signal_ratio', binning=[50,0,5])\n",
    "h['nDt_signal_ratio'].SetLineColor(4)\n",
    "h['nDt_signal_ratio'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_qcd_ratio'] = create_TH1D(nDt_avg_ratio['qcd'][0], axis_title=['nDt_qcd_ratio', 'Events'], name='nDt_qcd_ratio', binning=[50,0,5])\n",
    "h['nDt_qcd_ratio'].SetLineColor(2)\n",
    "h['nDt_qcd_ratio'].SetLineStyle(2)\n",
    "h['nDt_qcd_ratio'].SetLineWidth(2)\n",
    "\n",
    "h['nDt_zeroBias_ratio'] = create_TH1D(nDt_avg_ratio['zeroBias'][0], axis_title=['nDt_zeroBias_ratio', 'Events'], name='nDt_zeroBias_ratio', binning=[50,0,5])\n",
    "h['nDt_zeroBias_ratio'].SetLineColor(2)\n",
    "h['nDt_zeroBias_ratio'].SetLineStyle(1)\n",
    "h['nDt_zeroBias_ratio'].SetLineWidth(1)\n",
    "\n",
    "\n",
    "c5_6.SetLogy()\n",
    "\n",
    "h['nDt_signal_ratio'].Scale(1.0/h['nDt_signal_ratio'].Integral())\n",
    "h['nDt_qcd_ratio'].Scale(1.0/h['nDt_qcd_ratio'].Integral())\n",
    "h['nDt_zeroBias_ratio'].Scale(1.0/h['nDt_zeroBias_ratio'].Integral())\n",
    "\n",
    "h['nDt_signal_ratio'].GetXaxis().SetRangeUser(0,1.5)\n",
    "h['nDt_signal_ratio'].SetStats(0)\n",
    "h['nDt_signal_ratio'].SetTitle(\"\")\n",
    "h['nDt_signal_ratio'].SetXTitle(\"N_{DT} Fraction\")\n",
    "\n",
    "\n",
    "h['nDt_signal_ratio'].Draw('histo')\n",
    "h['nDt_qcd_ratio'].Draw('histo + same')\n",
    "h['nDt_zeroBias_ratio'].Draw('histo + same')\n",
    "\n",
    "\n",
    "legend = rt.TLegend(0.5,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "legend.SetFillStyle(0);\n",
    "legend.AddEntry( h['nDt_signal_ratio'], \"mX=50 GeV, c#tau=10m (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nDt_qcd_ratio'], \"QCD (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nDt_zeroBias_ratio'], \"Zero Bias\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c5_6.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *N<sub>DT</sub> Threshold ROC Curves*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates ROC curves for the signal efficiency of the m50ct1m signal sample against the ZeroBias/QCD samples\n",
    "# using nDt thresholds\n",
    "\n",
    "c7 = rt.TCanvas('c7','c7', 800, 600)\n",
    "\n",
    "h['roc_inclusive_zeroBias'] = create_TGraph(rejection_power['zeroBias']['noCluster']['dt_inclusive'], eff_ndt['m50ct10m']['noCluster']['dt_inclusive'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_no_mb1_zeroBias'] = create_TGraph(rejection_power['zeroBias']['noCluster']['dt_noMB1'], eff_ndt['m50ct10m']['noCluster']['dt_noMB1'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_no_mb12_zeroBias'] = create_TGraph(rejection_power['zeroBias']['noCluster']['dt_noMB12'], eff_ndt['m50ct10m']['noCluster']['dt_noMB12'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "# h['roc_no_mb1_ratioCut_zeroBias'] = create_TGraph(rejection_power['zeroBias']['noCluster_ratioCut']['dt_noMB1'], eff_ndt['m50ct10m']['noCluster_ratioCut']['dt_noMB1'], axis_title=['#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "\n",
    "\n",
    "h['roc_inclusive_qcd'] = create_TGraph(rejection_power['qcd']['noCluster']['dt_inclusive'], eff_ndt['m50ct10m']['noCluster']['dt_inclusive'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_no_mb1_qcd'] = create_TGraph(rejection_power['qcd']['noCluster']['dt_noMB1'], eff_ndt['m50ct10m']['noCluster']['dt_noMB1'], axis_title=['#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "h['roc_no_mb12_qcd'] = create_TGraph(rejection_power['qcd']['noCluster']['dt_noMB12'], eff_ndt['m50ct10m']['noCluster']['dt_noMB12'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "# h['roc_no_mb1_ratioCut_qcd'] = create_TGraph(rejection_power['qcd']['noCluster_ratioCut']['dt_noMB1'], eff_ndt['m50ct10m']['noCluster_ratioCut']['dt_noMB1'], axis_title=['#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "\n",
    "c7.SetLogx()\n",
    "# c7.SetLogy()\n",
    "\n",
    "h['roc_inclusive_zeroBias'].SetTitle('N_{DT}: mX=50 GeV, c#tau=10m (MC)')\n",
    "\n",
    "h['roc_inclusive_zeroBias'].SetLineWidth(2)\n",
    "h['roc_no_mb1_zeroBias'].SetLineWidth(2)\n",
    "# h['roc_no_mb1_ratioCut_zeroBias'].SetLineWidth(2)\n",
    "h['roc_no_mb12_zeroBias'].SetLineWidth(2)\n",
    "\n",
    "h['roc_inclusive_qcd'].SetLineWidth(2)\n",
    "h['roc_no_mb1_qcd'].SetLineWidth(2)\n",
    "# h['roc_no_mb1_ratioCut_qcd'].SetLineWidth(2)\n",
    "h['roc_no_mb12_qcd'].SetLineWidth(2)\n",
    "\n",
    "### ZeroBias #6\n",
    "\n",
    "h['roc_inclusive_zeroBias'].SetLineColor(1)\n",
    "h['roc_inclusive_zeroBias'].SetLineStyle(2)\n",
    "\n",
    "\n",
    "h['roc_no_mb1_zeroBias'].SetLineColor(2)\n",
    "h['roc_no_mb1_zeroBias'].SetLineStyle(2)\n",
    "\n",
    "h['roc_no_mb12_zeroBias'].SetLineColor(4)\n",
    "h['roc_no_mb12_zeroBias'].SetLineStyle(2)\n",
    "\n",
    "# h['roc_no_mb1_ratioCut_zeroBias'].SetLineColor(4)\n",
    "# h['roc_no_mb1_ratioCut_zeroBias'].SetLineStyle(2)\n",
    "\n",
    "\n",
    "### QCD\n",
    "\n",
    "# h['roc_inclusive_qcd'].SetLineColor(1)\n",
    "# h['roc_inclusive_qcd'].SetLineStyle(1)\n",
    "\n",
    "h['roc_no_mb1_qcd'].SetLineColor(2)\n",
    "h['roc_no_mb1_qcd'].SetLineStyle(1)\n",
    "\n",
    "h['roc_no_mb12_qcd'].SetLineColor(4)\n",
    "h['roc_no_mb12_qcd'].SetLineStyle(1)\n",
    "\n",
    "# h['roc_no_mb1_ratioCut_qcd'].SetLineColor(4)\n",
    "# h['roc_no_mb1_ratioCut_qcd'].SetLineStyle(1)\n",
    "\n",
    "####\n",
    "\n",
    "h['roc_no_mb1_zeroBias'].GetXaxis().SetLimits(10, 10000000)\n",
    "h['roc_no_mb1_zeroBias'].GetYaxis().SetRangeUser(0,1)\n",
    "\n",
    "\n",
    "\n",
    "h['roc_inclusive_zeroBias'].Draw()\n",
    "h['roc_no_mb1_zeroBias'].Draw('same')\n",
    "h['roc_no_mb12_zeroBias'].Draw('same')\n",
    "# h['roc_no_mb1_ratioCut_zeroBias'].Draw('same')\n",
    "\n",
    "h['roc_inclusive_qcd'].Draw('same')\n",
    "h['roc_no_mb1_qcd'].Draw('same')\n",
    "h['roc_no_mb12_qcd'].Draw('same')\n",
    "# h['roc_no_mb1_ratioCut_qcd'].Draw('same')\n",
    "\n",
    "\n",
    "legend = rt.TLegend(0.60,0.60,0.6,0.6);\n",
    "legend.SetTextSize(0.03);\n",
    "legend.SetBorderSize(0);\n",
    "legend.SetFillStyle(0);\n",
    "\n",
    "legend.AddEntry( h['roc_inclusive_zeroBias'], \"ZeroBias\", 'l');\n",
    "legend.AddEntry( h['roc_no_mb1_zeroBias'], \"ZeroBias w/o 1/1\", 'l');\n",
    "legend.AddEntry( h['roc_no_mb12_zeroBias'], \"ZeroBias w/o 1/1+1/2\", 'l');\n",
    "# legend.AddEntry( h['roc_no_mb1_ratioCut_zeroBias'], \"ZeroBias w/o 1/1 + Fraction Cut\", 'l');\n",
    "\n",
    "legend.AddEntry( h['roc_inclusive_qcd'], \"QCD\", 'l');\n",
    "legend.AddEntry( h['roc_no_mb1_qcd'], \"QCD w/o 1/1\", 'l');\n",
    "legend.AddEntry( h['roc_no_mb12_qcd'], \"QCD w/o 1/1+1/2\", 'l');\n",
    "# legend.AddEntry( h['roc_no_mb1_ratioCut_qcd'], \"QCD w/o 1/1 + Fraction Cut\", 'l');\n",
    "\n",
    "\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c7.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlap Offline Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Overlap Inclusive N<sub>RPC</sub> Histogram*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a 1D histogram of the number of RPC hits for the m50ct1m signal MC, QCD MC, and ZeroBias data\n",
    "# with no hit removal\n",
    "\n",
    "c6 = rt.TCanvas('c6','c6', 800, 600)\n",
    "h['nRpc_signal'] = create_TH1D(nRpc['m50ct1m'], axis_title=['nRpc_signal', 'Events'], name='nRpc_signal', binning=[150,0,500])\n",
    "h['nRpc_signal'].SetLineColor(4)\n",
    "\n",
    "h['nRpc_qcd'] = create_TH1D(nRpc['qcd'], axis_title=['nRpc_qcd', 'Events'], name='nRpc_qcd', binning=[150,0,500])\n",
    "h['nRpc_qcd'].SetLineColor(2)\n",
    "h['nRpc_qcd'].SetLineStyle(2)\n",
    "\n",
    "\n",
    "h['nRpc_zeroBias'] = create_TH1D(nRpc['zeroBias'], axis_title=['nRpc_zeroBias', 'Events'], name='nRpc_zeroBias', binning=[150,0,500])\n",
    "h['nRpc_zeroBias'].SetLineColor(2)\n",
    "h['nRpc_zeroBias'].SetLineStyle(1)\n",
    "\n",
    "c6.SetLogy()\n",
    "\n",
    "h['nRpc_signal'].Scale(1.0/h['nRpc_signal'].Integral())\n",
    "h['nRpc_qcd'].Scale(1.0/h['nRpc_qcd'].Integral())\n",
    "h['nRpc_zeroBias'].Scale(1.0/h['nRpc_zeroBias'].Integral())\n",
    "\n",
    "\n",
    "h['nRpc_signal'].SetLineWidth(2)\n",
    "h['nRpc_qcd'].SetLineWidth(2)\n",
    "h['nRpc_zeroBias'].SetLineWidth(2)\n",
    "\n",
    "h['nRpc_signal'].GetXaxis().SetRangeUser(0,200)\n",
    "\n",
    "\n",
    "h['nRpc_signal'].SetStats(0)\n",
    "h['nRpc_signal'].SetTitle(\"RPC Inclusive\")\n",
    "h['nRpc_signal'].SetXTitle(\"N_{DT}\")\n",
    "\n",
    "\n",
    "h['nRpc_signal'].Draw('histo')\n",
    "h['nRpc_qcd'].Draw('histo+same')\n",
    "h['nRpc_zeroBias'].Draw('histo+same')\n",
    "\n",
    "legend = rt.TLegend(0.50,0.70,0.87,0.87);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "legend.AddEntry( h['nRpc_signal'], \"mX=50 GeV, c#tau=1m (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nRpc_qcd'], \"QCD (MC)\" , \"L\");\n",
    "legend.AddEntry( h['nRpc_zeroBias'], \"Zero Bias\" , \"L\");\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c6.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *N<sub>RPC</sub> Threshold ROC Curves*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates ROC curves for the signal efficiency of the m50ct1m signal sample against the ZeroBias/QCD samples\n",
    "# using nRpc thresholds\n",
    "\n",
    "c8 = rt.TCanvas('c8','c8', 800, 600)\n",
    "\n",
    "h['roc_inclusive_zeroBias_rpc'] = create_TGraph(rejection_power['zeroBias']['noCluster']['rpc_inclusive'], eff_nrpc['m50ct1m']['noCluster']['rpc_inclusive'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "\n",
    "h['roc_inclusive_qcd_rpc'] = create_TGraph(rejection_power['qcd']['noCluster']['rpc_inclusive'], eff_nrpc['m50ct1m']['noCluster']['rpc_inclusive'], axis_title=['1/#epsilon_{bkg}', '#epsilon_{signal}'])\n",
    "\n",
    "c8.SetLogx()\n",
    "\n",
    "h['roc_inclusive_zeroBias_rpc'].SetTitle('N_{RPC}: mX=50 GeV, c#tau=1m (MC)')\n",
    "\n",
    "h['roc_inclusive_zeroBias_rpc'].SetLineWidth(2)\n",
    "h['roc_inclusive_qcd_rpc'].SetLineWidth(2)\n",
    "\n",
    "h['roc_inclusive_zeroBias_rpc'].SetLineColor(2)\n",
    "h['roc_inclusive_qcd_rpc'].SetLineColor(4)\n",
    "\n",
    "h['roc_inclusive_zeroBias_rpc'].GetXaxis().SetLimits(10, 10000000)\n",
    "h['roc_inclusive_zeroBias_rpc'].GetYaxis().SetRangeUser(0,1)\n",
    "\n",
    "\n",
    "\n",
    "h['roc_inclusive_zeroBias_rpc'].Draw()\n",
    "h['roc_inclusive_qcd_rpc'].Draw('same')\n",
    "\n",
    "\n",
    "legend = rt.TLegend(0.70,0.70,0.7,0.7);\n",
    "legend.SetTextSize(0.04);\n",
    "legend.SetBorderSize(0);\n",
    "legend.SetFillStyle(0);\n",
    "\n",
    "legend.AddEntry( h['roc_inclusive_zeroBias_rpc'], \"ZeroBias\", 'l');\n",
    "legend.AddEntry( h['roc_inclusive_qcd_rpc'], \"QCD\", 'l');\n",
    "\n",
    "legend.Draw();\n",
    "\n",
    "c8.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
