{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/02\n",
      "3.6.8 (default, Aug  7 2019, 17:28:10) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n"
     ]
    }
   ],
   "source": [
    "import ROOT as rt\n",
    "# import root_numpy as rtnp\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import awkward\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('/storage/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/lib/')\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 0\n",
    "\n",
    "wH = 1\n",
    "Z_MASS = 91.2\n",
    "\n",
    "\n",
    "# donotdelete = []\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "full 105.30388711\n",
      "mc /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p14//MC_RunIIFall18/v1/v1//normalized/ggH_HToSSTobbbb_ms55_pl1000_1pb_weighted.root\n",
      "NEvents 1285000.0\n",
      "NEvents_genweight 27594916.0\n",
      "weights [-4.0220227  3.9419844  3.9818022  4.0220227]\n",
      "0.39818925\n",
      "10443\n",
      "data /mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/Data2018/v4/v4/normalized/Run2_displacedJetMuonNtupler_V1p12_Data2016_Data2017_Data2018-HighMET_goodLumi.root\n",
      "NEvents 16130933.0\n",
      "NEvents_genweight 0.0\n",
      "weights [105303.89]\n",
      "14992230.0\n",
      "14992230\n",
      "361.3488755226135\n"
     ]
    }
   ],
   "source": [
    "fpath_bkg =OrderedDict()\n",
    "tree_bkg = OrderedDict()\n",
    "tree_sig = OrderedDict()\n",
    "fpath_sig =OrderedDict()\n",
    "\n",
    "\n",
    "start_t = time.time()\n",
    "data_year = 'full'\n",
    "pdgId = 13\n",
    "category = 0\n",
    "OLD_CTAU = 100 #cm\n",
    "ntupler_version = 'V1p14/'\n",
    "analyzer_version = 'v1/v1/'\n",
    "\n",
    "# ntupler_version = 'V1p12/'\n",
    "# analyzer_version = 'v4/v4/'\n",
    "if data_year == 2016:\n",
    "    data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/Data'+str(data_year)+'/v4/v4/normalized/'\n",
    "elif data_year == 2017:\n",
    "    data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/Data'+str(data_year)+'/v4/v4/normalized/'\n",
    "elif data_year == 2018:\n",
    "    data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/Data'+str(data_year)+'/v4/v4/normalized/'\n",
    "elif data_year == 'full':\n",
    "    data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/Data2018/v4/v4/normalized/'\n",
    "\n",
    "else:\n",
    "    print(\"DATA YEAR IS WRONG\")\n",
    "    raise NameError('DATA YEAR IS WRONG')\n",
    "mc_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_RunIIFall18/'+analyzer_version+'/normalized/'\n",
    "\n",
    "\n",
    "\n",
    "if category == 0:\n",
    "    if data_year == 2016:\n",
    "        fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2016_Run2016-HighMET-07Aug17_goodLumi.root'\n",
    "        fpath_bkg['mc'] = mc_path + 'ggH_HToSSTobbbb_ms55_pl1000_RunIIFall18_1pb_weighted.root'\n",
    "        lumi = (5.632467289+2.572903489+1.685313225+3.988453305+3.068943620+3.527270568+8.609721915)*1000 #29.085073411\n",
    "    elif data_year == 2017:\n",
    "        fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2017_Run2017-HighMET-17Nov2017_goodLumi.root'\n",
    "        fpath_bkg['mc'] = mc_path + 'ggH_HToSSTobbbb_ms55_pl1000_RunIIFall18_1pb_weighted.root'\n",
    "        lumi = (4.738190514+4.145487893+ 9.295575564+2.603562425) * 1000 #20.782816396\n",
    " \n",
    "    elif data_year == 2018:\n",
    "        fpath_bkg['mc'] = mc_path + 'ggH_HToSSTobbbb_ms55_pl1000_RunIIFall18_1pb_weighted.root'\n",
    "\n",
    "        fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2018_17Sept2018_Run2018-HighMET-17Sep2018_goodLumi.root'\n",
    "        lumi = (13.954129666 + 6.941561868 + 3.227904890 + 31.312400879) * 1000 #55.435997303\n",
    "#         fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2018_17Sept2018_Run2018AB-HighMET-17Sep2018_goodLumi.root'\n",
    "#         lumi = (13.954129666 + 6.941561868 ) * 1000 #AB\n",
    "#         fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2018_17Sept2018_Run2018CD-HighMET-17Sep2018_goodLumi.root'\n",
    "#         lumi = (3.227904890 + 31.312400879) * 1000 #CD\n",
    "    else: #2016, 2017, 2018AB\n",
    "        if OLD_CTAU == 100:\n",
    "            fpath_bkg['mc'] = mc_path + 'ggH_HToSSTobbbb_ms55_pl1000_1pb_weighted.root'\n",
    "        else:\n",
    "            fpath_bkg['mc'] = mc_path + 'ggH_HToSSTobbbb_ms55_pl10000_1pb_weighted.root'\n",
    "            #         fpath_bkg['mc'] = mc_path + 'ggH_HToSSTobbbb_ms55_pl1000_RunIIFall18_1pb_weighted.root'\n",
    "        fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "\n",
    "        lumi = (29.085073411 + 20.782816396+55.435997303)* 1000\n",
    "\n",
    "\n",
    "elif category == 1:\n",
    "    fpath_bkg['mc'] = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/MC_RunIIFall18/v3/v5/normalized/WH_HToSSTobbbb_ms55_pl10000_1pb_weighted.root'\n",
    "\n",
    "#     if pdgId == 13:\n",
    "#         fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2018_SingleMuon_17Sept2018_Run2018D-ZMu-PromptReco-v2.root'\n",
    "#     else:\n",
    "#         fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2018_EGamma_17Sept2018_Run2018D-ZElectron-PromptReco-v2.root'\n",
    "    lumi = 31.34*1000\n",
    "else:\n",
    "    data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/Data'+str(data_year)+'/v2/v3/normalized/'\n",
    "    mc_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p12/MC_RunIISummer16/v1/v2/signals/normalized/'\n",
    "    fpath_bkg['mc'] = mc_path + 'ZH_HToSSTobbbb_ms55_pl1000_1pb_weighted.root'\n",
    "    fpath_bkg['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p12_Data2018_SingleMuon_17Sept2018_Run2018D-ZMu-PromptReco-v2_goodLumi.root'\n",
    "    lumi = 29.516263349*1000\n",
    "\n",
    "NEvents = {}\n",
    "print(data_year, lumi/1000)\n",
    "NEvents_genweight = {}\n",
    "for k,v in fpath_bkg.items():\n",
    "    print (k, v)\n",
    "#     tree[k] = rtnp.root2array(v)\n",
    "    root_dir = uproot.open(v) \n",
    "#     if k[:7] == 'ntuples':\n",
    "#         tree_bkg[k] = root_dir['ntuples']['llp']\n",
    "#         NEvents[k] = root_dir['ntuples']['NEvents'][1]\n",
    "#     else:\n",
    "    tree_bkg[k] = root_dir['MuonSystem']\n",
    "    NEvents[k] = root_dir['NEvents'][1]\n",
    "    NEvents_genweight[k] = root_dir['NEvents_genweight'][1]\n",
    "#     tree[k] = root_dir['ntuples']\n",
    "    a = tree_bkg[k][\"weight\"].array()\n",
    "    print(\"NEvents\",NEvents[k])\n",
    "    print(\"NEvents_genweight\",NEvents_genweight[k])\n",
    "\n",
    "\n",
    "    print ('weights',np.unique(a)*lumi)\n",
    "    print(np.sum(a))\n",
    "    print(len(a))\n",
    "#     print(len(a)/ NEvents[k])\n",
    "#     print(a.shape)\n",
    "print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_names_file = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/trigger_names_llp_v1.dat'\n",
    "trigger_names = []\n",
    "with open(trigger_names_file) as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    for line in reader:\n",
    "        trigger_names.append(line[2])\n",
    "# if wH:\n",
    "#     trigger_paths = [87,135,136] #PFMET120\n",
    "# #     elif data_year == 2017: trigger_paths = [87,136] #PFMET120\n",
    "# else:\n",
    "trigger_paths = [177,362,87,135,136] #PFMET120\n",
    "trigger_paths += [84,91]\n",
    "if category == 0:\n",
    "    trigger_paths = [310]\n",
    "xsec = {}\n",
    "xsec['bbbb10m'] = (5.328E-01 + 8.4E-01) *0.324\n",
    "xsec['bbbb1m'] = (5.328E-01 + 8.4E-01) *0.324\n",
    "xsec['bbbb0.1m'] = (5.328E-01 + 8.4E-01) *0.324\n",
    "\n",
    "\n",
    "xsec['WJetsToLNu'] = 61526.7\n",
    "\n",
    "legend = {}\n",
    "legend['bbbb10m'] = 'signal c#tau = 10 m'\n",
    "legend['bbbb1m'] = 'signal c#tau = 1 m'\n",
    "legend['bbbb0.1m'] = 'signal c#tau = 0.1 m'\n",
    "\n",
    "legend['SingleElectron'] = 'SingleElectron'\n",
    "legend['SingleMuon'] = 'SingleMuon'\n",
    "legend['WJetsToLNu'] = 'WJetsToLNu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load bdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.283564]\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "\n",
    "import pickle\n",
    "# model = pickle.load(open( 'bdt_flatten_noEvtSelection.pickle.dat', \"rb\" ))\n",
    "bdt_name = 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi'\n",
    "model = pickle.load(open( bdt_name+'.pickle', \"rb\" ))\n",
    "y_pred = model.predict_proba([1,2,3,4,4,5,6])[:, 1]\n",
    "print (y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def deltaPhi( phi1,  phi2):\n",
    "    dphi = phi1-phi2\n",
    "    while (dphi > math.pi):\n",
    "        dphi -= 2*math.pi\n",
    "    while (dphi <= -math.pi):\n",
    "        dphi += 2*math.pi\n",
    "    return dphi\n",
    "def deltaR(eta1, phi1, eta2, phi2):\n",
    "    dphi = deltaPhi(phi1,phi2)\n",
    "    deta = eta1 - eta2\n",
    "    return (dphi*dphi + deta*deta)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc with different hit vetoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_vr\n",
      "rechit cluster 83130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/awkward/array/jagged.py:1031: RuntimeWarning: invalid value encountered in less\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigger 310 0.744591631798605\n",
      "True\n",
      "effiency 0.9020452099031216\n",
      "1\n",
      "using dPhi(jet,met)\n",
      "32.0 256.0 485.0 65.0\n",
      "34.30927835051546 32.0\n",
      "uncertainty on a:  5.013467415747312\n",
      "mc_vr\n",
      "rechit cluster 767\n",
      "trigger 310 0.9704108014938236\n",
      "True\n",
      "effiency 0.06262626262626263\n",
      "1\n",
      "using dPhi(jet,met)\n",
      "88.4845199584961 36.198204040527344 0.0 0.0\n",
      "nan 88.4845199584961\n",
      "uncertainty on a:  nan\n",
      "mc_sr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:272: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:272: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:273: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:273: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rechit cluster 767\n",
      "trigger 310 0.9704108014938236\n",
      "True\n",
      "effiency 0.9373737373737374\n",
      "1\n",
      "using dPhi(jet,met)\n",
      "1475.841064453125 172.94696044921875 8.044045448303223 201.1011199951172\n",
      "4323.67366266254 1475.841064453125\n",
      "uncertainty on a:  1589.0327214039878\n",
      "CPU times: user 1min 45s, sys: 11.4 s, total: 1min 56s\n",
      "Wall time: 4min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_t = time.time()\n",
    "JET_PT_CUT = 10.0\n",
    "MUON_PT_CUT = 20.0\n",
    "N_RECHIT_CUT = 90\n",
    "jetPt_cut = 50\n",
    "tightid = False\n",
    "\n",
    "\n",
    "# BDT_CUT = 0.467 #90% wp vBDT/v1, bdt_flatten_noEvtSelection\n",
    "# bdtBkgEff =  0.0661076084960519\n",
    "\n",
    "# BDT_CUT = 0.9227871 #90% wp vBDT/v2, bdt_flatten_metfilter_me1112nohits_eta2p1\n",
    "# bdtBkgEff =  0.10278372591006424\n",
    "if bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs':\n",
    "    BDT_CUT = 0.92245656 #bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs\n",
    "    bdtBkgEff = 0.09957173447537473\n",
    "elif bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi':\n",
    "    BDT_CUT = 0.9608465 #bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi\n",
    "    bdtBkgEff = 0.06745182012847965\n",
    "else:\n",
    "    print('BDT NAME NOT FOUND')\n",
    "\n",
    "intime = True\n",
    "DPHI_CUT = 1\n",
    "weight = {}\n",
    "weight_event = {}\n",
    "weight_ctau = {}\n",
    "lumiSec = {}\n",
    "evtNum = {}\n",
    "nCsc = {}\n",
    "npv = {}\n",
    "npu = {}\n",
    "runNum = {}\n",
    "nCsc_JetMuonVetoCluster0p4_Me1112Veto = {}\n",
    "gLLP_csc = {}\n",
    "cscClusterSize = {}\n",
    "cscClusterTime = {}\n",
    "nCscClusters = {}\n",
    "selections_cluster = {}\n",
    "sel_cluster = {}\n",
    "sel_jetveto = {}\n",
    "met_trigger = {}\n",
    "met = {}\n",
    "gLLP_beta = {}\n",
    "jetPt = {}\n",
    "jetPhi = {}\n",
    "metPhi = {}\n",
    "angle ={}\n",
    "nLeptons = {}\n",
    "genJetPt = {}\n",
    "genJetPhi = {}\n",
    "genMet = {}\n",
    "genMetPhi = {}\n",
    "pileupWeight = {}\n",
    "gLLP_ctau = {}\n",
    "npv = {}\n",
    "nRechitClusters = {}\n",
    "nJets = {}\n",
    "nJets_50gev = {}\n",
    "cscRechitClusterTimeDiff = {}\n",
    "cscRechitCluster_match_gLLP = {}\n",
    "\n",
    "cscRechitClusterXSpread = {}\n",
    "cscRechitClusterYSpread = {}\n",
    "cscRechitClusterNStation = {}\n",
    "cscRechitClusterEtaPhiSpread = {}\n",
    "cscRechitClusterPhiSpread = {}\n",
    "cscRechitClusterEtaSpread = {}\n",
    "cscRechitClusterX = {}\n",
    "cscRechitClusterY = {}\n",
    "cscRechitClusterZ = {}\n",
    "cscRechitClusterPhi = {}\n",
    "cscClusterJetVetoPt = {}\n",
    "cscRechitClusterEta = {}\n",
    "\n",
    "cscRechitClusterMaxStationRatio = {}\n",
    "cscRechitClusterNStation = {}\n",
    "cscRechitClusterNChamber = {}\n",
    "cscRechitClusterMet_dPhi = {}\n",
    "jetMet_dPhiMin30 = {}\n",
    "jetMet_dPhiMin = {}\n",
    "dphiMet_cluster = {}\n",
    "nRechits_sr = {}\n",
    "jetMet_dPhiMin30_sr = {}\n",
    "bdt_score = {}\n",
    "a = {}\n",
    "b = {}\n",
    "c = {}\n",
    "d = {}\n",
    "sel_ev = {}\n",
    "bdt_sel = {}\n",
    "\n",
    "legend = {}\n",
    "\n",
    "legend['data_oot'] = 'Data OOT region'\n",
    "legend['data_intime'] = 'Data in-time region'\n",
    "legend['mc_signal'] = 'signal MC in time'\n",
    "legend['mc_intime'] = 'MC in-time background'\n",
    "legend['mc_oot'] = 'MC OOT background'\n",
    "legend['mc_bkg'] = 'QCD 50toInf background'\n",
    "\n",
    "# keys = ['data','mc_intime_bkg','mc_oot_bkg','mc_signal']\n",
    "keys = ['data_intime','data_oot','mc_signal','mc_bkg']\n",
    "keys = ['data_intime','mc_signal',]\n",
    "keys = ['data_intime','mc_signal']\n",
    "keys = ['data_vr','mc_vr','mc_sr']\n",
    "\n",
    "for k in keys:\n",
    "    print(k)\n",
    "#     if k == 'data_intime': continue\n",
    "    if k == 'mc_bkg':\n",
    "        T = tree_bkg['QCDHT50toInf']\n",
    "    elif k[:2] == 'mc':\n",
    "        T = tree_bkg['mc']\n",
    "    else:\n",
    "        T = tree_bkg['data']\n",
    "\n",
    "        \n",
    "########### SELECTION: CLUSTERS ############\n",
    "\n",
    "    sel_rechitcluster =  np.abs(T.array('cscRechitClusterMaxChamber')) > 12\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, np.abs(T.array('cscRechitClusterEta')) < 2.1)\n",
    "\n",
    "    me1112_veto = 0\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberPlus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberPlus12') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberMinus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitClusterNRechitChamberMinus12') <= me1112_veto)\n",
    "    np.set_printoptions(threshold=10000)\n",
    "    print(\"rechit cluster\", np.count_nonzero(sel_rechitcluster.flatten()))\n",
    "    if intime:\n",
    "        sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitClusterJetVetoPt') < JET_PT_CUT)\n",
    "        sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitClusterMuonVetoPt') < MUON_PT_CUT)\n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster, np.logical_and(T.array('cscRechitClusterTime') < 12.5, T.array('cscRechitClusterTime') > -5.0))\n",
    "    else:\n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster,  T.array('cscRechitClusterTime') < -12.5)\n",
    "\n",
    "########### SELECTION: JETS ############\n",
    "    \n",
    "    sel_jet = np.logical_and(T.array('jetPt') > jetPt_cut, np.abs(T.array('jetEta')) < 2.4 )\n",
    "\n",
    "########### SELECTION: EVENTS ############\n",
    "    hlt = T['HLTDecision'].array()\n",
    "    # select only triggered events\n",
    "    sel_ev[k] = np.ones(hlt[:,0].shape, dtype=bool)\n",
    "    sel_ev[k] = np.zeros(hlt[:,0].shape)\n",
    "    for tr in trigger_paths:            \n",
    "        sel_ev[k]   = np.logical_or(sel_ev[k] ,hlt[:,tr])\n",
    "        print(\"trigger\",tr,1.0*np.count_nonzero(hlt[:,tr])/len(hlt[:,tr]))\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k], T.array('category') == category)\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k],sel_rechitcluster.sum() == 1)\n",
    "\n",
    "    if category == 0:\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('met') > 200)\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('nLeptons') == 0)\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k] , sel_jet.sum()>=1)\n",
    "\n",
    "        if k[:4] == 'data':\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag_HBHENoiseFilter'))\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag_HBHEIsoNoiseFilter'))\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag_BadPFMuonFilter'))\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag_CSCTightHaloFilter'))\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag_goodVertices'))\n",
    "#             sel_ev = np.logical_and(sel_ev, T.array('runNum')<319077)\n",
    "#             print('selev',np.count_nonzero(sel_ev))\n",
    "#             sel_ev = np.logical_and(sel_ev, T.array('Flag_ecalBadCalibFilter'))\n",
    "#             print('selev',np.count_nonzero(T.array('Flag_ecalBadCalibFilter')))\n",
    "    gLLP_csc[k] = T.array('gLLP_csc')\n",
    "    if k[:2] == 'mc':\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], np.sum(T.array('gLLP_csc'),axis = 1) > 0)\n",
    "########### BRANCHES ############\n",
    "\n",
    "   ##### event variables ##### \n",
    "    \n",
    "    gLLP_beta[k] = T.array('gLLP_beta')[sel_ev[k]]\n",
    "\n",
    "\n",
    "    ##### bdt variables ####\n",
    "    \n",
    "    cscRechitClusterPhi[k] = T.array('cscRechitClusterPhi')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterXSpread[k] = T.array('cscRechitClusterXSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterYSpread[k] = T.array('cscRechitClusterYSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEtaSpread[k] = T.array('cscRechitClusterEtaSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterPhiSpread[k] = T.array('cscRechitClusterPhiSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterNStation[k] = T.array('cscRechitClusterNStation')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEtaPhiSpread[k] = T.array('cscRechitClusterEtaPhiSpread')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterX[k] = T.array('cscRechitClusterX')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterY[k] = T.array('cscRechitClusterY')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterZ[k] = T.array('cscRechitClusterZ')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEta[k] = T.array('cscRechitClusterEta')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterPhi[k] = T.array('cscRechitClusterPhi')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "\n",
    "    if bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs':\n",
    "        \n",
    "        bdt_var = {'cscRechitClusterXSpread': cscRechitClusterXSpread[k],\n",
    "         'cscRechitClusterYSpread': cscRechitClusterYSpread[k],\n",
    "         'cscRechitClusterNStation':cscRechitClusterNStation[k],\n",
    "         'cscRechitClusterEtaPhiSpread':cscRechitClusterEtaPhiSpread[k],\n",
    "         'cscRechitClusterX':cscRechitClusterX[k],\n",
    "         'cscRechitClusterY':cscRechitClusterY[k],\n",
    "         'cscRechitClusterZ':cscRechitClusterZ[k],\n",
    "        }\n",
    "    elif bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p1_testsize0p2_abs_EtaPhi':\n",
    "        bdt_var = {'cscRechitClusterNStation': cscRechitClusterNStation[k],\n",
    "         'cscRechitClusterEtaSpread': cscRechitClusterEtaSpread[k],\n",
    "         'cscRechitClusterPhiSpread':cscRechitClusterPhiSpread[k],\n",
    "         'cscRechitClusterEtaPhiSpread':cscRechitClusterEtaPhiSpread[k],\n",
    "         'cscRechitClusterPhi':cscRechitClusterPhi[k],\n",
    "         'cscRechitClusterEta':np.abs(cscRechitClusterEta[k]),\n",
    "         'cscRechitClusterZ':np.abs(cscRechitClusterZ[k]),\n",
    "        }\n",
    "    else:\n",
    "        print('BDT NAME NOT FOUND')\n",
    "    \n",
    "    \n",
    "    dataset = pd.DataFrame(bdt_var)\n",
    "    bdt_score[k] = model.predict_proba(dataset.values)[:, 1]\n",
    "    print(len(bdt_score[k]) == np.count_nonzero(sel_ev[k]))\n",
    "    bdt_sel[k] = bdt_score[k] < BDT_CUT \n",
    "    if 'vr' in k:\n",
    "        bdt_sel[k] = bdt_score[k] < BDT_CUT \n",
    "    else:\n",
    "        bdt_sel[k] = bdt_score[k] >= BDT_CUT \n",
    "    print(\"effiency\",np.count_nonzero(bdt_sel[k])/len(bdt_sel[k]))\n",
    "\n",
    "\n",
    "\n",
    "    dphiMet_cluster[k] = np.abs(T.array('cscRechitClusterMet_dPhi'))[sel_rechitcluster][sel_ev[k]][:,0].flatten()[bdt_sel[k]]\n",
    "\n",
    "    jetMet_dPhiMin[k] = T.array('jetMet_dPhiMin')[sel_ev[k]][bdt_sel[k]]\n",
    "    metPhi[k] = T.array('metPhi')[sel_ev[k]]\n",
    "    jetPhi[k] = T.array('jetPhi')[sel_ev[k]]\n",
    "    jetPt[k] = T.array('jetPt')[sel_ev[k]]\n",
    "    jetMet_dPhiMin30[k] = []\n",
    "    for ev in range(len(jetPhi[k])):\n",
    "        dphi_min_temp = 999\n",
    "        for i in range(len(jetPhi[k][ev])):\n",
    "            if jetPt[k][ev][i] < 30: continue\n",
    "            dphi_temp = abs(deltaPhi(metPhi[k][ev],jetPhi[k][ev][i]))\n",
    "            if dphi_min_temp > dphi_temp: dphi_min_temp = dphi_temp\n",
    "        jetMet_dPhiMin30[k].append(dphi_min_temp)\n",
    "    jetMet_dPhiMin30[k] = np.array(jetMet_dPhiMin30[k])\n",
    "    jetMet_dPhiMin30_sr[k] = jetMet_dPhiMin30[k][np.logical_not(bdt_sel[k])]\n",
    "    jetMet_dPhiMin30[k] = jetMet_dPhiMin30[k][bdt_sel[k]]\n",
    "    weight[k] = T.array('weight')[sel_ev[k]][bdt_sel[k]]\n",
    "    npv[k] = T.array('npv')[sel_ev[k]][bdt_sel[k]]\n",
    "\n",
    "    \n",
    "    if k[:2] == 'mc':\n",
    "        pileupWeight[k] = T.array('pileupWeight')[sel_ev[k]][bdt_sel[k]]\n",
    "    else:\n",
    "        pileupWeight[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "    if k[:2] == 'mc':\n",
    "        weight[k] = weight[k]*lumi\n",
    "    ##### clusters #####\n",
    "    cscClusterTime[k] = T.array('cscRechitClusterTime')[sel_rechitcluster][sel_ev[k]][bdt_sel[k]][:,0]\n",
    "    cscClusterSize[k] =  T.array('cscRechitClusterSize')[sel_rechitcluster][sel_ev[k]][bdt_sel[k]]\n",
    "    nRechits_sr[k] =  T.array('cscRechitClusterSize')[sel_rechitcluster][sel_ev[k]][np.logical_not(bdt_sel[k])]\n",
    "\n",
    "    nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] = cscClusterSize[k][:,0]\n",
    "   \n",
    "    br = 1\n",
    "    var = jetMet_dPhiMin30[k]\n",
    "    print(br)\n",
    "    print(\"using dPhi(jet,met)\")\n",
    "    DPHI_CUT = 0.6\n",
    "    a[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var>=DPHI_CUT)])\n",
    "    b[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var>=DPHI_CUT)])\n",
    "    c[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var<DPHI_CUT)])\n",
    "    d[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var<DPHI_CUT)])\n",
    "    print(a[k],b[k],c[k],d[k])\n",
    "    print(b[k]/c[k]*d[k],a[k])\n",
    "    print(\"uncertainty on a: \", (1./b[k] + 1./c[k] + 1./d[k])**0.5*(b[k]/c[k]*d[k]))\n",
    "    if k == 'mc_sr':\n",
    "        sig_dphiJet = a[k]\n",
    "    elif k == 'data_vr':\n",
    "        bkg_dphiJet = a[k]/(1-bdtBkgEff)*bdtBkgEff\n",
    "    var = dphiMet_cluster[k]\n",
    "    DPHI_CUT = 0.75\n",
    "    a[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var>=DPHI_CUT)])\n",
    "    b[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var>=DPHI_CUT)])\n",
    "    c[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var<DPHI_CUT)])\n",
    "    d[k] = br * np.sum(weight[k][np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var<DPHI_CUT)])\n",
    "    if k == 'mc_sr':\n",
    "        sig_dphiCluster = d[k]\n",
    "    elif k == 'data_vr':\n",
    "        bkg_dphiCluster = a[k]/(1-bdtBkgEff)*bdtBkgEff\n",
    "    \n",
    "#     if k == 'data_intime':\n",
    "#         print(np.sum(weight[k][nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<70]/(1-bdtBkgEff)*bdtBkgEff))\n",
    "#         print(np.count_nonzero(nRechits_SR[k]<70))\n",
    "    \n",
    "\n",
    "# print(\"branching ratio: \"+str(br))\n",
    "# print(sig_dphiJet*137000/lumi, bkg_dphiJet*137000/lumi)\n",
    "# print(sig_dphiCluster*137000/lumi, bkg_dphiCluster*137000/lumi)\n",
    "\n",
    "# br = 0.005\n",
    "# print(\"branching ratio: \"+str(br))\n",
    "# print(\"asimov dataset\")\n",
    "# s = br*sig_dphiJet*137000/lumi\n",
    "# b = bkg_dphiJet* 137000/lumi\n",
    "# sig = (2*(s+b)*math.log(1+s/b)-s)**0.5\n",
    "# print(\"significance for dPhi(jet, MET): \", sig)\n",
    "# s = br*sig_dphiCluster*137000/lumi\n",
    "# b = bkg_dphiCluster* 137000/lumi\n",
    "# sig = (2*(s+b)*math.log(1+s/b)-s)**0.5\n",
    "# print(\"significance for dPhi(cluster,MET): \", sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# life time reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " #in cm\n",
    "ctaus = ['5','10','30','40', '50','100','200','300','500','1000', '5000', '10000', '100000']\n",
    "k = 'mc_vr'\n",
    "T = tree_bkg['mc']\n",
    "for ctau in ctaus:\n",
    "    new_ctau = float(ctau)\n",
    "    gLLP_ctau[ctau] = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "    weight_ctau[ctau] = np.exp(gLLP_ctau[ctau]*(1.0/OLD_CTAU - 1.0/new_ctau))*(OLD_CTAU*1.0/new_ctau)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 0.07240222891171773 0.86882675 12\n",
      "130 0.12411810670580183 0.86882675 7\n",
      "140 0.1184875454221453 0.8294128 7\n",
      "150 0.13799285888671875 0.6899643 5\n",
      "160 0.17249107360839844 0.6899643 4\n",
      "170 0.1632307469844818 0.652923 4\n",
      "180 0.1632307469844818 0.652923 4\n",
      "190 0.21764099597930908 0.652923 3\n",
      "200 0.5789625644683838 0.57896256 1\n",
      "210 0.5789625644683838 0.57896256 1\n"
     ]
    }
   ],
   "source": [
    " #in cm\n",
    "ctaus = ['5','10','30','40', '50','100','200','300','500','1000', '5000', '10000', '100000']\n",
    "ctaus = ['100']\n",
    "k = 'mc_signal'\n",
    "T = tree_bkg['mc']\n",
    "br = 0.01 # use 1%\n",
    "DPHI_CUT = 0.6\n",
    "N_RECHIT_CUTS = np.arange(120,220, 10)\n",
    "\n",
    "for N_RECHIT_CUT in N_RECHIT_CUTS:\n",
    "    a_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] >= N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] >= DPHI_CUT))\n",
    "    b_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] < N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] >= DPHI_CUT))\n",
    "    c_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] < N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] < DPHI_CUT))\n",
    "    d_data = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['data_vr'] >= N_RECHIT_CUT, jetMet_dPhiMin30['data_vr'] < DPHI_CUT))\n",
    "    for ctau in ctaus:\n",
    "        new_ctau = float(ctau)\n",
    "        w = br * pileupWeight['mc_vr'] * weight['mc_vr'] * weight_ctau[ctau]\n",
    "        a = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']>=N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']>=DPHI_CUT)])\n",
    "        b = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']<N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']>=DPHI_CUT)])\n",
    "        c = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']<N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']<DPHI_CUT)])\n",
    "        d = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_vr']>=N_RECHIT_CUT, jetMet_dPhiMin30['mc_vr']<DPHI_CUT)])\n",
    "\n",
    "        print(N_RECHIT_CUT, a/a_data, a, a_data)\n",
    "        w = br * pileupWeight['mc_sr'] * weight['mc_sr'] \n",
    "        a = np.sum(w[np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto['mc_sr']>=N_RECHIT_CUT, jetMet_dPhiMin30['mc_sr']>=DPHI_CUT)])\n",
    "#         print(a)\n",
    "        \n",
    "        \n",
    "#         print(N_RECHIT_CUT, a/a_data,b/b_data,c/c_data,d/d_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check bdt eff in low N_rechits bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 'data_intime'\n",
    "# print(\"n_rechit, VR, SR, unc\")\n",
    "# for n_rechits in [60,70,80,90]:\n",
    "#     for dphi in [ 0.4]:\n",
    "# #         print(\"dphi, n_rechits\", dphi, n_rechits)\n",
    "#         inverted = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<n_rechits, jetMet_dPhiMin30[k]<dphi))\n",
    "#         inverted_unc = inverted**0.5/(1-bdtBkgEff)*bdtBkgEff\n",
    "#         inverted = inverted/(1-bdtBkgEff)*bdtBkgEff\n",
    "#         print(n_rechits, np.count_nonzero(np.logical_and(nRechits_SR[k]<n_rechits, jetMet_dPhiMin30_sr[k]<dphi)), round(inverted,2), round(inverted_unc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120, 130, 140, 150, 160, 170, 180, 190, 200, 210])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(120,220, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8679678530424798 19.963260619977035 38.55223880597014 1.2296211251435132 0.6367268865658717\n",
      "signal [1473.9126, 279.7896, 29.397078, 171.97713]\n",
      "0.5063145809414465 20.32491389207807 38.69690011481056 1.0849598163030996 0.5698573988433102\n",
      "signal [1440.279, 313.42297, 33.644295, 167.7299]\n",
      "0.5063145809414465 20.32491389207807 39.203214695752 0.5786452353616532 0.29999872903436264\n",
      "signal [1403.3794, 350.3227, 42.50543, 158.86877]\n",
      "0.36165327210103326 20.469575200918484 39.27554535017221 0.5063145809414465 0.2638803432899252\n",
      "signal [1373.2905, 380.4115, 46.78697, 154.58723]\n",
      "0.2893226176808266 20.541905855338687 39.42020665901262 0.36165327210103326 0.1884578518838412\n",
      "signal [1344.4524, 409.2498, 46.78697, 154.58723]\n",
      "0.2893226176808266 20.541905855338687 39.56486796785304 0.21699196326061995 0.112661275257799\n",
      "signal [1304.9998, 448.70242, 50.4911, 150.88312]\n",
      "0.2893226176808266 20.541905855338687 39.637198622273246 0.1446613088404133 0.0749704593260536\n",
      "signal [1273.4146, 480.2876, 57.195545, 144.17867]\n",
      "0.21699196326061995 20.614236509758896 39.637198622273246 0.1446613088404133 0.07523443981663831\n",
      "signal [1254.3818, 499.32028, 57.195545, 144.17867]\n",
      "0.07233065442020666 20.75889781859931 39.637198622273246 0.1446613088404133 0.0757624007978077\n",
      "signal [1225.4226, 528.2793, 60.899677, 140.47453]\n",
      "0.07233065442020666 20.75889781859931 39.70952927669345 0.07233065442020666 0.03781220003387852\n",
      "signal [1200.4489, 553.2532, 60.899677, 140.47453]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "N_RECHIT_CUTS = np.arange(120,220, 10)\n",
    "# N_RECHIT_CUT = 120\n",
    "DPHI_CUT = 0.6\n",
    "UNBLIND = False\n",
    "\n",
    "for N_RECHIT_CUT in N_RECHIT_CUTS:\n",
    "\n",
    "\n",
    "    k = 'data_vr'\n",
    "\n",
    "    a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, jetMet_dPhiMin30[k] >= DPHI_CUT))/(1-bdtBkgEff)*bdtBkgEff\n",
    "    b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, jetMet_dPhiMin30[k] >= DPHI_CUT))/(1-bdtBkgEff)*bdtBkgEff\n",
    "    c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, jetMet_dPhiMin30[k] < DPHI_CUT))/(1-bdtBkgEff)*bdtBkgEff\n",
    "    d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, jetMet_dPhiMin30[k] < DPHI_CUT))/(1-bdtBkgEff)*bdtBkgEff\n",
    "    c1 = b/c\n",
    "    c2 = d/c\n",
    "    a_pred = b*d/c\n",
    "    stat_unc = (1./b + 1./c + 1./d)**0.5*(b/c*d)\n",
    "    sys_unc = abs(a-a_pred)/a_pred\n",
    "    unc = [(stat_unc**2 + sys_unc**2)**0.5, b**0.5, c**0.5, d**0.5]\n",
    "    print(a, b, c, d, a_pred)\n",
    "    \n",
    "#     print(a*(1-bdtBkgEff)/bdtBkgEff, b*(1-bdtBkgEff)/bdtBkgEff, c*(1-bdtBkgEff)/bdtBkgEff, d*(1-bdtBkgEff)/bdtBkgEff, a_pred*(1-bdtBkgEff)/bdtBkgEff)\n",
    "\n",
    "    #####\n",
    "    # a = c*c1*c2\n",
    "    # b = c1* c\n",
    "    # c = c\n",
    "    # d = c2*c\n",
    "    #####\n",
    "    k = 'mc_sr'\n",
    "#     br = 0.001 # 0.01 percent br\n",
    "    # ntupler_version = 'V1p12'\n",
    "    # analyzer_version = '/v4/v4/'\n",
    "    outDataCardsDir = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine/datacards/'+ntupler_version+analyzer_version\n",
    "    if not os.path.isdir(outDataCardsDir):os.mkdir(outDataCardsDir)\n",
    "    sig_norm = []\n",
    "\n",
    "    for ctau in ctaus:\n",
    "        new_ctau = int(ctau)\n",
    "        modelName = 'ggh_mh125_mx55_ctau'+str(int(OLD_CTAU/100))+'m_reweight_'+str(new_ctau)+'cm_nRechit'+str(N_RECHIT_CUT)+'dPhi0p6'\n",
    "        signal_rate = []\n",
    "        w = pileupWeight[k] * weight[k] * weight_ctau[ctau]\n",
    "        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, jetMet_dPhiMin30[k]>=DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "        \n",
    "        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, jetMet_dPhiMin30[k]>=DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, jetMet_dPhiMin30[k]<DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "        cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, jetMet_dPhiMin30[k]<DPHI_CUT)\n",
    "        signal_rate.append(np.sum(w[cond]))\n",
    "#         print(np.sum(signal_rate), np.sum(w))\n",
    "#         print(ctau,N_RECHIT_CUT, signal_rate)\n",
    "#         print(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k][nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=120])\n",
    "        norm = np.sum(signal_rate)/2\n",
    "    #     norm= signal_rate[0]/1.57\n",
    "    #     norm = np.min(signal_rate)/0.1\n",
    "        sig_norm.append(norm)\n",
    "        if new_ctau == 100: print(\"signal\", signal_rate)\n",
    "        signal_rate = signal_rate/norm\n",
    "        \n",
    "    #     signal_rate = signal_rate/signal_rate[0]\n",
    "        make_datacard(outDataCardsDir, modelName, signal_rate, norm, a_pred,b,c,d, unc)\n",
    "#         if new_ctau == 100: print(\"signal\", signal_rate)\n",
    "#     print([int(a) for a in ctaus])\n",
    "# print(sig_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datacard(outDataCardsDir,modelName, signal_rate, norm, a,b,c,d, unc):\n",
    "    c1 = b/c\n",
    "    c2 = d/c\n",
    "    \n",
    "    text_file = open(outDataCardsDir+modelName+\".txt\", \"w\")\n",
    "    text_file.write('# signal norm {0} \\n'.format(norm))\n",
    "\n",
    "    text_file.write('imax {0} \\n'.format(4))\n",
    "    text_file.write('jmax {0} \\n'.format(1))\n",
    "    text_file.write('kmax * \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('bin \\t chA \\t chB \\t chC \\t chD \\n')\n",
    "    text_file.write('observation \\t {0:6.2f} \\t {1:6.2f} \\t {2:6.2f} \\t {3:6.2f} \\n'.format(a, b, c, d))\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    text_file.write('bin \\t chA \\t chA \\t chB \\t chB \\t chC \\t chC \\t chD \\t chD \\n')\n",
    "    text_file.write('process sig \\t bkg \\t sig \\t bkg \\t sig \\t bkg \\t sig \\t bkg \\n')\n",
    "    text_file.write('process 0 \\t 1 \\t 0 \\t 1 \\t 0 \\t 1 \\t 0 \\t 1 \\n')\n",
    "    rate_string = 'rate'\n",
    "    for i, rate in enumerate(signal_rate):\n",
    "\n",
    "        rate_string =  rate_string+'\\t {0:e} \\t 1'.format(rate)\n",
    "    text_file.write(rate_string+'\\n')\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    for ch in ['A','B','C','D']:\n",
    "        text_file.write('NA_{0}\\t rateParam \\t ch{1} \\t bkg \\t {2:6.2f} \\n'.format(data_year, ch, c))\n",
    "\n",
    "    text_file.write('c1_{0}\\t rateParam \\t chA \\t bkg \\t {1:e} \\n'.format(data_year, c1))\n",
    "    text_file.write('c2_{0}\\t rateParam \\t chA \\t bkg \\t {1:e} \\n'.format(data_year, c2))\n",
    "    text_file.write('c1_{0}\\t rateParam \\t chB \\t bkg \\t {1:e} \\n'.format(data_year, c1))\n",
    "    text_file.write('c2_{0}\\t rateParam \\t chD \\t bkg \\t {1:e} \\n'.format(data_year, c2))\n",
    "\n",
    "#     #### uncertainties ####\n",
    "    text_file.write('lumi\\t lnN \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\n')\n",
    "    text_file.write('signal_yield \\t lnN \\t 1.2 \\t - \\t 1.2 \\t - \\t 1.2 \\t - \\t 1.2 \\t - \\n')\n",
    "    text_file.write('data_pred \\t lnN \\t - \\t {0} \\t - \\t {1} \\t - \\t {2} \\t - \\t {3} \\n'.format(1+unc[0], 1+unc[1], 1+unc[2], 1+unc[3]))\n",
    "\n",
    "\n",
    "\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# significance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# background prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution for event level variables in different binnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roc curve for event level variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['histo_utilities'])\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "leg = rt.TLegend(0.5,0.80,0.90,0.90)\n",
    "\n",
    "leg.SetTextSize(0.03)\n",
    "leg.SetBorderSize(0)\n",
    "\n",
    "leg.SetEntrySeparation(0.01)\n",
    "c = rt.TCanvas('c','c', 800, 800)\n",
    "# Plotting ncsc\n",
    "start_t = time.time()\n",
    "\n",
    "legend = {}\n",
    "legend['data_oot'] = 'Data OOT region'\n",
    "legend['data_intime'] = 'Data in-time region'\n",
    "legend['mc_signal'] = 'signal MC in time'\n",
    "legend['mc_intime'] = 'MC in-time background'\n",
    "legend['mc_oot'] = 'MC OOT background'\n",
    "legend['mc_bkg'] = 'QCD 50toInf background'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "keys = ['data_intime','data_oot','mc_signal',]\n",
    "keys = ['data_intime','mc_signal',]\n",
    "\n",
    "\n",
    "h = {}\n",
    "rt.gStyle.SetOptFit(1011)\n",
    "# for i,k in enumerate(tree_bkg.keys()):\n",
    "br = 1\n",
    "for i,k in enumerate(keys):\n",
    "\n",
    "#     if k == 'data_intime':\n",
    "#         cond = nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < 200\n",
    "        \n",
    "#     else:\n",
    "#         cond = np.ones(weight[k].shape, dtype=bool)\n",
    "#     cond = np.logical_and(cond, jetMet_dPhiMin4[k]>0.25)\n",
    "    if k == 'mc_signal':\n",
    "        br = 1\n",
    "    else: br = 1\n",
    "#     if k == 'mc_background':br = 1\n",
    "    bins = [50,0,1000]\n",
    "    metcut = 200\n",
    "    h[k] = create_TH1D( nCsc_JetMuonVetoCluster0p4_Me1112Veto[k][cond], axis_title=['N_{rechits}', 'Events'], name=k, binning=bins,weights = br*weight[k][cond])\n",
    "    h[k].SetLineColor(std_color_list[i])\n",
    "    print(\"weight\",weight[k][0])\n",
    "    leg.AddEntry(h[k], legend[k]+\" (scaled)\" if k == 'data_oot' else legend[k])\n",
    "#     if k == 'mc_signal':\n",
    "#         for i in range(h[k].GetNbinsX()):\n",
    "#             s = 0.015*h[k].GetBinContent(i+1)\n",
    "#             b = h['data_oot'].GetBinContent(i+1)\n",
    "#             if s+b == 0:continue\n",
    "#             sig = s/(s+b)**0.5\n",
    "#             print(i,h[k].GetBinCenter(i+1),sig,s,b)\n",
    "#             if sig < 1./100:\n",
    "#                 print(i,sig)\n",
    "#                 continue\n",
    "#     h[k].SetMinimum(1)\n",
    "\n",
    "#     r = h[k].Fit('expo', 'LRSQ+', '', 50,400)\n",
    "#     print(r.Get())\n",
    "#     print(r.Prob())\n",
    "#     h[k].GetFunction(\"expo\").SetLineColor(std_color_list[2])\n",
    "#     h[k].GetFunction(\"expo\").SetLineWidth(2)\n",
    "    h[k].GetXaxis().SetLabelSize(0.04)\n",
    "    h[k].SetMinimum(0.1)\n",
    "    h[k].SetMaximum(10E6/2)\n",
    "#     h[k+'met'].GetXaxis().SetLabelSize(0.02)\n",
    "    if k == 'data_oot':\n",
    "        scale = 1.0*h['data_intime'].GetBinContent(4)/h['data_oot'].GetBinContent(4)\n",
    "#         for i in range(10):\n",
    "#             print(1.0*h['data_intime'].GetBinContent(i+1)/h['data_oot'].GetBinContent(i+1))\n",
    "        h[k].Scale(scale)\n",
    "    if k[:4] == 'data':\n",
    "        h[k].Draw('same E1')\n",
    "    else:\n",
    "        h[k].Draw(\"same hist\")\n",
    "#     h[k+'met'].DrawNormalized('same')\n",
    "    \n",
    "\n",
    "# c = make_ratio_plot([h['mc'],h['data']], fit = False, logy=True, in_tags = [\"MC\",\"Data\"], ratio_bounds = [0,3])\n",
    "c.SetRightMargin(0)\n",
    "c.SetLogy()\n",
    "leg.Draw()\n",
    "\n",
    "c.Draw()\n",
    "# print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['histo_utilities'])\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "leg = rt.TLegend(0.5,0.80,0.90,0.90)\n",
    "\n",
    "leg.SetTextSize(0.03)\n",
    "leg.SetBorderSize(0)\n",
    "\n",
    "leg.SetEntrySeparation(0.01)\n",
    "c = rt.TCanvas('c','c', 800, 800)\n",
    "# Plotting ncsc\n",
    "start_t = time.time()\n",
    "\n",
    "\n",
    "k = 'data_intime'\n",
    "\n",
    "h = {}\n",
    "rt.gStyle.SetOptFit(1011)\n",
    "\n",
    "bins = [40,0,1000]\n",
    "metcut = 200\n",
    "\n",
    "# cscRechitClusterMaxChamber = {}\n",
    "# cscRechitClusterNChamber = {}\n",
    "# cscRechitClusterNStation = {}\n",
    "# cscRechitClusterMaxStationRatio = {}\n",
    "# cscRechitClusterMaxChamberRatio = {}\n",
    "\n",
    "# h[k] = create_TH1D( cscRechitClusterMaxChamber[k], axis_title=['max chamber', 'Events'], name=k, binning=[200,-50,50])\n",
    "h[k] = create_TH1D( cscRechitClusterMaxChamberRatio[k], axis_title=['max chamber ratio', 'Events'], name=k, binning=[20,0,1])\n",
    "# h[k] = create_TH1D( cscClusterMet_dPhi[k], axis_title=['#Delta#phi(MET, cluster)', 'Events'], name=k, binning=[20,0,3.14])\n",
    "# h[k] = create_TH1D( n_chamber[k], axis_title=['Number of Chambers', 'Events'], name=k, binning=[10,0,10])\n",
    "# h[k] = create_TH1D( cscRechitClusterNStation[k], axis_title=['max station', 'Events'], name=k, binning=[5,0,5])\n",
    "# print(cscRechitClusterMaxStationRatio[k])\n",
    "# h[k] = create_TH1D( cscRechitClusterNStation[k], axis_title=['Number of station', 'Events'], name=k, binning=[20,0,10])\n",
    "\n",
    "\n",
    "# h['1jet'].GetXaxis().SetLabelSize(0.04)\n",
    "# h['1jet'].SetMinimum(0.1)\n",
    "# h['1jet'].SetMaximum(10E6/2)\n",
    "\n",
    "h[k].Draw('hist')\n",
    "\n",
    "\n",
    "c.SetRightMargin(0)\n",
    "c.SetLogy()\n",
    "\n",
    "c.Draw()\n",
    "# print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_t = time.time()\n",
    "#ROC curve\n",
    "c = rt.TCanvas('c','c', 800, 800)\n",
    "leg = rt.TLegend(0.35,0.80,0.85,0.92)\n",
    "leg.SetTextSize(0.022)\n",
    "leg.SetBorderSize(0)\n",
    "\n",
    "leg.SetEntrySeparation(0.01)\n",
    "\n",
    "var = [nCsc_JetMuonVetoCluster0p4_Me1112Veto,]\n",
    "name = ['nCsc_JetMuonVetoCluster0p4_Me1112Veto',]\n",
    "legend = [ 'jet & muon veto + ME11/12 veto',]\n",
    "\n",
    "bkg_k = 'data_oot'\n",
    "sig_k = 'mc_signal'\n",
    "br = 0.01\n",
    "\n",
    "threshold = list(range(300))\n",
    "threshold = np.array(list(range(2000)))\n",
    "# print(threshold)\n",
    "for i in range(len(var)):\n",
    "    event_count = {}\n",
    "    \n",
    "    for k in ['data_oot','mc_signal']:\n",
    "        event_count[k] = []\n",
    "        for th in threshold:\n",
    "            event_count[k].append(np.sum(weight[k][var[i][k]>th]))\n",
    "        event_count[k] = np.array(event_count[k])\n",
    "        if k == sig_k:\n",
    "            event_count[k] = event_count[k]*br\n",
    "    sig = event_count[sig_k]/np.sqrt(event_count[sig_k]+event_count[bkg_k])\n",
    "    cond = event_count[sig_k]>0\n",
    "    sig = sig[cond]\n",
    "    ncsc = threshold[cond]\n",
    "#     gr['bbbb'] = create_TGraph(eff_bkg,eff_sig,axis_title = ['#epsilon_{bkg}','#epsilon_{signal}'])\n",
    "    h[sig_k+str(i)] = create_TGraph(ncsc, sig,  axis_title=['N_{rechits}', 'Significnace'])\n",
    "#     h[sig_k+str(i)] = create_TGraph(ncsc, event_count[sig_k],  axis_title=['N_{rechits}', 'Event Yield'])\n",
    "\n",
    "    h[sig_k+str(i)].SetLineWidth(2)\n",
    "    h[sig_k+str(i)].SetMarkerColor(std_color_list[i])\n",
    "    h[sig_k+str(i)].SetLineColor(std_color_list[i])\n",
    "    h[sig_k+str(i)].GetXaxis().SetRangeUser(0, 3000)\n",
    "    h[sig_k+str(i)].GetXaxis().SetLabelSize(0.04)\n",
    "\n",
    "#     h[sig_k+str(i)].GetYaxis().SetRangeUser(0, 3)\n",
    "\n",
    "\n",
    "    leg.AddEntry(h[sig_k+str(i)],sig_k+\" \"+legend[i])\n",
    "    h[sig_k+str(i)].Draw('ac' if i == 0 else 'c')\n",
    "\n",
    "#     h[sig_k+str(i)].Draw('ac' if i==0 else 'c')\n",
    "#     gr['bbbb'].Draw('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# c.SetLogy()\n",
    "c.Draw()\n",
    "# c.SaveAs('../plots/timing_studies/compare_timing_definition_ROC.png')\n",
    "\n",
    "print(time.time()-start_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ncsc\n",
    "start_t = time.time()\n",
    "c = rt.TCanvas('c','c', 1000, 800)\n",
    "h = {}\n",
    "# leg = rt.TLegend(0.50,0.75,0.97,0.93)\n",
    "leg = rt.TLegend(0.58,0.70,0.94,0.85)\n",
    "leg.SetTextSize(0.022)\n",
    "# leg.SetTextFont(42)\n",
    "leg.SetEntrySeparation(0.01)\n",
    "\n",
    "i = 0\n",
    "k = 'data_intime'\n",
    "\n",
    "# h[k] = create_TH2D(np.column_stack((angle[k][cond],jetPt[k][cond][:,0])), axis_title = ['\\Delta\\phi (jet,met)','jet p_{T}[GeV]','Events'], binning=[80,-3.14,3.14,100,0,2000])\n",
    "h[k] = create_TH2D(np.column_stack(( nCsc_JetMuonVetoCluster0p4_Me1112Veto[k], dphiMet_cluster[k])),\n",
    "                   axis_title = ['N_{rechits}','\\Delta\\phi (cluster,met)','Events'], binning=[50,0,600,50,0,3.14])\n",
    "h[k] = create_TH2D(np.column_stack(( nCsc_JetMuonVetoCluster0p4_Me1112Veto[k], jetMet_dPhiMin4[k])),\n",
    "                   axis_title = ['N_{rechits}','min_{4jet}\\Delta\\phi (jet,met)','Events'], binning=[50,0,600,50,0,3.14])\n",
    "\n",
    "\n",
    "h[k].GetXaxis().SetLabelSize(0.04)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h[k].SetLineColor(std_color_list[i])\n",
    "# leg.AddEntry(h[k], k)\n",
    "#     h[k].SetMaximum(10E5)\n",
    "#     h[k].SetMinimum(1)\n",
    "h[k].Draw('colz')\n",
    "c.SetRightMargin(0.2)\n",
    "\n",
    "\n",
    "\n",
    "# if setlog: \n",
    "c.SetLogz()\n",
    "c.Draw()\n",
    "print(time.time()-start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# event yield vs. ncsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
